{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## LangChain chains",
   "id": "3548fe4a952ca65f"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-05T06:59:48.141055Z",
     "start_time": "2025-11-05T06:59:46.565708Z"
    }
   },
   "source": "!pip install -q langchain langchain-openai python-dotenv",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.3\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Prosty chain: prompt → model → wynik",
   "id": "cd970036ab362bbd"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-11-05T06:59:48.147340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Jesteś ekspertem programowania w Pythonie i geniuszem w dziedzinie AI.\"),\n",
    "    (\"user\", \"Napisz kod związany z tematem {topic}\")\n",
    "])\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "result = chain.invoke({'topic': 'AGI'})\n"
   ],
   "id": "e5d97fe610b0504",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T06:56:48.115911Z",
     "start_time": "2025-11-05T06:56:48.112423Z"
    }
   },
   "cell_type": "code",
   "source": "print(result)",
   "id": "7c9889063b3f8268",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tworzenie sztucznej inteligencji ogólnej (AGI) to bardzo ambitne zadanie, które wykracza poza możliwości prostego kodu. AGI odnosi się do systemów AI, które mogą rozumieć, uczyć się i stosować wiedzę w różnych dziedzinach, podobnie jak człowiek. Niemniej jednak, mogę pokazać prosty przykład, który ilustruje podstawowe koncepcje związane z uczeniem maszynowym i przetwarzaniem języka naturalnego, które są kluczowe w rozwoju bardziej zaawansowanych systemów AI.\n",
      "\n",
      "Poniżej znajduje się przykład prostego modelu klasyfikacji tekstu przy użyciu biblioteki `scikit-learn` w Pythonie. Model ten może być użyty do klasyfikacji wiadomości e-mail jako \"spam\" lub \"nie spam\".\n",
      "\n",
      "### Przykład kodu: Klasyfikacja wiadomości e-mail\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.metrics import accuracy_score, classification_report\n",
      "\n",
      "# Przykładowe dane\n",
      "data = {\n",
      "    'text': [\n",
      "        'Win a million dollars now!',\n",
      "        'Important meeting tomorrow at 10 AM.',\n",
      "        'Congratulations! You have won a lottery.',\n",
      "        'Please find the attached report.',\n",
      "        'Get cheap loans now!',\n",
      "        'Let’s schedule a call next week.'\n",
      "    ],\n",
      "    'label': ['spam', 'ham', 'spam', 'ham', 'spam', 'ham']\n",
      "}\n",
      "\n",
      "# Tworzenie DataFrame\n",
      "df = pd.DataFrame(data)\n",
      "\n",
      "# Podział danych na zestaw treningowy i testowy\n",
      "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.2, random_state=42)\n",
      "\n",
      "# Przekształcanie tekstu na wektory\n",
      "vectorizer = CountVectorizer()\n",
      "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
      "X_test_vectorized = vectorizer.transform(X_test)\n",
      "\n",
      "# Tworzenie modelu klasyfikacji\n",
      "model = MultinomialNB()\n",
      "model.fit(X_train_vectorized, y_train)\n",
      "\n",
      "# Predykcja\n",
      "y_pred = model.predict(X_test_vectorized)\n",
      "\n",
      "# Ocena modelu\n",
      "accuracy = accuracy_score(y_test, y_pred)\n",
      "report = classification_report(y_test, y_pred)\n",
      "\n",
      "print(f'Accuracy: {accuracy:.2f}')\n",
      "print('Classification Report:')\n",
      "print(report)\n",
      "```\n",
      "\n",
      "### Opis kodu:\n",
      "1. **Dane**: Używamy prostego zestawu danych z wiadomościami e-mail, które są oznaczone jako \"spam\" lub \"ham\" (nie spam).\n",
      "2. **Podział danych**: Dzielimy dane na zestaw treningowy i testowy.\n",
      "3. **Wektoryzacja**: Używamy `CountVectorizer`, aby przekształcić tekst na wektory liczbowych cech.\n",
      "4. **Model**: Tworzymy model klasyfikacji przy użyciu algorytmu Naive Bayes.\n",
      "5. **Predykcja i ocena**: Model przewiduje etykiety dla zestawu testowego, a następnie oceniamy jego dokładność.\n",
      "\n",
      "### Uwaga:\n",
      "To jest bardzo podstawowy przykład i nie jest to AGI. AGI wymaga znacznie bardziej zaawansowanych algorytmów, architektur i danych. W rzeczywistości, AGI to temat badań, który wciąż jest w fazie rozwoju i wymaga znacznych postępów w wielu dziedzinach, takich jak uczenie się ze wzmocnieniem, przetwarzanie języka naturalnego, rozumienie kontekstu i wiele innych.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Sequential chain: dwa modele w sekwencji",
   "id": "2cac72131d772ec2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T06:56:52.022901Z",
     "start_time": "2025-11-05T06:56:48.185370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# 1) Chain: streszczenie (wejście: {text} → wyjście: str)\n",
    "summary_chain = (\n",
    "    ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"Streść poniższy tekst w 1–2 zdaniach po polsku.\"),\n",
    "        (\"user\", \"{text}\")\n",
    "    ])\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 2) Adapter: zamień str → {\"text\": str}, żeby podać do następnego promptu\n",
    "to_dict = RunnableLambda(lambda s: {\"text\": s})\n",
    "\n",
    "# 3) Chain: tłumaczenie streszczenia na francuski (wejście: {text} → wyjście: str)\n",
    "translate_chain = (\n",
    "    ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"Przetłumacz tekst na język francuski.\"),\n",
    "        (\"user\", \"{text}\")\n",
    "    ])\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "sequential_chain = summary_chain | to_dict | translate_chain\n",
    "input_text = \"LangChain umożliwia tworzenie aplikacji AI poprzez łączenie modeli, promptów i narzędzi w spójne pipeline’y.\"\n",
    "\n",
    "final_translation = sequential_chain.invoke({\"text\": input_text})\n",
    "\n",
    "print(final_translation)\n"
   ],
   "id": "92240f604a750d3e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain permet de créer des applications d'IA en intégrant des modèles, des invites et des outils dans des processus organisés.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Branching chain: jedna odpowiedź, dwa przetworzenia",
   "id": "256cc9e98cf0ddff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T06:56:54.425495Z",
     "start_time": "2025-11-05T06:56:52.077188Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "# Prompt do streszczenia\n",
    "prompt_summary = ChatPromptTemplate.from_template(\"Streść: {text}\")\n",
    "\n",
    "# Prompt do sentymentu\n",
    "prompt_sentiment = ChatPromptTemplate.from_template(\"Określ ton wypowiedzi: {text}\")\n",
    "\n",
    "branch_chain = RunnableParallel(\n",
    "    summary=(prompt_summary | llm | StrOutputParser()),\n",
    "    sentiment=(prompt_sentiment | llm | StrOutputParser())\n",
    ")\n",
    "\n",
    "text = \"Jestem bardzo zadowolony z tego kursu, nauczyłem się dużo o LangChain! Teraz wiem, że LangChain umożliwia tworzenie aplikacji AI poprzez łączenie modeli, promptów i narzędzi w spójne pipeline’y.\"\n",
    "result = branch_chain.invoke({\"text\": text})\n",
    "\n",
    "print(result)\n"
   ],
   "id": "783d3e92e71467ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'summary': 'Uczestnik kursu jest bardzo zadowolony i zdobył wiele wiedzy na temat LangChain.', 'sentiment': 'Ton wypowiedzi jest pozytywny i entuzjastyczny. Osoba wyraża zadowolenie z kursu oraz podkreśla, że zdobyła cenną wiedzę na temat LangChain.'}\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
