{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## LangChain chains",
   "id": "3548fe4a952ca65f"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-06T06:54:53.597821Z",
     "start_time": "2025-10-06T06:54:52.017991Z"
    }
   },
   "source": "!pip install -q langchain langchain-openai python-dotenv",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Prosty chain: prompt → model → wynik",
   "id": "cd970036ab362bbd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T07:01:09.135841Z",
     "start_time": "2025-10-06T07:00:47.297520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"jesteś ekspertem programowania w Pythonie i geniuszem w dziedzinie AI.\"),\n",
    "    (\"user\", \"napisz kod {topic}\")\n",
    "])\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "result = chain.invoke({'topic': 'AGI'})\n"
   ],
   "id": "e5d97fe610b0504",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T07:01:24.319921Z",
     "start_time": "2025-10-06T07:01:24.316641Z"
    }
   },
   "cell_type": "code",
   "source": "print(result)",
   "id": "7c9889063b3f8268",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tworzenie ogólnej inteligencji sztucznej (AGI) to niezwykle złożone i ambitne zadanie, które wykracza poza możliwości pojedynczego programu czy fragmentu kodu. AGI odnosi się do systemu, który potrafi uczyć się, rozumieć i stosować wiedzę w różnych dziedzinach, podobnie jak człowiek. Obecnie nie istnieje żaden powszechnie akceptowany model AGI, a badania w tej dziedzinie są wciąż w toku.\n",
      "\n",
      "Jednak mogę zaproponować prosty przykład kodu w Pythonie, który ilustruje podstawowe elementy uczenia maszynowego, które są częścią większego obrazu AGI. Poniżej znajduje się przykład prostego modelu uczenia maszynowego przy użyciu biblioteki `scikit-learn`, który klasyfikuje dane.\n",
      "\n",
      "```python\n",
      "import numpy as np\n",
      "from sklearn import datasets\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.metrics import accuracy_score\n",
      "\n",
      "# Wczytanie zbioru danych (np. Iris)\n",
      "iris = datasets.load_iris()\n",
      "X = iris.data\n",
      "y = iris.target\n",
      "\n",
      "# Podział danych na zbiór treningowy i testowy\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
      "\n",
      "# Utworzenie modelu klasyfikacji\n",
      "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
      "\n",
      "# Trenowanie modelu\n",
      "model.fit(X_train, y_train)\n",
      "\n",
      "# Predykcja na zbiorze testowym\n",
      "y_pred = model.predict(X_test)\n",
      "\n",
      "# Ocena modelu\n",
      "accuracy = accuracy_score(y_test, y_pred)\n",
      "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
      "```\n",
      "\n",
      "Ten kod wykonuje następujące kroki:\n",
      "1. Wczytuje zbiór danych Iris.\n",
      "2. Dzieli dane na zbiór treningowy i testowy.\n",
      "3. Tworzy model klasyfikacji przy użyciu lasu losowego.\n",
      "4. Trenuje model na zbiorze treningowym.\n",
      "5. Dokonuje predykcji na zbiorze testowym i ocenia dokładność modelu.\n",
      "\n",
      "Pamiętaj, że AGI wymaga znacznie bardziej zaawansowanych technik, takich jak uczenie się przez wzmocnienie, transfer learning, a także zrozumienie kontekstu i zdolności do rozwiązywania problemów w różnych dziedzinach. To, co przedstawiłem, to tylko bardzo podstawowy przykład uczenia maszynowego.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Sequential chain: dwa modele w sekwencji",
   "id": "2cac72131d772ec2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T07:04:37.608189Z",
     "start_time": "2025-10-06T07:04:33.692116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# 1) Chain: streszczenie (wejście: {tekst} → wyjście: str)\n",
    "summary_chain = (\n",
    "    ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"Streść poniższy tekst w 1–2 zdaniach po polsku.\"),\n",
    "        (\"user\", \"{tekst}\")\n",
    "    ])\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 2) Adapter: zamień str → {\"tekst\": str}, żeby podać do następnego promptu\n",
    "to_dict = RunnableLambda(lambda s: {\"tekst\": s})\n",
    "\n",
    "# 3) Chain: tłumaczenie streszczenia na francuski (wejście: {tekst} → wyjście: str)\n",
    "translate_chain = (\n",
    "    ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"Przetłumacz tekst na język francuski.\"),\n",
    "        (\"user\", \"{tekst}\")\n",
    "    ])\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "sequential_chain = summary_chain | to_dict | translate_chain\n",
    "input_text = \"LangChain umożliwia tworzenie aplikacji AI poprzez łączenie modeli, promptów i narzędzi w spójne pipeline’y.\"\n",
    "\n",
    "final_translation = sequential_chain.invoke({\"tekst\": input_text})\n",
    "\n",
    "print(final_translation)\n"
   ],
   "id": "92240f604a750d3e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain permet de créer des applications d'IA en intégrant des modèles, des invites et des outils dans des processus organisés.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Branching chain: jedna odpowiedź, dwa przetworzenia",
   "id": "256cc9e98cf0ddff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T07:06:33.689570Z",
     "start_time": "2025-10-06T07:06:29.839509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "# Prompt do streszczenia\n",
    "prompt_summary = ChatPromptTemplate.from_template(\"Streść: {tekst}\")\n",
    "\n",
    "# Prompt do sentymentu\n",
    "prompt_sentiment = ChatPromptTemplate.from_template(\"Określ ton wypowiedzi: {tekst}\")\n",
    "\n",
    "branch_chain = RunnableParallel(\n",
    "    summary=(prompt_summary | llm | StrOutputParser()),\n",
    "    sentiment=(prompt_sentiment | llm | StrOutputParser())\n",
    ")\n",
    "\n",
    "text = \"Jestem bardzo zadowolony z tego kursu, nauczyłem się dużo o LangChain!\"\n",
    "result = branch_chain.invoke({\"tekst\": text})\n",
    "\n",
    "print(result)\n"
   ],
   "id": "783d3e92e71467ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'summary': 'Uczestnik kursu wyraża swoje zadowolenie, podkreślając, że zdobył wiele wiedzy na temat LangChain.', 'sentiment': 'Ton wypowiedzi jest pozytywny i entuzjastyczny. Osoba wyraża zadowolenie z kursu oraz podkreśla, że zdobyła cenną wiedzę na temat LangChain.'}\n"
     ]
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
