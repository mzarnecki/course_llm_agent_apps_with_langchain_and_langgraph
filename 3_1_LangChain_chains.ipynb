{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## LangChain chains",
   "id": "3548fe4a952ca65f"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-12T05:34:02.138801Z",
     "start_time": "2025-09-12T05:33:59.845783Z"
    }
   },
   "source": "!pip install -q langchain langchain-openai python-dotenv",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Prosty chain: prompt → model → wynik",
   "id": "cd970036ab362bbd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T05:54:41.545606Z",
     "start_time": "2025-09-12T05:54:31.095380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"jesteś ekspertem programowania w Pythonie i geniuszem w dziedzinie AI.\"),\n",
    "    (\"user\", \"napisz kod {topic}\")\n",
    "])\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "result = chain.invoke({'topic': 'AGI'})\n",
    "\n",
    "print(result)"
   ],
   "id": "e5d97fe610b0504",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tworzenie prawdziwej sztucznej inteligencji ogólnej (AGI) to niezwykle złożone zadanie, które wykracza poza możliwości obecnych technologii i narzędzi. AGI odnosi się do systemów AI, które mogą rozumieć, uczyć się i stosować wiedzę w różnych dziedzinach, podobnie jak człowiek. Obecnie nie istnieje żaden kod, który mógłby być uznany za AGI.\n",
      "\n",
      "Jednak mogę pokazać ci prosty przykład, jak można zbudować system AI, który uczy się na podstawie danych. Poniżej znajduje się przykład prostego modelu uczenia maszynowego w Pythonie, który wykorzystuje bibliotekę `scikit-learn` do klasyfikacji danych.\n",
      "\n",
      "```python\n",
      "import numpy as np\n",
      "from sklearn import datasets\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.metrics import accuracy_score\n",
      "\n",
      "# Wczytanie zbioru danych (np. Iris)\n",
      "iris = datasets.load_iris()\n",
      "X = iris.data\n",
      "y = iris.target\n",
      "\n",
      "# Podział danych na zbiór treningowy i testowy\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
      "\n",
      "# Utworzenie modelu klasyfikacji\n",
      "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
      "\n",
      "# Trenowanie modelu\n",
      "model.fit(X_train, y_train)\n",
      "\n",
      "# Predykcja na zbiorze testowym\n",
      "y_pred = model.predict(X_test)\n",
      "\n",
      "# Ocena modelu\n",
      "accuracy = accuracy_score(y_test, y_pred)\n",
      "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
      "```\n",
      "\n",
      "Ten kod wykonuje następujące kroki:\n",
      "\n",
      "1. Wczytuje zbiór danych Iris.\n",
      "2. Dzieli dane na zbiór treningowy i testowy.\n",
      "3. Tworzy model klasyfikacji przy użyciu lasu losowego.\n",
      "4. Trenuje model na zbiorze treningowym.\n",
      "5. Dokonuje predykcji na zbiorze testowym.\n",
      "6. Oblicza dokładność modelu.\n",
      "\n",
      "Pamiętaj, że to tylko prosty przykład i nie ma nic wspólnego z AGI. AGI wymagałoby znacznie bardziej zaawansowanych algorytmów, architektur i podejść do nauki.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Sequential chain: dwa modele w sekwencji",
   "id": "2cac72131d772ec2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T05:57:55.195009Z",
     "start_time": "2025-09-12T05:57:52.160928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# 1) Chain: streszczenie (wejście: {tekst} → wyjście: str)\n",
    "summary_chain = (\n",
    "    ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"Streszcz poniższy tekst w 1–2 zdaniach po polsku.\"),\n",
    "        (\"user\", \"{tekst}\")\n",
    "    ])\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 2) Adapter: zamień str → {\"tekst\": str}, żeby podać do następnego promptu\n",
    "to_dict = RunnableLambda(lambda s: {\"tekst\": s})\n",
    "\n",
    "# 3) Chain: tłumaczenie streszczenia na francuski (wejście: {tekst} → wyjście: str)\n",
    "translate_chain = (\n",
    "    ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"Przetłumacz tekst na język francuski.\"),\n",
    "        (\"user\", \"{tekst}\")\n",
    "    ])\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 4) Prawdziwy sequential chain: summary → (wrap) → translate\n",
    "sequential_chain = summary_chain | to_dict | translate_chain\n",
    "\n",
    "# Test — jedno wywołanie całego łańcucha\n",
    "input_text = \"LangChain umożliwia tworzenie aplikacji AI poprzez łączenie modeli, promptów i narzędzi w spójne pipeline’y.\"\n",
    "final_translation = sequential_chain.invoke({\"tekst\": input_text})\n",
    "\n",
    "print(\"Tłumaczenie francuskie:\\n\", final_translation)\n",
    "\n"
   ],
   "id": "92240f604a750d3e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tłumaczenie francuskie:\n",
      " LangChain permet de créer des applications d'IA en intégrant des modèles, des invites et des outils dans des processus organisés.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Branching chain: jedna odpowiedź, dwa przetworzenia",
   "id": "256cc9e98cf0ddff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T05:57:57.516840Z",
     "start_time": "2025-09-12T05:57:56.126434Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "# Prompt do streszczenia\n",
    "prompt_summary = ChatPromptTemplate.from_template(\"Streszcz: {tekst}\")\n",
    "\n",
    "# Prompt do sentymentu\n",
    "prompt_sentiment = ChatPromptTemplate.from_template(\"Określ ton wypowiedzi: {tekst}\")\n",
    "\n",
    "# Dwa równoległe przetworzenia\n",
    "branch_chain = RunnableParallel(\n",
    "    summary=(prompt_summary | llm | StrOutputParser()),\n",
    "    sentiment=(prompt_sentiment | llm | StrOutputParser()),\n",
    ")\n",
    "\n",
    "text = \"Jestem bardzo zadowolony z tego kursu, nauczyłem się dużo o LangChain!\"\n",
    "result = branch_chain.invoke({\"tekst\": text})\n",
    "\n",
    "print(result)\n"
   ],
   "id": "783d3e92e71467ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'summary': 'Uczestnik kursu wyraża swoje zadowolenie, podkreślając, że zdobył wiele wiedzy na temat LangChain.', 'sentiment': 'Ton wypowiedzi jest pozytywny i entuzjastyczny. Osoba wyraża zadowolenie z kursu oraz podkreśla, że zdobyła cenną wiedzę na temat LangChain.'}\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Prosty RAG chain",
   "id": "5be3f300874a387f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T06:12:55.310983Z",
     "start_time": "2025-09-12T06:12:51.923628Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "docs = [\n",
    "    \"LangChain to framework do pracy z dużymi modelami językowymi.\",\n",
    "    \"Chains w LangChain to przepływy danych pomiędzy promptami, modelami i parserami.\",\n",
    "    \"Retriever pozwala wyszukiwać informacje w bazie wektorowej.\"\n",
    "]\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=50, chunk_overlap=10)\n",
    "splitted = splitter.split_text(\" \".join(docs))\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_texts(splitted, embedding=embeddings)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Odpowiedz tylko na podstawie KONTEKSTU:\\n{context}\"),\n",
    "    (\"user\", \"{question}\")\n",
    "])\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\".join(d.page_content for d in docs)\n",
    "\n",
    "runnable = RunnablePassthrough.assign(context=lambda x: x[\"question\"])\n",
    "\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": runnable | (lambda x: x[\"question\"]) | retriever | format_docs,\n",
    "        \"question\": lambda x: x[\"question\"]\n",
    "    }\n",
    "    | rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "response = rag_chain.invoke({\"question\" : \"Do czego służy biblioteka LangChain?\"})\n",
    "\n",
    "print(response)\n"
   ],
   "id": "f2ce769dc1b24e18",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biblioteka LangChain służy do pracy z dużymi modelami językowymi, umożliwiając tworzenie przepływów danych pomiędzy promptami, modelami i parserami. Dodatkowo, LangChain pozwala na wyszukiwanie informacji w bazie wektorowej.\n"
     ]
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
