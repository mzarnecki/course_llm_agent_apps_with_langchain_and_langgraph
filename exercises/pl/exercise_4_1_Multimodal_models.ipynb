{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2a99545",
   "metadata": {},
   "source": [
    "## Zadania: Modele Multimodalne\n",
    "\n",
    "Przykłady przetwarzania obrazu przez model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db54cec1",
   "metadata": {},
   "source": [
    "Zadanie 1 \\\n",
    "Wczytaj dowolny obraz z dysku (np. `sample.jpg`) i poproś model o opis w 1–2 zdaniach."
   ]
  },
  {
   "cell_type": "code",
   "id": "f73d354b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T18:36:20.799344Z",
     "start_time": "2025-11-10T18:36:14.318460Z"
    }
   },
   "source": [
    "# TODO: Wczytaj obraz i zbuduj wiadomość dla modelu multimodalnego\n",
    "# HINT: Możesz zaczytać obrazek i przekazać jako data URL lub file-URI (w zależności od klienta).\n",
    "from base64 import b64encode\n",
    "from pathlib import Path\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "img_path = Path(\"../../data/img/airport.jpg\")  # <- podmień na własną ścieżkę\n",
    "if img_path.exists():\n",
    "    client = OpenAI()\n",
    "    data = b64encode(img_path.read_bytes()).decode(\"utf-8\")\n",
    "    resp = client.responses.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        input=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"input_text\", \"text\": (\"Opisz co jest na obrazku w 1–2 zdaniach po polsku.\")},\n",
    "                {\"type\": \"input_image\", \"image_url\": f\"data:image/jpeg;base64,{data}\"}\n",
    "            ],\n",
    "        }],\n",
    "    )\n",
    "\n",
    "    response = resp.output_text\n",
    "    print(\"Odpowiedź modelu:\", response)\n",
    "else:\n",
    "    print(\"Brak pliku – wstaw własny obraz i uruchom ponownie.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model decision: Na obrazku widać ludzi poruszających się w przestrzeni lotniska, przechodzących wzdłuż dużych okien. Silhouetty pasażerów z bagażami kontrastują z jasnym tłem.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "0cae15f9",
   "metadata": {},
   "source": [
    "Zadanie 2 \\\n",
    "Łączenie modalności – obraz + pytanie \\\n",
    "Podaj pytanie o wybrany fragment obrazka (np. „Ile jest osób?”) i poproś model o krótką odpowiedź."
   ]
  },
  {
   "cell_type": "code",
   "id": "3590f6a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T18:43:26.468839Z",
     "start_time": "2025-11-10T18:43:23.464335Z"
    }
   },
   "source": [
    "# TODO: Zastosuj podobny schemat jak w Zadaniu 1, ale dodaj pytanie użytkownika.\n",
    "# Wskazówka: połącz komunikat tekstowy z obrazem i przekaż jako wejście do modelu.\n",
    "from base64 import b64encode\n",
    "from pathlib import Path\n",
    "from openai import OpenAI\n",
    "\n",
    "img_path = Path(\"../../data/img/airport.jpg\")  # <- podmień na własną ścieżkę\n",
    "question = \"Ile osób znajduje się na zdjęciu?\"\n",
    "\n",
    "if img_path.exists():\n",
    "    data = b64encode(img_path.read_bytes()).decode(\"utf-8\")\n",
    "    content = [\n",
    "        {\"type\": \"input_text\", \"text\": f\"Odpowiedz krótko po polsku: ____\"}, # <- wstaw question\n",
    "        {\"type\": \"input_image\", \"image_url\": f\"data:image/jpeg;base64,____\"} # <- wstaw data\n",
    "    ]\n",
    "    client = OpenAI()\n",
    "    resp = client.responses.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        input=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": content\n",
    "        }])\n",
    "\n",
    "    print(resp.output_text)\n",
    "else:\n",
    "    print(\"Brak pliku – wstaw własny obraz i uruchom ponownie.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nie wiem, ile osób znajduje się na zdjęciu.\n"
     ]
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
