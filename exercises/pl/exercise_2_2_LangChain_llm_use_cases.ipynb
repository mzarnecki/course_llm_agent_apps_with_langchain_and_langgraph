{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Zadania: LangChain Hello World i rodzaje zadań realizowanych z wykorzystaniem LLM",
   "id": "4c85647bfca48639"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Instalacja bibliotek",
   "id": "33865d142d2b4369"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T15:15:48.883767Z",
     "start_time": "2025-11-11T15:15:47.232394Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install langchain-openai python-dotenv",
   "id": "2999805064e37d83",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-openai in /home/michal/anaconda3/lib/python3.13/site-packages (1.0.2)\r\n",
      "Requirement already satisfied: python-dotenv in /home/michal/anaconda3/lib/python3.13/site-packages (1.1.1)\r\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.2 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-openai) (1.0.4)\r\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-openai) (2.7.1)\r\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-openai) (0.11.0)\r\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (1.33)\r\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (0.4.42)\r\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (24.2)\r\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (2.11.10)\r\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (6.0.2)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (9.0.0)\r\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (4.15.0)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/michal/anaconda3/lib/python3.13/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.2->langchain-openai) (3.0.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai) (0.28.1)\r\n",
      "Requirement already satisfied: orjson>=3.9.14 in /home/michal/anaconda3/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai) (3.10.14)\r\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai) (1.0.0)\r\n",
      "Requirement already satisfied: requests>=2.0.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai) (2.32.5)\r\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai) (0.23.0)\r\n",
      "Requirement already satisfied: anyio in /home/michal/.local/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai) (4.10.0)\r\n",
      "Requirement already satisfied: certifi in /home/michal/anaconda3/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai) (2025.8.3)\r\n",
      "Requirement already satisfied: httpcore==1.* in /home/michal/.local/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai) (1.0.9)\r\n",
      "Requirement already satisfied: idna in /home/michal/anaconda3/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai) (3.7)\r\n",
      "Requirement already satisfied: h11>=0.16 in /home/michal/.local/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai) (0.16.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\r\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.10.0)\r\n",
      "Requirement already satisfied: sniffio in /home/michal/.local/lib/python3.13/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\r\n",
      "Requirement already satisfied: tqdm>4 in /home/michal/anaconda3/lib/python3.13/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.2->langchain-openai) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/michal/anaconda3/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.2->langchain-openai) (2.33.2)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.2->langchain-openai) (0.4.0)\r\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/michal/anaconda3/lib/python3.13/site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.11.6)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/michal/anaconda3/lib/python3.13/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai) (3.3.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/michal/anaconda3/lib/python3.13/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai) (2.5.0)\r\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Zadanie 1\n",
    "Generowanie tekstu\n",
    "1. Uruchom łańcuch (`chain`) dla 3 różnych zapytań i porównaj długość oraz strukturę odpowiedzi.\n",
    "2. Dodaj prosty pomiar czasu wykonania (time.perf_counter) i wypisz wyniki.\n",
    "3. Zaimplementuj funkcję pomocniczą `run_query(text: str) -> str`, która wywoła łańcuch i zwraca sam tekst odpowiedzi."
   ],
   "id": "ca905aa533c89caf"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-11T15:15:50.741202Z",
     "start_time": "2025-11-11T15:15:48.899462Z"
    }
   },
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# pobranie klucza OpenAI\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"Brak klucza API w pliku .env!\")\n",
    "\n",
    "# utworzenie klienta API OpenAI z wybranym modelem\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, api_key=api_key)\n",
    "\n",
    "# prosty prompt i request do API LLM\n",
    "response = llm.invoke(\"Napisz krótkie pozdrowienie w języku polskim.\")\n",
    "\n",
    "print(\"Odpowiedź modelu:\\n\")\n",
    "print(response.content)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odpowiedź modelu:\n",
      "\n",
      "Cześć! Mam nadzieję, że masz wspaniały dzień! Pozdrawiam serdecznie!\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Zadanie 2\n",
    "Generowanie tekstu\n",
    "Uruchom łańcuch (`chain`) dla 2 różnych zapytań i porównaj długość oraz strukturę odpowiedzi."
   ],
   "id": "1124603ed27c0a9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T15:16:12.451477Z",
     "start_time": "2025-11-11T15:15:50.797801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = llm.invoke(\"Wygeneruj przepis na słodki sernik z tuńczykiem, brokułem i cebulą.\")\n",
    "\n",
    "print(\"Odpowiedź modelu:\\n\")\n",
    "print(response.content)"
   ],
   "id": "4bcecd4b93ac98f1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odpowiedź modelu:\n",
      "\n",
      "Oto przepis na nietypowy, słodki sernik z tuńczykiem, brokułem i cebulą. To połączenie smaków może być zaskakujące, ale spróbujmy!\n",
      "\n",
      "### Słodki sernik z tuńczykiem, brokułem i cebulą\n",
      "\n",
      "#### Składniki:\n",
      "\n",
      "**Na spód:**\n",
      "- 200 g herbatników (np. digestive)\n",
      "- 100 g masła\n",
      "\n",
      "**Na masę serową:**\n",
      "- 500 g twarogu (najlepiej zmielonego)\n",
      "- 200 g serka mascarpone\n",
      "- 3 jajka\n",
      "- 100 g cukru (można dostosować do smaku)\n",
      "- 1 łyżeczka ekstraktu waniliowego\n",
      "- 1 puszka tuńczyka w sosie własnym (odcedzonego)\n",
      "- 200 g brokułów (ugotowanych na parze i drobno posiekanych)\n",
      "- 1 mała cebula (drobno posiekana i podsmażona na złoto)\n",
      "- Szczypta soli\n",
      "- Szczypta pieprzu\n",
      "\n",
      "**Na wierzch:**\n",
      "- 100 g śmietany kremówki\n",
      "- 2 łyżki cukru pudru\n",
      "- Owoce do dekoracji (np. maliny, borówki)\n",
      "\n",
      "#### Przygotowanie:\n",
      "\n",
      "1. **Przygotowanie spodu:**\n",
      "   - Rozgrzej piekarnik do 180°C.\n",
      "   - Herbatniki pokrusz na drobno (możesz użyć blendera).\n",
      "   - Roztop masło i wymieszaj z pokruszonymi herbatnikami.\n",
      "   - Wyłóż dno tortownicy (o średnicy 24 cm) papierem do pieczenia i wciśnij mieszankę herbatnikową, tworząc równą warstwę. Piecz przez 10 minut, a następnie odstaw do ostygnięcia.\n",
      "\n",
      "2. **Przygotowanie masy serowej:**\n",
      "   - W dużej misce połącz twaróg, serek mascarpone, jajka, cukier i ekstrakt waniliowy. Miksuj do uzyskania gładkiej konsystencji.\n",
      "   - Dodaj odcedzonego tuńczyka, posiekane brokuły, podsmażoną cebulę, sól i pieprz. Delikatnie wymieszaj, aby składniki się połączyły.\n",
      "\n",
      "3. **Pieczenie:**\n",
      "   - Wylej masę serową na przygotowany spód z herbatników.\n",
      "   - Piecz w piekarniku przez około 50-60 minut, aż sernik będzie ścięty, ale wciąż lekko sprężysty w środku.\n",
      "   - Po upieczeniu wyłącz piekarnik i pozostaw sernik w środku na kolejne 30 minut, aby stopniowo ostygł.\n",
      "\n",
      "4. **Przygotowanie wierzchu:**\n",
      "   - Ubij śmietanę kremówkę z cukrem pudrem na sztywno.\n",
      "   - Po ostudzeniu sernika, nałóż ubitą śmietanę na wierzch i udekoruj owocami.\n",
      "\n",
      "5. **Podanie:**\n",
      "   - Sernik najlepiej smakuje schłodzony. Wstaw go do lodówki na kilka godzin przed podaniem.\n",
      "\n",
      "Smacznego! To nietypowe połączenie smaków z pewnością zaskoczy Twoich gości!\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Zadanie 3\n",
    "Klasyfikacja\n",
    "Zmodyfikuj teksty oraz prompt w poniższym kodzie tak aby klasyfikować sentyment tekstu (pozytywny, negatywny, neutralny). W przykładach umieść teksty o różnym sentymencie.\n",
    "```\n",
    "[\n",
    "    \"This product is amazing! I loved it.\",\n",
    "    \"I am very disappointed. The product broke after one use.\",\n",
    "    \"It's okay, does the job but nothing special.\"\n",
    "]\n",
    "```"
   ],
   "id": "f5ee48d932b337f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T15:17:21.982967Z",
     "start_time": "2025-11-11T15:17:17.960043Z"
    }
   },
   "cell_type": "code",
   "source": [
    "articles = [\n",
    "    \"The government announced new tax reforms today.\",\n",
    "    \"The local team won the championship in a thrilling match.\",\n",
    "    \"New advancements in AI are reshaping the tech industry.\",\n",
    "    \"The art exhibit showcased contemporary works by emerging artists.\",\n",
    "    \"New guidelines for a healthy diet were published by the health department.\"\n",
    "]\n",
    "response = llm.invoke('Sklasyfikuj załączone teksty do grup \"Polityka\", \"Sport\", \"Technologia\", \"Kultura\", \"Zdrowie\".\\n\\n' + '\\n'.join(articles))\n",
    "\n",
    "print(\"Odpowiedź modelu:\\n\")\n",
    "print(response.content)"
   ],
   "id": "29165f1f81b5a7b9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odpowiedź modelu:\n",
      "\n",
      "Oto klasyfikacja załączonych tekstów:\n",
      "\n",
      "1. **Polityka**: The government announced new tax reforms today.\n",
      "2. **Sport**: The local team won the championship in a thrilling match.\n",
      "3. **Technologia**: New advancements in AI are reshaping the tech industry.\n",
      "4. **Kultura**: The art exhibit showcased contemporary works by emerging artists.\n",
      "5. **Zdrowie**: New guidelines for a healthy diet were published by the health department.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Zadanie 4\n",
    "Analiza dokumentu\n",
    "Uruchom łańcuch dla 3 różnych promptów:\n",
    "1. Dla jakich lat wartości są prezentowane w raporcie?\n",
    "2. Jaka jest wartość \"Netto-Cashflow\" w 2019?\n",
    "3. Znajdź informacje na temat rocznego przychodu firmy."
   ],
   "id": "cfe6391cfa987531"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T15:16:44.902868Z",
     "start_time": "2025-11-11T15:16:14.821725Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file = open(\"../../data/annual_report.html\", \"r\")\n",
    "document = file.read()\n",
    "response = llm.invoke(f\"Przeanalizuj załaczony dokument ____ \\n\\n {document}\")\n",
    "print(\"Odpowiedź modelu:\\n\")\n",
    "print(response.content)"
   ],
   "id": "5ecaf0f4709cf23",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odpowiedź modelu:\n",
      "\n",
      "Dokument, które przesłałeś, to tabela przedstawiająca wyniki finansowe oraz dane operacyjne firmy za lata 2018 i 2019. Poniżej znajduje się analiza kluczowych informacji zawartych w tabeli:\n",
      "\n",
      "### 1. **Produkcja**\n",
      "- **Segment Automobile**: W 2019 roku wyprodukowano 1.802.073 samochodów, co oznacza spadek o 3,7% w porównaniu do 2018 roku (1.871.386).\n",
      "- **Motoren**: Wzrost produkcji z 1.955.532 do 1.969.731, co daje wzrost o 0,7%.\n",
      "- **Segment Motorräder**: Spadek produkcji z 53.320 do 51.723, co oznacza spadek o 3,0%.\n",
      "\n",
      "### 2. **Auslieferungen an Kunden (Dostawy do klientów)**\n",
      "- **Segment Automobile**: Spadek dostaw z 2.081.418 do 1.853.833, co daje spadek o 10,9%.\n",
      "- **Marka Audi**: Wzrost dostaw z 1.812.485 do 1.845.573, co oznacza wzrost o 1,8%.\n",
      "- **Marka Lamborghini**: Znaczący wzrost dostaw z 5.750 do 8.205, co daje wzrost o 42,7%.\n",
      "- **Segment Motorräder (Marka Ducati)**: Niewielki wzrost z 53.004 do 53.183, co oznacza wzrost o 0,3%.\n",
      "\n",
      "### 3. **Belegschaft (Zatrudnienie)**\n",
      "- Średnia liczba pracowników spadła z 91.477 do 90.783, co oznacza spadek o 0,8%.\n",
      "\n",
      "### 4. **Umsatzerlöse (Przychody)**\n",
      "- Przychody spadły z 59.248 mln EUR do 55.680 mln EUR, co daje spadek o 6,0%.\n",
      "\n",
      "### 5. **Operatives Ergebnis (Wynik operacyjny)**\n",
      "- **Operatives Ergebnis przed Sondereinflüssen**: Spadek z 4.705 mln EUR do 4.509 mln EUR (-4,2%).\n",
      "- **Operatives Ergebnis**: Wzrost z 3.529 mln EUR do 4.509 mln EUR (27,8%).\n",
      "\n",
      "### 6. **Wyniki finansowe**\n",
      "- **Ergebnis vor Steuern (Wynik przed opodatkowaniem)**: Wzrost z 4.361 mln EUR do 5.223 mln EUR (19,8%).\n",
      "- **Ergebnis nach Steuern (Wynik po opodatkowaniu)**: Wzrost z 3.463 mln EUR do 3.943 mln EUR (13,9%).\n",
      "\n",
      "### 7. **Wskaźniki rentowności**\n",
      "- **Operative Umsatzrendite**: Wzrost z 6,0% do 8,1%.\n",
      "- **Kapitalrendite (RoI)**: Wzrost z 10,0% do 12,7%.\n",
      "- **Umsatzrendite vor Steuern**: Wzrost z 7,4% do 9,4%.\n",
      "\n",
      "### 8. **Inwestycje i badania**\n",
      "- **Sachinvestitionsquote**: Spadek z 5,9% do 4,9%.\n",
      "- **Forschungs- und Entwicklungskostenquote**: Wzrost z 7,1% do 7,9%.\n",
      "\n",
      "### 9. **Cashflow**\n",
      "- **Cashflow z działalności operacyjnej**: Wzrost z 7.013 mln EUR do 7.479 mln EUR (6,7%).\n",
      "- **Netto-Cashflow**: Wzrost z 2.141 mln EUR do 3.160 mln EUR (47,6%).\n",
      "\n",
      "### 10. **Bilans**\n",
      "- **Bilanzsumme (Suma bilansowa)**: Wzrost z 65.598 mln EUR do 66.878 mln EUR (2,0%).\n",
      "- **Eigenkapitalquote (Wskaźnik kapitału własnego)**: Spadek z 45,3% do 42,5%.\n",
      "\n",
      "### **Podsumowanie**\n",
      "Dokument wskazuje na mieszane wyniki finansowe firmy. Chociaż przychody i produkcja w segmencie samochodów spadły, to jednak wyniki operacyjne i zyski przed opodatkowaniem wzrosły. Wzrost dostaw w przypadku marki Lamborghini oraz stabilny wzrost w segmencie Ducati mogą sugerować pozytywne trendy w tych segmentach. Spadek zatrudnienia oraz przychodów może budzić pewne obawy, ale wzrost rentowności i cashflow wskazuje na poprawę efektywności operacyjnej.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Zadanie 5\n",
    "Tłumaczenia maszynowe\n",
    "Uruchom łańcuch (`chain`) dla 3 różnych zapytań tłumacząc teksty w różnych językach.\n",
    "Czy wykorzystany model zna język Swahili?"
   ],
   "id": "f80dd7cc21e40740"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T15:18:24.345566Z",
     "start_time": "2025-11-11T15:18:22.795968Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = llm.invoke(\"Przetłumacz poniższy tekst na język polski:\\n I'm foreigner and I don't speak german fluently.\")\n",
    "\n",
    "print(\"Odpowiedź modelu:\\n\")\n",
    "print(response.content)"
   ],
   "id": "817c691daa758421",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odpowiedź modelu:\n",
      "\n",
      "Jina langu ni mgeni na siwezi kuzungumza Kijerumani kwa ufasaha.\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Zadanie 6\n",
    "Question answering\n",
    "Wstaw pytanie dotyczace informacji w przekazanym promptcie"
   ],
   "id": "97c5e19db3285a8a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T15:16:46.858773Z",
     "start_time": "2025-11-11T15:16:45.890803Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = llm.invoke(\"Odpowiedz na poniżesze pytania w oparciu o załaczony tekst:\\n\"\n",
    "\"LangChain to framework do pracy z dużymi modelami językowymi.\\n\"\n",
    "\"Chains w LangChain to przepływy danych pomiędzy promptami, modelami i parserami.\\n\"\n",
    "\"Retriever pozwala wyszukiwać informacje w bazie wektorowej.\\n\"\n",
    "\"____\") # <- Wstaw pytanie dotyczace informacji w przekazanym promptcie np. Czym jest LangChain?\n",
    "\n",
    "print(\"Odpowiedź modelu:\\n\")\n",
    "print(response.content)"
   ],
   "id": "189b2679404bf9c5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odpowiedź modelu:\n",
      "\n",
      "Chains w LangChain służą do tworzenia przepływów danych pomiędzy promptami, modelami i parserami.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Zadanie 7\n",
    "Sumaryzacja\n",
    "1. Dodaj własny dokument z tekstem w folderze \"../../data/\" lub innej wybranej lokalizacji.\n",
    "2. Podmień ścieżkę do pliku w ponizszym kodzie.\n",
    "3. Dodaj limit słów w promptcie i wygeneruj podsumowanie załączonego pliku."
   ],
   "id": "6c12729c6b0a3c77"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T15:17:06.213192Z",
     "start_time": "2025-11-11T15:16:46.913870Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file = open(\"../../data/nad_niemnem.txt\", \"r\") # <- tu podmień ścieżkę do pliku\n",
    "document = file.read()\n",
    "response = llm.invoke(f\"Napisz krótkie podsumowanie (ok. 500 słów) załączonego tekstu.\\n{document[:1800]}\")\n",
    "\n",
    "print(\"Odpowiedź modelu:\\n\")\n",
    "print(response.content)"
   ],
   "id": "82e5c070f2c9b660",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odpowiedź modelu:\n",
      "\n",
      "„Nad Niemnem” Elizy Orzeszkowej to powieść, która wprowadza czytelnika w malowniczy świat letniego krajobrazu nad rzeką Niemen. Opis dnia, w którym rozgrywa się akcja, jest pełen radości i harmonii z naturą. Orzeszkowa w mistrzowski sposób przedstawia piękno otaczającej przyrody, która tętni życiem i emanuje pozytywną energią. W powietrzu unosi się zapach kwiatów, a śpiew ptaków i owadów tworzy symfonię dźwięków, która podkreśla letnią atmosferę.\n",
      "\n",
      "W opisie krajobrazu autorka zwraca uwagę na kontrasty między wzgórzami a doliną, gdzie wznoszą się gaje i borki, a także na brzeg rzeki, który majestatycznie wyrasta z zieleni. Obraz dworków i siedlisk ludzkich, które harmonijnie wpisują się w ten pejzaż, tworzy wrażenie spokoju i sielanki. Orzeszkowa maluje obraz życia wiejskiego, w którym ludzie żyją w zgodzie z naturą, a ich domy są otoczone ogrodami i polami.\n",
      "\n",
      "W powieści pojawia się również motyw drogi, która przerzyna równinę, symbolizując nie tylko fizyczne połączenie miejsc, ale także relacje międzyludzkie i różnorodność życia społecznego. Drogi, porośnięte trawą i kwiatami, stają się metaforą życia, które jest pełne zakrętów i niespodzianek. Orzeszkowa ukazuje, jak bliskość natury wpływa na codzienność mieszkańców, którzy czerpią radość z prostych przyjemności, takich jak spacer po polach czy obserwowanie zmieniającego się krajobrazu.\n",
      "\n",
      "Warto zauważyć, że w opisie przyrody Orzeszkowa nie tylko maluje piękne obrazy, ale także wprowadza elementy refleksji nad życiem i jego ulotnością. Letni dzień, pełen słońca i radości, staje się tłem dla rozważań o ludzkich losach, relacjach i wartościach. Autorka zdaje się sugerować, że harmonia z naturą jest kluczem do szczęścia, a życie w zgodzie z otaczającym światem przynosi spełnienie.\n",
      "\n",
      "Powieść „Nad Niemnem” to nie tylko opis przyrody, ale także głęboka analiza społeczna i psychologiczna. Orzeszkowa wprowadza postacie, które będą musiały zmierzyć się z wyzwaniami życia, a ich losy będą się splatały z pięknem i surowością natury. W ten sposób autorka tworzy bogaty i wielowarstwowy obraz życia, w którym przyroda odgrywa kluczową rolę.\n",
      "\n",
      "Podsumowując, „Nad Niemnem” to utwór, który zachwyca nie tylko opisami malowniczych krajobrazów, ale także głębokimi refleksjami na temat życia, relacji międzyludzkich i harmonii z naturą. Orzeszkowa w mistrzowski sposób łączy te elementy, tworząc dzieło, które pozostaje aktualne i inspirujące dla kolejnych pokoleń czytelników.\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
