{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a691cf5",
   "metadata": {},
   "source": [
    "## Zadania: Ewaluacja - porównanie łańcuchów tekstowych\n",
    "\n",
    "**Temat:** BLEU, ROUGE, METEOR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0709af",
   "metadata": {},
   "source": "## Zadanie 1 - BLEU"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ac1427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "reference = [\"to\",\"jest\",\"krótka\",\"odpowiedź\"]      # TODO: ewentualnie zmień\n",
    "candidate = [\"to\",\"jest\",\"krótka\",\"odpowiedz\"]      # TODO: ewentualnie zmień\n",
    "\n",
    "weights = (1.0, 0.0, 0.0, 0.0)                      # TODO: BLEU-1\n",
    "score = sentence_bleu([reference], candidate, weights=weights, smoothing_function=SmoothingFunction().method1)\n",
    "print(\"BLEU-1:\", round(score, 4))\n",
    "assert 0.0 <= score <= 1.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8213ce02",
   "metadata": {},
   "source": "## Zadanie 2 - ROUGE-L (rouge-score)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497ea63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install rouge-score\n",
    "from rouge_score import rouge_scorer\n",
    "ref = \"To jest prosty przykład metryki ROUGE.\"\n",
    "pred = \"To jest przykład bardzo prostego ROUGE.\"\n",
    "scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)  # TODO: zmień jeśli chcesz\n",
    "scores = scorer.score(ref, pred)\n",
    "print(\"ROUGE-L F1:\", round(scores[\"rougeL\"].fmeasure, 4))\n",
    "assert 0.0 <= scores[\"rougeL\"].fmeasure <= 1.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eff6c80",
   "metadata": {},
   "source": "## Zadanie 3 - METEOR"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e1759e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install nltk\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "ref = \"Szybki brązowy lis przeskakuje nad leniwym psem\"\n",
    "cand = \"Brązowy lis szybko skacze nad leniwym psem\"\n",
    "meteor = meteor_score([ref], cand)  # TODO: uzupełnij poprawnie listę referencji\n",
    "print(\"METEOR:\", round(meteor, 4))\n",
    "assert 0.0 <= meteor <= 1.0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
