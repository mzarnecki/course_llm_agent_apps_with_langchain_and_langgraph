{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be304df0c16cc932",
   "metadata": {},
   "source": "## LangChain components"
  },
  {
   "cell_type": "markdown",
   "id": "a4b1b26363bfed05",
   "metadata": {},
   "source": "### Install libraries"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-03T07:16:27.071158Z",
     "start_time": "2025-11-03T07:16:25.520077Z"
    }
   },
   "source": [
    "!pip install -q python-dotenv langchain langchain-openai langchain-community"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.3\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "20734714333be78c",
   "metadata": {},
   "source": "### Configure .env and model"
  },
  {
   "cell_type": "code",
   "id": "fd2b0cdbcb177adb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T07:16:30.503104Z",
     "start_time": "2025-11-03T07:16:27.076735Z"
    }
   },
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "b934756513189fe8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T07:16:32.018689Z",
     "start_time": "2025-11-03T07:16:30.606759Z"
    }
   },
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You're a helpful assistant. Keep your answers concise.\"),\n",
    "    (\"user\", \"Summarize in 1 sentence: {text}\")\n",
    "])\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()  # LCEL: prompt → model → parser\n",
    "result = chain.invoke({\"text\": \"LangChain is a library created in 2022, just as the world was beginning to discover the practical possibilities of large language models like GPT-5. Its creators noticed that most LLM-based projects repeated similar patterns – for example, combining prompts into sequences, storing conversation context, querying databases and search engines. Instead of building all this from scratch, they created a library that provides ready-made building blocks for assembling applications. Thanks to LangChain, we can quickly create prototypes and then develop them towards production. The library has become a standard in the world of AI developers because it allows for easy integration of models from different vendors – not only OpenAI, but also Anthropic, HuggingFace, and local open-source models.\"})\n",
    "print(result)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is a 2022 library that streamlines the development of applications using large language models by providing reusable building blocks for common tasks, facilitating rapid prototyping and integration with various AI models.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "9f0f36cc0a222968",
   "metadata": {},
   "source": [
    "### Prompt template\n",
    "LangChain's ChatPromptTemplate is a template for building structured prompts for chat models. It allows you to define roles (system, user, assistant), variables, and message formats to generate LLM prompts in a consistent and reusable manner."
   ]
  },
  {
   "cell_type": "code",
   "id": "58d640276960a0c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T07:16:33.728612Z",
     "start_time": "2025-11-03T07:16:32.071087Z"
    }
   },
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-4o\")\n",
    "template = \"\"\"\n",
    "Specify tags and the main topic of the text.\n",
    "tags: What are best tags describing text. Give maximum 5 tags separated by comma.\n",
    "topic: What is the topic of text. Use maximum couple of words\n",
    "\n",
    "Format response as JSON as below. Return only JSON without markdown tags.\n",
    "'tags': ['sometag', 'othertag', 'anothertag', 'tag4', 'tag5']\n",
    "'subject': 'Some subject of text'\n",
    "\n",
    "text: {input}\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(template=template)\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "chain.invoke({\"input\":\"They picked a way among the trees, and their ponies plodded along, carefully avoiding the many writhing and interlacing roots.  There was no undergrowth.  The ground was rising steadily, and as they went forward it seemed that the trees became taller, darker, and thicker. There was no sound, except an occasional drip of moisture falling through the still leaves.  For the moment there was no whispering or movement among the branches; but they all got an uncomfortable feeling that they were being watched with disapproval, deepening to dislike and even enmity.  The feeling steadily grew, until they found themselves looking up quickly, or glancing back over their shoulders, as if they expected a sudden blow.\"})"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{\\n    'tags': ['forest', 'suspense', 'nature', 'mystery', 'adventure'],\\n    'subject': 'forest journey'\\n}\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "c7e817465b616462",
   "metadata": {},
   "source": [
    "### ResponseSchema and OutputParser\n",
    "LangChain's ResponseSchema defines the expected response format (e.g., JSON fields with name, type, and description) and helps the model return data in a predictable structure.\n",
    "\n",
    "The OutputParser interprets the raw LLM response and transforms it into the desired form (e.g., Pydantic object, JSON, list), facilitating further use within the application."
   ]
  },
  {
   "cell_type": "code",
   "id": "765ef2a9b758f243",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T07:21:21.684072Z",
     "start_time": "2025-11-03T07:21:20.935657Z"
    }
   },
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class TextAnalysis(BaseModel):\n",
    "    tags: List[str] = Field(description=\"What are best tags describing text. Give maximum 5 tags separated by comma.\")\n",
    "    topic: str = Field(description=\"What is the topic of text. Use maximum couple of words.\")\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=TextAnalysis)\n",
    "instructions = parser.get_format_instructions()\n",
    "\n",
    "template = \"\"\"\n",
    "Specify tags and the main topic of the text. Return only JSON without markdown tags.\n",
    "tags: What are best tags describing text. Give maximum 5 tags separated by comma.\n",
    "topic: What is the topic of text. Use maximum couple of words\n",
    "\n",
    "Format response as JSON as below:\n",
    "'tags': ['sometag', 'othertag', 'anothertag', 'tag4', 'tag5']\n",
    "'subject': 'Some subject of text'\n",
    "\n",
    "text: {input}\n",
    "\n",
    "{instructions}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template=template)\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.0)\n",
    "chain = prompt | llm | parser\n",
    "output_dict = chain.invoke({\n",
    "    \"input\":\"They picked a way among the trees, and their ponies plodded along, carefully avoiding the many writhing and interlacing roots.  There was no undergrowth.  The ground was rising steadily, and as they went forward it seemed that the trees became taller, darker, and thicker. There was no sound, except an occasional drip of moisture falling through the still leaves.  For the moment there was no whispering or movement among the branches; but they all got an uncomfortable feeling that they were being watched with disapproval, deepening to dislike and even enmity.  The feeling steadily grew, until they found themselves looking up quickly, or glancing back over their shoulders, as if they expected a sudden blow.\",\n",
    "    \"instructions\":instructions})\n",
    "print(output_dict)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tags': ['forest', 'mystery', 'nature', 'ominous', 'adventure'], 'topic': 'Exploring a mysterious forest'}\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
