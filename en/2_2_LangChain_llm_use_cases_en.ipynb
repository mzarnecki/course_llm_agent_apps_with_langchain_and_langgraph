{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c85647bfca48639",
   "metadata": {},
   "source": [
    "## LangChain Hello World and types of tasks performed with LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfb04be88376bce",
   "metadata": {},
   "source": "### Instal libraries"
  },
  {
   "cell_type": "code",
   "id": "2999805064e37d83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T07:12:13.047843Z",
     "start_time": "2025-11-03T07:12:11.374566Z"
    }
   },
   "source": [
    "# before running the notebook, make sure you have Anaconda installed: https://www.anaconda.com/docs/getting-started/anaconda/install\n",
    "# install required packages (only once)\n",
    "!pip install langchain-openai python-dotenv"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-openai in /home/michal/anaconda3/lib/python3.13/site-packages (1.0.1)\r\n",
      "Requirement already satisfied: python-dotenv in /home/michal/anaconda3/lib/python3.13/site-packages (1.1.0)\r\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-openai) (1.0.0)\r\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-openai) (2.5.0)\r\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-openai) (0.11.0)\r\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-openai) (1.33)\r\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-openai) (0.4.30)\r\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-openai) (24.2)\r\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-openai) (2.11.7)\r\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-openai) (6.0.2)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-openai) (9.0.0)\r\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-openai) (4.15.0)\r\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/michal/.local/lib/python3.13/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.10.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.28.1)\r\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.10.0)\r\n",
      "Requirement already satisfied: sniffio in /home/michal/.local/lib/python3.13/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\r\n",
      "Requirement already satisfied: tqdm>4 in /home/michal/anaconda3/lib/python3.13/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\r\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/michal/anaconda3/lib/python3.13/site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.11.6)\r\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.32.5)\r\n",
      "Requirement already satisfied: idna>=2.8 in /home/michal/anaconda3/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=1.109.1->langchain-openai) (3.7)\r\n",
      "Requirement already satisfied: certifi in /home/michal/anaconda3/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (2025.8.3)\r\n",
      "Requirement already satisfied: httpcore==1.* in /home/michal/.local/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (1.0.9)\r\n",
      "Requirement already satisfied: h11>=0.16 in /home/michal/.local/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (0.16.0)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/michal/anaconda3/lib/python3.13/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain-openai) (3.0.0)\r\n",
      "Requirement already satisfied: orjson>=3.9.14 in /home/michal/anaconda3/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-openai) (3.10.14)\r\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-openai) (1.0.0)\r\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-openai) (0.23.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-openai) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/michal/anaconda3/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-openai) (2.33.2)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-openai) (0.4.0)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/michal/anaconda3/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (3.3.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/michal/anaconda3/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.5.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.3\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "387b2d7785918f08",
   "metadata": {},
   "source": [
    "### LangChain Hello world"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-03T07:12:14.036474Z",
     "start_time": "2025-11-03T07:12:13.056476Z"
    }
   },
   "source": [
    "# import libraries\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# get OpenAI API key from the environment\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"Missing API key in file .env!\")\n",
    "\n",
    "# create the OpenAI API client with the selected model\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, api_key=api_key)\n",
    "\n",
    "# simple prompt and request to the LLM API\n",
    "response = llm.invoke(\"Write a short greeting in English.\")\n",
    "\n",
    "print(\"Model response:\\n\")\n",
    "print(response.content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model response:\n",
      "\n",
      "Hello! I hope you're having a wonderful day. It's great to connect with you!\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "1124603ed27c0a9",
   "metadata": {},
   "source": "### Text generation"
  },
  {
   "cell_type": "code",
   "id": "4bcecd4b93ac98f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T07:12:30.217175Z",
     "start_time": "2025-11-03T07:12:14.093947Z"
    }
   },
   "source": [
    "response = llm.invoke(\"Generate a recipe for sweet cheesecake with tuna, broccoli and onion.\")\n",
    "\n",
    "print(\"Model response:\\n\")\n",
    "print(response.content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model response:\n",
      "\n",
      "Creating a sweet cheesecake with tuna, broccoli, and onion is quite unconventional, but I can help you craft a unique recipe that balances these flavors. Here’s a creative take on a savory-sweet cheesecake that incorporates these ingredients:\n",
      "\n",
      "### Sweet Tuna, Broccoli, and Onion Cheesecake\n",
      "\n",
      "#### Ingredients\n",
      "\n",
      "**For the Crust:**\n",
      "- 1 cup crushed graham crackers\n",
      "- 1/4 cup melted butter\n",
      "- 2 tablespoons sugar\n",
      "- Pinch of salt\n",
      "\n",
      "**For the Filling:**\n",
      "- 8 oz cream cheese, softened\n",
      "- 1/2 cup sour cream\n",
      "- 1/4 cup sugar\n",
      "- 1/4 cup honey or maple syrup\n",
      "- 2 large eggs\n",
      "- 1 can (5 oz) tuna, drained and flaked\n",
      "- 1 cup cooked broccoli, finely chopped\n",
      "- 1/2 small onion, finely chopped (sautéed until soft)\n",
      "- 1 teaspoon lemon juice\n",
      "- 1 teaspoon vanilla extract\n",
      "- 1/2 teaspoon salt\n",
      "- 1/4 teaspoon black pepper\n",
      "\n",
      "**For the Topping (optional):**\n",
      "- Fresh herbs (like dill or parsley) for garnish\n",
      "- A drizzle of honey or balsamic glaze\n",
      "\n",
      "#### Instructions\n",
      "\n",
      "1. **Prepare the Crust:**\n",
      "   - Preheat your oven to 350°F (175°C).\n",
      "   - In a mixing bowl, combine the crushed graham crackers, melted butter, sugar, and salt. Mix until well combined.\n",
      "   - Press the mixture firmly into the bottom of a 9-inch springform pan to form an even layer. Bake for 8-10 minutes until lightly golden. Remove from the oven and let it cool.\n",
      "\n",
      "2. **Prepare the Filling:**\n",
      "   - In a large mixing bowl, beat the softened cream cheese until smooth.\n",
      "   - Add the sour cream, sugar, honey (or maple syrup), and mix until well combined.\n",
      "   - Add the eggs one at a time, mixing well after each addition.\n",
      "   - Stir in the flaked tuna, chopped broccoli, sautéed onion, lemon juice, vanilla extract, salt, and black pepper. Mix until everything is evenly incorporated.\n",
      "\n",
      "3. **Bake the Cheesecake:**\n",
      "   - Pour the filling over the cooled crust, smoothing the top with a spatula.\n",
      "   - Bake in the preheated oven for 30-35 minutes, or until the center is set but still slightly jiggly.\n",
      "   - Turn off the oven and leave the cheesecake inside for an additional hour to cool gradually.\n",
      "\n",
      "4. **Chill:**\n",
      "   - After the cheesecake has cooled, remove it from the oven and let it cool to room temperature. Then refrigerate for at least 4 hours, or overnight for best results.\n",
      "\n",
      "5. **Serve:**\n",
      "   - Before serving, garnish with fresh herbs and a drizzle of honey or balsamic glaze if desired.\n",
      "   - Slice and enjoy your unique sweet cheesecake with tuna, broccoli, and onion!\n",
      "\n",
      "### Notes:\n",
      "- This recipe is quite experimental, so feel free to adjust the sweetness or savory elements to your taste.\n",
      "- You can also add spices or herbs to enhance the flavor profile, such as garlic powder or dill.\n",
      "\n",
      "Enjoy your culinary adventure!\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "f5ee48d932b337f",
   "metadata": {},
   "source": "### Classification"
  },
  {
   "cell_type": "code",
   "id": "29165f1f81b5a7b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T07:12:33.392311Z",
     "start_time": "2025-11-03T07:12:30.273930Z"
    }
   },
   "source": [
    "articles = [\n",
    "    \"The government announced new tax reforms today.\",\n",
    "    \"The local team won the championship in a thrilling match.\",\n",
    "    \"New advancements in AI are reshaping the tech industry.\",\n",
    "    \"The art exhibit showcased contemporary works by emerging artists.\",\n",
    "    \"New guidelines for a healthy diet were published by the health department.\"\n",
    "]\n",
    "for subject in articles:\n",
    "    response = llm.invoke(\"Classify texts into groups Politics, Sport, Technology, Culture, Health. Return only single word with category.\"\n",
    "    f\"Text: {subject}\")\n",
    "\n",
    "    print(subject)\n",
    "    print(response.content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The government announced new tax reforms today.\n",
      "Politics\n",
      "The local team won the championship in a thrilling match.\n",
      "Sport\n",
      "New advancements in AI are reshaping the tech industry.\n",
      "Technology\n",
      "The art exhibit showcased contemporary works by emerging artists.\n",
      "Culture\n",
      "New guidelines for a healthy diet were published by the health department.\n",
      "Health\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "b544986e777e52a",
   "metadata": {},
   "source": "### Sentiment analysis"
  },
  {
   "cell_type": "code",
   "id": "b4bc685457491afc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T07:12:34.870702Z",
     "start_time": "2025-11-03T07:12:33.449579Z"
    }
   },
   "source": [
    "# Sample reviews\n",
    "reviews = [\n",
    "    \"This product is amazing! I loved it.\",\n",
    "    \"I am very disappointed. The product broke after one use.\",\n",
    "    \"It's okay, does the job but nothing special.\"\n",
    "]\n",
    "for review in reviews:\n",
    "    response = llm.invoke(f\"Rate the sentiment of a review. Return only one word (positive, negative, neutral): {review}\")\n",
    "\n",
    "    print(\"Model response:\\n\")\n",
    "    print(response.content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model response:\n",
      "\n",
      "Positive\n",
      "Model response:\n",
      "\n",
      "Negative\n",
      "Model response:\n",
      "\n",
      "Neutral\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "cfe6391cfa987531",
   "metadata": {},
   "source": "### Document analysis"
  },
  {
   "cell_type": "code",
   "id": "5ecaf0f4709cf23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T07:12:36.873320Z",
     "start_time": "2025-11-03T07:12:34.923737Z"
    }
   },
   "source": [
    "file = open(\"../data/annual_report.html\", \"r\")\n",
    "document = file.read()\n",
    "response = llm.invoke(f\"Analyze the attached document and find information about the company's annual revenue. {document}\")\n",
    "print(\"Model response:\\n\")\n",
    "print(response.content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model response:\n",
      "\n",
      "The company's annual revenue, referred to as \"Umsatzerlöse\" in the document, is as follows:\n",
      "\n",
      "- For the year **2019**, the revenue was **55,680 million EUR**.\n",
      "- For the year **2018**, the revenue was **59,248 million EUR**.\n",
      "\n",
      "Additionally, there was a **decrease of 6.0%** in revenue from 2018 to 2019.\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "f80dd7cc21e40740",
   "metadata": {},
   "source": [
    "### Machine translation"
   ]
  },
  {
   "cell_type": "code",
   "id": "817c691daa758421",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T07:12:37.887271Z",
     "start_time": "2025-11-03T07:12:36.964571Z"
    }
   },
   "source": [
    "response = llm.invoke(\"Translate the text below into Polish:\\n I'm foreigner and I don't speak german fluently.\")\n",
    "\n",
    "print(\"Model response:\\n\")\n",
    "print(response.content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model response:\n",
      "\n",
      "Jestem obcokrajowcem i nie mówię płynnie po niemiecku.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "97c5e19db3285a8a",
   "metadata": {},
   "source": [
    "### Question answering"
   ]
  },
  {
   "cell_type": "code",
   "id": "189b2679404bf9c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T07:12:38.743089Z",
     "start_time": "2025-11-03T07:12:37.939819Z"
    }
   },
   "source": [
    "response = llm.invoke(\"Answer the following questions based on the attached text:\\n\"\n",
    "\"LangChain is a framework for working with large language models.\\n\"\n",
    "\"Chains in LangChain are data flows between prompts, models, and parsers.\\n\"\n",
    "\"Retriever allows you to search for information in a vector database.\\n\"\n",
    "\"Question: What are Chains used for in LangChain?\")\n",
    "\n",
    "print(\"Model response:\\n\")\n",
    "print(response.content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model response:\n",
      "\n",
      "Chains in LangChain are used for creating data flows between prompts, models, and parsers.\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "6c12729c6b0a3c77",
   "metadata": {},
   "source": "### Summarization"
  },
  {
   "cell_type": "code",
   "id": "82e5c070f2c9b660",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T07:12:49.161044Z",
     "start_time": "2025-11-03T07:12:38.795682Z"
    }
   },
   "source": [
    "file = open(\"../data/nad_niemnem.txt\", \"r\")\n",
    "document = file.read()\n",
    "response = llm.invoke(f\"Write a short summary (approx. 500 words) of the attached text.\\n{document[:1800]}\")\n",
    "\n",
    "print(\"Model repsonse:\\n\")\n",
    "print(response.content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model repsonse:\n",
      "\n",
      "**Summary of \"Nad Niemnem\" by Eliza Orzeszkowa**\n",
      "\n",
      "\"Nad Niemnem,\" a novel by Eliza Orzeszkowa, opens with a vivid and picturesque description of a summer day, filled with warmth, joy, and the beauty of nature. The setting is characterized by lush greenery, blooming fields, and a clear blue sky, creating an atmosphere of celebration and tranquility. The landscape is dominated by gentle hills adorned with dark forests and a sandy bank of the Niemen River, which serves as a natural boundary, enhancing the idyllic scenery.\n",
      "\n",
      "The narrative introduces a sprawling estate, surrounded by a series of smaller homesteads that form a semi-circle along the riverbank. These dwellings, both large and small, emerge from their gardens, with smoke rising gently from chimneys and sunlight reflecting off windows, creating a sparkling effect. The roads, lined with patches of grass and wildflowers, weave through the countryside, connecting the fields to the river, which is a central element of the local life.\n",
      "\n",
      "As the story unfolds, it delves into the lives of the inhabitants of this rural setting, exploring their relationships, struggles, and the socio-economic conditions of the time. The characters are deeply connected to the land, and their lives are intertwined with the rhythms of nature. The novel captures the essence of rural Polish life in the late 19th century, highlighting themes of love, family, and the impact of social change.\n",
      "\n",
      "Orzeszkowa's writing is rich in detail, painting a vivid picture of the environment and the characters' interactions with it. The beauty of the landscape serves as a backdrop to the unfolding human drama, emphasizing the connection between people and their surroundings. The author skillfully contrasts the serenity of nature with the complexities of human emotions and societal issues, creating a multifaceted narrative that resonates with readers.\n",
      "\n",
      "Throughout the novel, the Niemen River symbolizes both a physical and metaphorical boundary, representing the divide between different social classes and the challenges faced by the characters. The river is a source of life and sustenance, but it also reflects the struggles and conflicts that arise within the community. As the characters navigate their personal journeys, the river serves as a constant reminder of the larger forces at play in their lives.\n",
      "\n",
      "In summary, \"Nad Niemnem\" is a rich tapestry of rural life, exploring the interplay between nature and humanity. Orzeszkowa's evocative prose captures the beauty of the Polish landscape while delving into the complexities of human relationships and societal change. The novel stands as a testament to the enduring connection between people and the land they inhabit, making it a significant work in Polish literature.\n"
     ]
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
