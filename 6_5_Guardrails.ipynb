{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": [
    "## Guardrails\n",
    "Guardrails w LangChain to mechanizmy pilnujące, aby odpowiedzi modelu spełniały określone wymagania techniczne lub formatowe.\n",
    "Na przykład JsonValidityEvaluator sprawdza, czy zwrócony tekst jest poprawnym JSON-em – jeśli struktura jest niepoprawna, evaluator zwróci błąd.\n",
    "Dzięki temu można automatycznie wykrywać i odrzucać odpowiedzi, które nie nadają się do dalszego przetwarzania."
   ],
   "id": "8843f9eae98bb3a4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### JSON Format Validator\n",
    "Sprawdza, czy wygenerowana odpowiedź jest poprawnym JSON-em"
   ],
   "id": "963e720e47fbc32e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T17:49:00.346973Z",
     "start_time": "2025-10-10T17:49:00.344336Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.evaluation import JsonValidityEvaluator\n",
    "\n",
    "evaluator = JsonValidityEvaluator()\n",
    "# print(evaluator.evaluate_strings(prediction='{\"x\": 1}'))      # poprawne\n",
    "print(evaluator.evaluate_strings(prediction='{x: 1}'))        # błąd\n"
   ],
   "id": "51429117cf2939bb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0, 'reasoning': 'Expecting property name enclosed in double quotes: line 1 column 2 (char 1)'}\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### JsonEqualityEvaluator\n",
    "Sprawdza równość JSON-ów po sparsowaniu (kolejność kluczy w JSON nie ma znaczenia)"
   ],
   "id": "6cb1491ea9f8286d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T17:49:43.104085Z",
     "start_time": "2025-10-10T17:49:43.101161Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.evaluation import JsonEqualityEvaluator\n",
    "\n",
    "evaluator = JsonEqualityEvaluator()\n",
    "print(evaluator.evaluate_strings(\n",
    "    prediction='{\"a\":1,\"b\":[2,3]}',\n",
    "    reference='{\"b\":[2,3],\"a\":2}',\n",
    "))\n"
   ],
   "id": "a9b6c949f0ea4ddc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': False}\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### RegexMatchEvaluator\n",
    "Sprawdza dopasowanie do wyrażenia regularnego"
   ],
   "id": "4a367a91398ca8bb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T17:52:18.680053Z",
     "start_time": "2025-10-10T17:52:18.673146Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.evaluation import RegexMatchStringEvaluator\n",
    "\n",
    "evaluator = RegexMatchStringEvaluator()\n",
    "result = evaluator.evaluate_strings(\n",
    "    prediction=\"Order ID: ABC-1234\",\n",
    "    reference=r\"^Order ID: [A-Z]{3}-\\d{4}$\",\n",
    ")\n",
    "print(result['score'])\n",
    "\n",
    "iter = 3\n",
    "while result['score'] < 1.0 and iter > 0:\n",
    "    iter -= 1\n",
    "    print('run model once more')"
   ],
   "id": "a879dcfff035934",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "run model once more\n",
      "run model once more\n",
      "run model once more\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Fallback Messages Validator\n",
    "Kiedy główny model zawiedzie (rate limit / błąd) automatycznie użyj modelu zapasowego."
   ],
   "id": "392b8b0fc506ff11"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T08:17:13.768660Z",
     "start_time": "2025-10-11T08:17:11.559346Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "primary = ChatOpenAI(model=\"gpt-4o-miniS\", max_retries=0)  # wyłącz retry, by fallback zadziałał\n",
    "backup  = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "chain = primary.with_fallbacks([backup])\n",
    "\n",
    "print(chain.invoke(\"Opisz w 1 zdaniu Python.\"))\n"
   ],
   "id": "ea1d15d55ae7e062",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Python to wysokopoziomowy język programowania, znany ze swojej przejrzystej składni i wszechstronności, który jest powszechnie stosowany do tworzenia różnego rodzaju aplikacji i skryptów.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 59, 'prompt_tokens': 16, 'total_tokens': 75, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CPP4qEWR8cQ2EV3ArBAXyOtzxCjjh', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--8b72b4ab-ca69-441b-8ef5-6b0cc441f2b2-0' usage_metadata={'input_tokens': 16, 'output_tokens': 59, 'total_tokens': 75, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Token Limit\n",
    "Śledzenie i przycinanie historii do limitu tokenów, żeby nie przekroczyć kontekstu modelu."
   ],
   "id": "39f6d9c66cfb3d10"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T17:55:19.033819Z",
     "start_time": "2025-10-10T17:55:15.252449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_core.messages.utils import trim_messages, count_tokens_approximately\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"Jesteś pomocnym asystentem.\"),\n",
    "    HumanMessage(content=\"(tu długa historia rozmowy / wiele wiadomości...)\"),\n",
    "]\n",
    "\n",
    "trimmed = trim_messages(\n",
    "    messages,\n",
    "    strategy=\"last\",\n",
    "    token_counter=count_tokens_approximately,\n",
    "    max_tokens=256,\n",
    "    start_on=\"human\",\n",
    "    include_system=True,\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "print(json.dumps(llm.invoke(trimmed).response_metadata, indent=4))\n"
   ],
   "id": "f4f147d4e8dd6c4f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"token_usage\": {\n",
      "        \"completion_tokens\": 36,\n",
      "        \"prompt_tokens\": 33,\n",
      "        \"total_tokens\": 69,\n",
      "        \"completion_tokens_details\": {\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"audio_tokens\": 0,\n",
      "            \"reasoning_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "        },\n",
      "        \"prompt_tokens_details\": {\n",
      "            \"audio_tokens\": 0,\n",
      "            \"cached_tokens\": 0\n",
      "        }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"system_fingerprint\": \"fp_560af6e559\",\n",
      "    \"id\": \"chatcmpl-CPBcjgDnYifYhkEWXRH30M4AXrFpZ\",\n",
      "    \"service_tier\": \"default\",\n",
      "    \"finish_reason\": \"stop\",\n",
      "    \"logprobs\": null\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Word Limit\n",
    "poproś o max N słów, po generacji policz słowa. W razie przekroczenia – skróć odpowiedź."
   ],
   "id": "d3b409e890c6ac61"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T17:55:40.134506Z",
     "start_time": "2025-10-10T17:55:36.984530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "limit = 25\n",
    "prompt = f\"Napisz streszczenie w MAKS {limit} słowach: Czym jest uczenie maszynowe?\"\n",
    "\n",
    "resp = llm.invoke(prompt).content\n",
    "if len(resp.split()) > limit:\n",
    "    # szybka korekta – poproś model o skrócenie do limitu\n",
    "    resp = llm.invoke(f\"Skróć to do maks {limit} słów, bez dopisków:\\n\\n{resp}\").content\n",
    "\n",
    "print(resp)\n"
   ],
   "id": "44ce2da6c0d8aaab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uczenie maszynowe to dziedzina sztucznej inteligencji, która umożliwia komputerom uczenie się z danych i doskonalenie swoich działań bez programowania.\n"
     ]
    }
   ],
   "execution_count": 30
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
