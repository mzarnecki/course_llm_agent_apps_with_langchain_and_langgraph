{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": "## String and comparison evaluation",
   "id": "8843f9eae98bb3a4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T05:42:13.276842Z",
     "start_time": "2025-09-23T05:42:13.272659Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy.sql.functions import random\n",
    "\n",
    "load_dotenv()"
   ],
   "id": "68ff02d966926bc4",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Embedding Distance Evaluator\n",
    "Embedding Distance Evaluator porównuje dwie odpowiedzi, zamieniając je na wektory osadzeń (embeddings) i mierząc odległość lub podobieństwo kosinusowe. Dzięki temu ocenia semantyczną bliskość treści, a nie tylko dopasowanie słów."
   ],
   "id": "d97458f8894ba508"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T05:32:36.549583Z",
     "start_time": "2025-09-23T05:32:35.744059Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.evaluation import load_evaluator\n",
    "\n",
    "evaluator = load_evaluator(\"embedding_distance\", embeddings_model=\"openai\")\n",
    "\n",
    "result1 = evaluator.evaluate_strings(\n",
    "    prediction=\"Stolica Polski to Warszawa\",\n",
    "    reference=\"Stolica Polski to Warszawa\"\n",
    ")\n",
    "\n",
    "result2 = evaluator.evaluate_strings(\n",
    "    prediction=\"Stolica Polski to Warszawa\",\n",
    "    reference=\"Stolica Polski nosi nazwę Warszawa\"\n",
    ")\n",
    "\n",
    "result3 = evaluator.evaluate_strings(\n",
    "    prediction=\"Stolica Polski to Warszawa\",\n",
    "    reference=\"Stolica Burkina Faso nosi nazwę Wagadugu\"\n",
    ")\n",
    "\n",
    "print(round(result1[\"score\"], 4))\n",
    "print(round(result2[\"score\"], 4))\n",
    "print(round(result3[\"score\"], 4))\n"
   ],
   "id": "abf878369f056ddc",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in LangChainTracer.on_chain_end callback: TypeError(\"RunTree.patch() got an unexpected keyword argument 'exclude_inputs'\")\n",
      "Error in LangChainTracer.on_chain_end callback: TypeError(\"RunTree.patch() got an unexpected keyword argument 'exclude_inputs'\")\n",
      "Error in LangChainTracer.on_chain_end callback: TypeError(\"RunTree.patch() got an unexpected keyword argument 'exclude_inputs'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0\n",
      "0.0508\n",
      "0.1318\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### String Comparison\n",
    "Ewaluator porównuje dwa teksty przy użyciu metryki BLEU, która mierzy n-gramowe podobieństwo wygenerowanej odpowiedzi do odpowiedzi referencyjnej."
   ],
   "id": "f51fedf1acbb83eb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T05:32:56.141747Z",
     "start_time": "2025-09-23T05:32:56.130302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "evaluator = load_evaluator(\"string_distance\", metric=\"bleu\")\n",
    "\n",
    "result1 = evaluator.evaluate_strings(\n",
    "    prediction=\"Stolica Polski to Warszawa\",\n",
    "    reference=\"Stolica Polski to Warszawa\"\n",
    ")\n",
    "\n",
    "result2 = evaluator.evaluate_strings(\n",
    "    prediction=\"Stolicą Polski jest Warszawa\",\n",
    "    reference=\"Stolica Polski to Warszawa\"\n",
    ")\n",
    "\n",
    "result3 = evaluator.evaluate_strings(\n",
    "    prediction=\"Stolica Polski to Warszawa\",\n",
    "    reference=\"Warszawa jest stolicą Polski\"\n",
    ")\n",
    "\n",
    "print(round(result1[\"score\"], 4))\n",
    "print(round(result2[\"score\"], 4))\n",
    "print(round(result3[\"score\"], 4))\n"
   ],
   "id": "b056b0e4a33539e5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in LangChainTracer.on_chain_end callback: TypeError(\"RunTree.patch() got an unexpected keyword argument 'exclude_inputs'\")\n",
      "Error in LangChainTracer.on_chain_end callback: TypeError(\"RunTree.patch() got an unexpected keyword argument 'exclude_inputs'\")\n",
      "Error in LangChainTracer.on_chain_end callback: TypeError(\"RunTree.patch() got an unexpected keyword argument 'exclude_inputs'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.069\n",
      "0.4991\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### String Comparison: BLUE, ROUGE, METEOR",
   "id": "8b33b6e594d30c36"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T05:34:14.214859Z",
     "start_time": "2025-09-23T05:34:14.200649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.evaluation import load_evaluator\n",
    "\n",
    "# BLEU evaluator\n",
    "bleu_eval = load_evaluator(\"string_distance\", metric=\"bleu\")\n",
    "\n",
    "result_bleu = bleu_eval.evaluate_strings(\n",
    "    prediction=\"Warsaw is the capital of Poland\",\n",
    "    reference=\"The capital of Poland is Warsaw\"\n",
    ")\n",
    "print(\"BLEU:\", result_bleu)\n",
    "\n",
    "# ROUGE evaluator\n",
    "rouge_eval = load_evaluator(\"string_distance\", metric=\"rouge\")\n",
    "\n",
    "result_rouge = rouge_eval.evaluate_strings(\n",
    "    prediction=\"Warsaw is capital\",\n",
    "    reference=\"Warsaw is the capital of Poland\"\n",
    ")\n",
    "print(\"ROUGE:\", result_rouge)\n",
    "\n",
    "# METEOR evaluator\n",
    "meteor_eval = load_evaluator(\"string_distance\", metric=\"meteor\")\n",
    "\n",
    "result_meteor = meteor_eval.evaluate_strings(\n",
    "    prediction=\"The dog runs quickly\",\n",
    "    reference=\"The dog is running fast\"\n",
    ")\n",
    "print(\"METEOR:\", result_meteor)\n"
   ],
   "id": "c360ac20053cc1cb",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in LangChainTracer.on_chain_end callback: TypeError(\"RunTree.patch() got an unexpected keyword argument 'exclude_inputs'\")\n",
      "Error in LangChainTracer.on_chain_end callback: TypeError(\"RunTree.patch() got an unexpected keyword argument 'exclude_inputs'\")\n",
      "Error in LangChainTracer.on_chain_end callback: TypeError(\"RunTree.patch() got an unexpected keyword argument 'exclude_inputs'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: {'score': 0.28903225806451616}\n",
      "ROUGE: {'score': 0.11385199240986721}\n",
      "METEOR: {'score': 0.30186335403726705}\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Testy A/B\n",
    "PairwiseStringEvaluator służy do porównywania dwóch odpowiedzi tekstowych względem jednej referencji, aby wybrać lepszą. Dzięki temu można automatycznie ocenić, która z odpowiedzi jest bliższa oczekiwanemu wynikowi."
   ],
   "id": "1c0bc677b17e562e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T05:42:21.687748Z",
     "start_time": "2025-09-23T05:42:18.606894Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.evaluation import load_evaluator\n",
    "\n",
    "evaluator = load_evaluator(\"labeled_pairwise_string\")\n",
    "\n",
    "result = evaluator.evaluate_string_pairs(\n",
    "    input=\"What is the capital of Poland?\",\n",
    "    prediction=\"Warsaw is the capital of Poland\",\n",
    "    prediction_b=\"I don't know\",\n",
    "    reference=\"Warsaw is Poland's capital\"\n",
    ")\n",
    "\n",
    "print(json.dumps(result, indent=4))"
   ],
   "id": "99cf12d4d38fb415",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in LangChainTracer.on_llm_end callback: TypeError(\"RunTree.patch() got an unexpected keyword argument 'exclude_inputs'\")\n",
      "Error in LangChainTracer.on_chain_end callback: TypeError(\"RunTree.patch() got an unexpected keyword argument 'exclude_inputs'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"reasoning\": \"Assistant A's response is helpful, relevant, correct, and accurate. It directly answers the user's question about the capital of Poland. On the other hand, Assistant B's response is not helpful or accurate. It does not provide the user with the information they were seeking. Therefore, Assistant A's response is superior in this case. \\n\\nFinal verdict: [[A]]\",\n",
      "    \"value\": \"A\",\n",
      "    \"score\": 1\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Ewaluacja odpowiedzi LLM poprzez LLM\n",
    "Polega na tym, że jeden model LLM ocenia odpowiedzi wygenerowane przez inny (lub ten sam) model, według zadanych kryteriów. Dzięki temu można automatyzować ocenę jakości treści bez konieczności ręcznej weryfikacji."
   ],
   "id": "498d46b178a8c225"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T05:50:30.388410Z",
     "start_time": "2025-09-23T05:50:20.431500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\")\n",
    "template = \"\"\"\n",
    "You are base of knowledge about star wars. Respond to question below with only name without any additional text.\n",
    "{input}\n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate.from_template(template=template)\n",
    "chain = prompt_template | llm\n",
    "prediction = chain.invoke({\"input\": \"What is the capital of star wars Sith Empire?\"})\n",
    "print(prediction)\n",
    "\n",
    "evaluator = load_evaluator(\"labeled_score_string\", llm=ChatOpenAI(model=\"gpt-4o\"))\n",
    "eval_result = evaluator.evaluate_strings(\n",
    "    prediction=prediction,\n",
    "    reference=\"Coruscant\",\n",
    "    input=\"What is the capital of star wars Sith Empire?\",\n",
    ")\n",
    "print(json.dumps(eval_result, indent=4))\n",
    "\n",
    "eval_result = evaluator.evaluate_strings(\n",
    "    prediction=\"Hollywood\",\n",
    "    reference=\"Coruscant\",\n",
    "    input=\"What is the capital of star wars Sith Empire?\",\n",
    ")\n",
    "print(json.dumps(eval_result, indent=4))\n",
    "\n"
   ],
   "id": "fec00ff98e795156",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in LangChainTracer.on_chain_end callback: TypeError(\"RunTree.patch() got an unexpected keyword argument 'exclude_inputs'\")\n",
      "Error in LangChainTracer.on_llm_end callback: TypeError(\"RunTree.patch() got an unexpected keyword argument 'exclude_inputs'\")\n",
      "Error in LangChainTracer.on_chain_end callback: TypeError(\"RunTree.patch() got an unexpected keyword argument 'exclude_inputs'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Dromund Kaas' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 39, 'total_tokens': 44, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CIqCqOmIF3lAb5hsqegRXxRo2i499', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--4fe9c624-56fd-4e93-bbb1-b01562f87569-0' usage_metadata={'input_tokens': 39, 'output_tokens': 5, 'total_tokens': 44, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in LangChainTracer.on_llm_end callback: TypeError(\"RunTree.patch() got an unexpected keyword argument 'exclude_inputs'\")\n",
      "Error in LangChainTracer.on_chain_end callback: TypeError(\"RunTree.patch() got an unexpected keyword argument 'exclude_inputs'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"reasoning\": \"The assistant's response provides the capital of the Sith Empire in the Star Wars universe as \\\"Dromund Kaas.\\\" This answer is correct according to Star Wars lore. Dromund Kaas is widely recognized as the capital of the Sith Empire, particularly during the timeline related to Star Wars: The Old Republic, which is an Expanded Universe (now Legends) storyline. \\n\\nThe response is helpful and relevant to the question as it pertains directly to the query about the capital of the Sith Empire in Star Wars. It is accurate, demonstrating correctness in the context of the Star Wars Expanded Universe. However, the response lacks depth since it does not provide any additional context or insight about Dromund Kaas or its significance in the Star Wars universe.\\n\\nGiven these considerations, the response scores well on correctness and relevance but could be improved with more detailed information. \\n\\nRating: [[8]]\",\n",
      "    \"score\": 8\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in LangChainTracer.on_llm_end callback: TypeError(\"RunTree.patch() got an unexpected keyword argument 'exclude_inputs'\")\n",
      "Error in LangChainTracer.on_chain_end callback: TypeError(\"RunTree.patch() got an unexpected keyword argument 'exclude_inputs'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"reasoning\": \"The AI's response is not accurate regarding the question asked. The capital of the Sith Empire in Star Wars lore is not Hollywood, which is a location in the real world unrelated to the Star Wars universe. According to the Star Wars Expanded Universe (Legends) and various comics and video games, the capital of the Sith Empire is Coruscant during certain periods, but more specifically, it is often discussed as being Korriban or Dromund Kaas. \\n\\n- Helpfulness: The response is not helpful or appropriate to the question.\\n- Relevance: The response is not referring to any real quote from the Star Wars narrative or expanded universe.\\n- Correctness: The response is factually incorrect.\\n- Depth: The response shows no depth of thought or understanding of the Star Wars universe.\\n\\nOverall, the answer fails on all criteria because it provides incorrect and irrelevant information.\\n\\nRating: [[1]]\",\n",
      "    \"score\": 1\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Ewaluacja odpowiedzi – własny grading i ContextQAEvalChain\n",
    "W tym przykładzie najpierw generujemy odpowiedzi na pytania z kontekstem, a następnie oceniamy ich jakość dwiema metodami. Pierwsza to własny łańcuch gradingowy, który przyznaje ocenę w skali 0–5 względem odpowiedzi referencyjnej, a druga to wbudowany evaluator ContextQAEvalChain, który sprawdza spójność predykcji z dostarczonym kontekstem."
   ],
   "id": "e49bff9136e2bd05"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T05:55:55.579379Z",
     "start_time": "2025-09-23T05:55:50.327207Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.evaluation.qa import ContextQAEvalChain\n",
    "\n",
    "# 1) Model\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# 2) Łańcuch Q&A z kontekstem\n",
    "qa_prompt = PromptTemplate.from_template(\n",
    "    \"Answer the question based on the context.\\n\"\n",
    "    \"Context: {context}\\n\"\n",
    "    \"Question: {question}\\n\"\n",
    "    \"Answer:\"\n",
    ")\n",
    "qa_chain = qa_prompt | llm | StrOutputParser()\n",
    "\n",
    "# 3) Łańcuch oceny (grading) – skala 0..5\n",
    "grading_template = \"\"\"You are an expert in grading answers.\n",
    "You are grading the following question:\n",
    "{query}\n",
    "\n",
    "Here is the correct expected answer:\n",
    "{answer}\n",
    "\n",
    "You are grading the following predicted answer:\n",
    "{result}\n",
    "\n",
    "What grade do you give from 0 to 5, where 0 is the lowest for low similarity and 5 is for the high similarity?\n",
    "Return only the number.\"\"\"\n",
    "grading_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"answer\", \"result\"],\n",
    "    template=grading_template\n",
    ")\n",
    "grade_chain = grading_prompt | llm | StrOutputParser()\n",
    "\n",
    "# 4) Dane wejściowe (dodano też referencję 'answer')\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"Why can't people breathe underwater?\",\n",
    "        \"context\": \"Because humans don't have gills.\",\n",
    "        \"answer\": \"Because humans don't have gills.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Why is the sky blue?\",\n",
    "        \"context\": \"It is an optical effect due to Rayleigh scattering of sunlight in the atmosphere.\",\n",
    "        \"answer\": \"Because of Rayleigh scattering of sunlight in the atmosphere.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is in my pocket?\",\n",
    "        \"context\": \"\",\n",
    "        \"answer\": \"Unknown; insufficient information.\"\n",
    "    },\n",
    "]\n",
    "\n",
    "# 5) Generowanie odpowiedzi\n",
    "predictions = qa_chain.batch(\n",
    "    [{\"context\": ex[\"context\"], \"question\": ex[\"question\"]} for ex in examples]\n",
    ")\n",
    "\n",
    "# 6) Ocena własnym łańcuchem grading\n",
    "grades = grade_chain.batch(\n",
    "    [{\"query\": ex[\"question\"], \"answer\": ex[\"answer\"], \"result\": pred}\n",
    "     for ex, pred in zip(examples, predictions)]\n",
    ")\n",
    "\n",
    "# 7) Ocena gotowym ewaluatorem ContextQAEvalChain\n",
    "eval_chain = ContextQAEvalChain.from_llm(llm)\n",
    "\n",
    "predictions_dicts = [{\"text\": pred} for pred in predictions]\n",
    "\n",
    "graded_outputs = eval_chain.evaluate(\n",
    "    examples,\n",
    "    predictions_dicts,\n",
    "    question_key=\"question\",\n",
    "    prediction_key=\"text\"\n",
    ")\n",
    "\n",
    "# 8) Podgląd wyników\n",
    "print(\"\\n--- Wyniki własnego grading chain ---\")\n",
    "for ex, pred, grade in zip(examples, predictions, grades):\n",
    "    print({\n",
    "        \"question\": ex[\"question\"],\n",
    "        \"prediction\": pred.strip(),\n",
    "        \"reference\": ex[\"answer\"],\n",
    "        \"grade_0_5\": grade.strip()\n",
    "    })\n",
    "\n",
    "print(\"\\n--- Wyniki ContextQAEvalChain ---\")\n",
    "print(graded_outputs)"
   ],
   "id": "b348fa1178dc88f2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in LangChainTracer.on_chain_end callback: TypeError(\"RunTree.patch() got an unexpected keyword argument 'exclude_inputs'\")\n",
      "Error in LangChainTracer.on_chain_end callback: TypeError(\"RunTree.patch() got an unexpected keyword argument 'exclude_inputs'\")\n",
      "Error in LangChainTracer.on_chain_end callback: TypeError(\"RunTree.patch() got an unexpected keyword argument 'exclude_inputs'\")\n",
      "Error in LangChainTracer.on_llm_end callback: TypeError(\"RunTree.patch() got an unexpected keyword argument 'exclude_inputs'\")\n",
      "Error in LangChainTracer.on_llm_end callback: TypeError(\"RunTree.patch() got an unexpected keyword argument 'exclude_inputs'\")\n",
      "Error in LangChainTracer.on_llm_end callback: TypeError(\"RunTree.patch() got an unexpected keyword argument 'exclude_inputs'\")\n",
      "Error in LangChainTracer.on_chain_end callback: TypeError(\"RunTree.patch() got an unexpected keyword argument 'exclude_inputs'\")\n",
      "Error in LangChainTracer.on_chain_end callback: TypeError(\"RunTree.patch() got an unexpected keyword argument 'exclude_inputs'\")\n",
      "Error in LangChainTracer.on_chain_end callback: TypeError(\"RunTree.patch() got an unexpected keyword argument 'exclude_inputs'\")\n",
      "Error in LangChainTracer.on_chain_end callback: TypeError(\"RunTree.patch() got an unexpected keyword argument 'exclude_inputs'\")\n",
      "Error in LangChainTracer.on_chain_end callback: TypeError(\"RunTree.patch() got an unexpected keyword argument 'exclude_inputs'\")\n",
      "Error in LangChainTracer.on_chain_end callback: TypeError(\"RunTree.patch() got an unexpected keyword argument 'exclude_inputs'\")\n",
      "Error in LangChainTracer.on_chain_end callback: TypeError(\"RunTree.patch() got an unexpected keyword argument 'exclude_inputs'\")\n",
      "Error in LangChainTracer.on_chain_end callback: TypeError(\"RunTree.patch() got an unexpected keyword argument 'exclude_inputs'\")\n",
      "Error in LangChainTracer.on_chain_end callback: TypeError(\"RunTree.patch() got an unexpected keyword argument 'exclude_inputs'\")\n",
      "Error in LangChainTracer.on_llm_end callback: TypeError(\"RunTree.patch() got an unexpected keyword argument 'exclude_inputs'\")\n",
      "Error in LangChainTracer.on_llm_end callback: TypeError(\"RunTree.patch() got an unexpected keyword argument 'exclude_inputs'\")\n",
      "Error in LangChainTracer.on_llm_end callback: TypeError(\"RunTree.patch() got an unexpected keyword argument 'exclude_inputs'\")\n",
      "Error in LangChainTracer.on_chain_end callback: TypeError(\"RunTree.patch() got an unexpected keyword argument 'exclude_inputs'\")\n",
      "Error in LangChainTracer.on_chain_end callback: TypeError(\"RunTree.patch() got an unexpected keyword argument 'exclude_inputs'\")\n",
      "Error in LangChainTracer.on_chain_end callback: TypeError(\"RunTree.patch() got an unexpected keyword argument 'exclude_inputs'\")\n",
      "Error in LangChainTracer.on_chain_end callback: TypeError(\"RunTree.patch() got an unexpected keyword argument 'exclude_inputs'\")\n",
      "Error in LangChainTracer.on_chain_end callback: TypeError(\"RunTree.patch() got an unexpected keyword argument 'exclude_inputs'\")\n",
      "Error in LangChainTracer.on_chain_end callback: TypeError(\"RunTree.patch() got an unexpected keyword argument 'exclude_inputs'\")\n",
      "Error in LangChainTracer.on_llm_end callback: TypeError(\"RunTree.patch() got an unexpected keyword argument 'exclude_inputs'\")\n",
      "Error in LangChainTracer.on_llm_end callback: TypeError(\"RunTree.patch() got an unexpected keyword argument 'exclude_inputs'\")\n",
      "Error in LangChainTracer.on_llm_end callback: TypeError(\"RunTree.patch() got an unexpected keyword argument 'exclude_inputs'\")\n",
      "Error in LangChainTracer.on_chain_end callback: TypeError(\"RunTree.patch() got an unexpected keyword argument 'exclude_inputs'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Wyniki własnego grading chain ---\n",
      "{'question': \"Why can't people breathe underwater?\", 'prediction': \"People can't breathe underwater because they don't have gills, which are necessary for extracting oxygen from water.\", 'reference': \"Because humans don't have gills.\", 'grade_0_5': '5'}\n",
      "{'question': 'Why is the sky blue?', 'prediction': \"The sky is blue because of Rayleigh scattering, which occurs when sunlight interacts with the molecules and small particles in the Earth's atmosphere. Shorter wavelengths of light, such as blue, are scattered more than longer wavelengths, causing the sky to appear predominantly blue to our eyes.\", 'reference': 'Because of Rayleigh scattering of sunlight in the atmosphere.', 'grade_0_5': '5'}\n",
      "{'question': 'What is in my pocket?', 'prediction': \"I'm sorry, but I can't determine what is in your pocket.\", 'reference': 'Unknown; insufficient information.', 'grade_0_5': '5'}\n",
      "\n",
      "--- Wyniki ContextQAEvalChain ---\n",
      "[{'text': 'CORRECT'}, {'text': 'CORRECT'}, {'text': 'INCORRECT'}]\n"
     ]
    }
   ],
   "execution_count": 41
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
