{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Retrieval Augmented Generation (RAG)",
   "id": "18aff68d57dfa9f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Instalacja bibliotek",
   "id": "2abbfab0c5f365cf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T19:20:18.593248Z",
     "start_time": "2025-09-16T19:20:16.786616Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install langchain_text_splitters",
   "id": "534b948b01e54cb5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_text_splitters in /home/michal/anaconda3/lib/python3.13/site-packages (0.3.11)\r\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=0.3.75 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain_text_splitters) (0.3.75)\r\n",
      "Requirement already satisfied: langsmith>=0.3.45 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=0.3.75->langchain_text_splitters) (0.4.19)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=0.3.75->langchain_text_splitters) (9.0.0)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=0.3.75->langchain_text_splitters) (1.33)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=0.3.75->langchain_text_splitters) (6.0.2)\r\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=0.3.75->langchain_text_splitters) (4.15.0)\r\n",
      "Requirement already satisfied: packaging>=23.2 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=0.3.75->langchain_text_splitters) (24.2)\r\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=0.3.75->langchain_text_splitters) (2.11.7)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/michal/anaconda3/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<2.0.0,>=0.3.75->langchain_text_splitters) (3.0.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/michal/.local/lib/python3.13/site-packages (from langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain_text_splitters) (0.28.1)\r\n",
      "Requirement already satisfied: orjson>=3.9.14 in /home/michal/anaconda3/lib/python3.13/site-packages (from langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain_text_splitters) (3.10.14)\r\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain_text_splitters) (1.0.0)\r\n",
      "Requirement already satisfied: requests>=2.0.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain_text_splitters) (2.32.5)\r\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain_text_splitters) (0.23.0)\r\n",
      "Requirement already satisfied: anyio in /home/michal/.local/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain_text_splitters) (4.10.0)\r\n",
      "Requirement already satisfied: certifi in /home/michal/anaconda3/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain_text_splitters) (2025.8.3)\r\n",
      "Requirement already satisfied: httpcore==1.* in /home/michal/.local/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain_text_splitters) (1.0.9)\r\n",
      "Requirement already satisfied: idna in /home/michal/anaconda3/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain_text_splitters) (3.7)\r\n",
      "Requirement already satisfied: h11>=0.16 in /home/michal/.local/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain_text_splitters) (0.16.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from pydantic>=2.7.4->langchain-core<2.0.0,>=0.3.75->langchain_text_splitters) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/michal/anaconda3/lib/python3.13/site-packages (from pydantic>=2.7.4->langchain-core<2.0.0,>=0.3.75->langchain_text_splitters) (2.33.2)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from pydantic>=2.7.4->langchain-core<2.0.0,>=0.3.75->langchain_text_splitters) (0.4.0)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/michal/anaconda3/lib/python3.13/site-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain_text_splitters) (3.3.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/michal/anaconda3/lib/python3.13/site-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain_text_splitters) (2.5.0)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/michal/.local/lib/python3.13/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.75->langchain_text_splitters) (1.3.1)\r\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Budowa VectorStore (FAISS) i Retrievera",
   "id": "eb8d5442171267e3"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-16T19:31:34.010953Z",
     "start_time": "2025-09-16T19:31:31.233760Z"
    }
   },
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "docs = [\n",
    "    \"LangChain to framework do pracy z LLM.\",\n",
    "    \"RAG łączy retrieval kontekstu z generacją odpowiedzi.\",\n",
    "    \"FAISS to biblioteka do przechowywania i wyszukiwania embeddingów.\",\n",
    "    \"Retriever służy do wyszukiwania najbardziej podobnych dokumentów do zapytania użytkownika. Retriever może zwrócić różną liczbę pasujących dokumentów określona w parametrze k. Retriever wykorzystuje różne algorytmy podobieństwa tekstów, np. dopasowanie kosinusowe, odległość euklidesowa, MMR.\"\n",
    "]\n",
    "\n",
    "# Podział dokumentów na fragmenty\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=20)\n",
    "split = splitter.create_documents(docs)\n",
    "\n",
    "print(f\"Number of chunks: {len(split)}\")\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_documents(split, embedding=embeddings)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    "\n",
    "query = \"Po co używa się retrievera?\"\n",
    "context = retriever.invoke(query)\n",
    "print(\"Znaleziony kontekst:\")\n",
    "for i, c in enumerate(context, 1):\n",
    "    print(f\"{i}.\", c.page_content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 7\n",
      "Znaleziony kontekst:\n",
      "1. Retriever służy do wyszukiwania najbardziej podobnych dokumentów do zapytania użytkownika. Retriever\n",
      "2. Retriever może zwrócić różną liczbę pasujących dokumentów określona w parametrze k. Retriever\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Prosty łańcuch RAG (prompt + kontekst + LLM)",
   "id": "b38b755be95529a1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T19:32:05.241221Z",
     "start_time": "2025-09-16T19:32:02.911870Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Udziel precyzyjnej odpowiedzi wyłącznie na podstawie KONTEKSTU. Jeśli brak danych — powiedz, że nie wiesz.\"),\n",
    "    (\"system\", \"KONTEKST:\\n{context}\"),\n",
    "    (\"user\", \"{question}\")\n",
    "])\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(rag_chain.invoke(\"Czym jest FAISS i do czego służy?\"))"
   ],
   "id": "a500f01ecc94fa8d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS to biblioteka do przechowywania i wyszukiwania embeddingów. Służy do efektywnego wyszukiwania podobnych dokumentów w dużych zbiorach danych.\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Przykład RAG - cały program",
   "id": "99540ca4f91ca9c2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T20:00:31.883142Z",
     "start_time": "2025-09-16T20:00:30.188830Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Model\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Dokumenty źródłowe\n",
    "docs = [\n",
    "    \"LangChain to framework do pracy z LLM.\",\n",
    "    \"RAG łączy dopasowanie kontekstu z generacją odpowiedzi.\",\n",
    "    \"FAISS to biblioteka do przechowywania i wyszukiwania embeddingów.\"\n",
    "]\n",
    "\n",
    "# Split\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=50, chunk_overlap=10)\n",
    "splits = splitter.create_documents(docs)\n",
    "\n",
    "# Embeddings + vector store\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_documents(splits, embedding=embeddings)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    "\n",
    "# Prompt RAG\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Odpowiadaj tylko na podstawie kontekstu:\\n{context}\"),\n",
    "    (\"user\", \"{question}\")\n",
    "])\n",
    "\n",
    "# Pipeline\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": lambda x: retriever.invoke(x[\"question\"]),\n",
    "        \"question\": lambda x: x[\"question\"]\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "\n",
    "print(rag_chain.invoke({\"question\": \"Co to jest FAISS?\"}))\n"
   ],
   "id": "5c3a659781bccd03",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS to biblioteka do przechowywania i przeszukiwania dużych zbiorów wektorów.\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### RAG z pętlą i ewaluacją",
   "id": "fa40afa881954fcd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T20:01:41.618686Z",
     "start_time": "2025-09-16T20:01:39.732914Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "eval_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Oceń odpowiedź.\"),\n",
    "    (\"user\", \"Pytanie: {question}\\nOdpowiedź: {answer}\\nCzy odpowiedź jest poprawna? Odpowiedz yes/no.\") #Pytanie \"Czy odpowiedź jest kompletna?\" spowoduje kolejne iteracje\n",
    "])\n",
    "\n",
    "def rag_with_eval(question, max_retries):\n",
    "    for attempt in range(max_retries):\n",
    "        context = retriever.invoke(question)\n",
    "        answer = (prompt | llm | StrOutputParser()).invoke({\"context\": context, \"question\": question})\n",
    "        eval_result = (eval_prompt | llm | StrOutputParser()).invoke({\"question\": question, \"answer\": answer})\n",
    "        print(f\"Wynik ewaluacji {eval_result}\")\n",
    "        if \"yes\" in eval_result.lower():\n",
    "            return f\"✅ Odpowiedź zaakceptowana:\\n{answer}\"\n",
    "        print(f\"❌ Odpowiedź: {answer}\\n odrzucona, ponawiam próbę...\")\n",
    "    return \"Nie udało się uzyskać poprawnej odpowiedzi.\"\n",
    "\n",
    "print(rag_with_eval(\"Co to jest RAG?\", max_retries=3))\n"
   ],
   "id": "bf6b17249a0ef1a2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wynik ewaluacji Yes.\n",
      "✅ Odpowiedź zaakceptowana:\n",
      "RAG łączy dopasowanie kontekstu z generacją odpowiedzi.\n"
     ]
    }
   ],
   "execution_count": 28
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
