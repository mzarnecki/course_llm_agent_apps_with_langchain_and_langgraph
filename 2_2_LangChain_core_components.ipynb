{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.2. Komponenty biblioteki LangChain",
   "id": "be304df0c16cc932"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Instalacja bibliotek",
   "id": "a4b1b26363bfed05"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-02T19:01:19.796819Z",
     "start_time": "2025-10-02T19:01:18.154555Z"
    }
   },
   "source": "!pip install -q python-dotenv langchain langchain-openai langchain-community",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Konfiguracja .env i modelu",
   "id": "20734714333be78c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T18:59:52.492130Z",
     "start_time": "2025-10-02T18:59:49.951039Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Jesteś pomocnym asystentem. Odpowiadaj zwięźle.\"),\n",
    "    (\"user\", \"Streśc w 1 zdaniu: {tekst}\")\n",
    "])\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()  # LCEL: prompt → model → parser\n",
    "result = chain.invoke({\"tekst\": \"LangChain to biblioteka, która powstała w 2022 roku, w momencie kiedy świat zaczął odkrywać praktyczne możliwości dużych modeli językowych takich jak GPT-5. Jej twórcy zauważyli, że większość projektów opartych na LLM powtarza podobne wzorce – na przykład łączenie promptów w sekwencje, przechowywanie kontekstu rozmowy, wykonywanie zapytań do baz danych oraz wyszukiwarek. Zamiast budować to wszystko od zera, stworzyli bibliotekę, która dostarcza gotowe klocki do składania aplikacji. Dzięki LangChain możemy szybko tworzyć prototypy, a później rozwijać je w kierunku produkcyjnym. Biblioteka stała się swoistym standardem w świecie deweloperów AI, bo pozwala łatwo integrować modele różnych dostawców – nie tylko OpenAI, ale też Anthropic, HuggingFace czy lokalne modele open-source.\"})\n",
    "print(result)\n"
   ],
   "id": "fd2b0cdbcb177adb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain to biblioteka stworzona w 2022 roku, która ułatwia tworzenie aplikacji opartych na dużych modelach językowych, oferując gotowe komponenty do integracji i prototypowania, co czyni ją standardem wśród deweloperów AI.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Prompt template\n",
    "ChatPromptTemplate w LangChain to szablon do budowania ustrukturyzowanych promptów dla modeli czatu.\n",
    "Pozwala definiować role (system, user, assistant), zmienne i format wiadomości, aby w spójny i wielokrotnego użytku sposób generować wejścia dla LLM."
   ],
   "id": "9f0f36cc0a222968"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T18:59:55.872564Z",
     "start_time": "2025-10-02T18:59:53.568198Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-4o\")\n",
    "template = \"\"\"\n",
    "Specify tags and the main topic of the text.\n",
    "tags: What are best tags describing text. Give maximum 5 tags separated by comma.\n",
    "topic: What is the topic of text. Use maximum couple of words\n",
    "\n",
    "Format response as JSON as below. Return only JSON without markdown tags.\n",
    "'tags': ['sometag', 'othertag', 'anothertag', 'tag4', 'tag5']\n",
    "'subject': 'Some subject of text'\n",
    "\n",
    "text: {input}\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(template=template)\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "chain.invoke({\"input\":\"They picked a way among the trees, and their ponies plodded along, carefully avoiding the many writhing and interlacing roots.  There was no undergrowth.  The ground was rising steadily, and as they went forward it seemed that the trees became taller, darker, and thicker. There was no sound, except an occasional drip of moisture falling through the still leaves.  For the moment there was no whispering or movement among the branches; but they all got an uncomfortable feeling that they were being watched with disapproval, deepening to dislike and even enmity.  The feeling steadily grew, until they found themselves looking up quickly, or glancing back over their shoulders, as if they expected a sudden blow.\"})"
   ],
   "id": "58d640276960a0c0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{\\n    'tags': ['forest', 'suspense', 'mystery', 'nature', 'tension'],\\n    'subject': 'Journey through forest'\\n}\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### ResponseSchema i OutputParser\n",
    "ResponseSchema w LangChain to definicja oczekiwanego formatu odpowiedzi (np. pola JSON z nazwą, typem, opisem), która pomaga modelowi zwracać dane w przewidywalnej strukturze.\n",
    "\n",
    "OutputParser interpretuje surową odpowiedź LLM i przekształca ją w żądaną formę (np. obiekt Pydantic, JSON, lista), ułatwiając dalsze użycie w aplikacji."
   ],
   "id": "c7e817465b616462"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T18:59:59.170277Z",
     "start_time": "2025-10-02T18:59:57.461210Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser\n",
    "\n",
    "tags_schema = ResponseSchema(\n",
    "    name=\"tags\",\n",
    "    description=\" What are best tags describing text. Give maximum 5 tags separated by comma.\",\n",
    ")\n",
    "topic_schema = ResponseSchema(\n",
    "    name=\"topic\",\n",
    "    description=\"What is the topic of text. Use maximum couple of words.\"\n",
    ")\n",
    "\n",
    "response_schemas = [tags_schema, topic_schema]\n",
    "parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "instructions = parser.get_format_instructions()\n",
    "\n",
    "template = \"\"\"\n",
    "Specify tags and the main topic of the text. Return only JSON without markdown tags.\n",
    "tags: What are best tags describing text. Give maximum 5 tags separated by comma.\n",
    "topic: What is the topic of text. Use maximum couple of words\n",
    "\n",
    "Format response as JSON as below:\n",
    "'tags': ['sometag', 'othertag', 'anothertag', 'tag4', 'tag5']\n",
    "'subject': 'Some subject of text'\n",
    "\n",
    "text: {input}\n",
    "\n",
    "{instructions}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template=template)\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.0)\n",
    "chain = prompt | llm | parser\n",
    "output_dict = chain.invoke({\n",
    "    \"input\":\"They picked a way among the trees, and their ponies plodded along, carefully avoiding the many writhing and interlacing roots.  There was no undergrowth.  The ground was rising steadily, and as they went forward it seemed that the trees became taller, darker, and thicker. There was no sound, except an occasional drip of moisture falling through the still leaves.  For the moment there was no whispering or movement among the branches; but they all got an uncomfortable feeling that they were being watched with disapproval, deepening to dislike and even enmity.  The feeling steadily grew, until they found themselves looking up quickly, or glancing back over their shoulders, as if they expected a sudden blow.\",\n",
    "    \"instructions\":instructions})\n",
    "print(output_dict)"
   ],
   "id": "765ef2a9b758f243",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tags': ['fantasy', 'adventure', 'mystery', 'forest', 'suspense'], 'topic': 'Journey through the forest'}\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
