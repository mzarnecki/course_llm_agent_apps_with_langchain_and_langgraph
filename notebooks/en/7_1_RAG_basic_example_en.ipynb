{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18aff68d57dfa9f",
   "metadata": {},
   "source": [
    "## Retrieval Augmented Generation (RAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abbfab0c5f365cf",
   "metadata": {},
   "source": "### Install libraries"
  },
  {
   "cell_type": "code",
   "id": "534b948b01e54cb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T11:18:25.545072Z",
     "start_time": "2025-11-10T11:18:24.170362Z"
    }
   },
   "source": [
    "!pip install langchain_text_splitters"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_text_splitters in /home/michal/anaconda3/lib/python3.13/site-packages (1.0.0)\r\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain_text_splitters) (1.0.4)\r\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain_text_splitters) (1.33)\r\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain_text_splitters) (0.4.42)\r\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain_text_splitters) (24.2)\r\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain_text_splitters) (2.11.10)\r\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain_text_splitters) (6.0.2)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain_text_splitters) (9.0.0)\r\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain_text_splitters) (4.15.0)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/michal/anaconda3/lib/python3.13/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain_text_splitters) (3.0.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_text_splitters) (0.28.1)\r\n",
      "Requirement already satisfied: orjson>=3.9.14 in /home/michal/anaconda3/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_text_splitters) (3.10.14)\r\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_text_splitters) (1.0.0)\r\n",
      "Requirement already satisfied: requests>=2.0.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_text_splitters) (2.32.5)\r\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_text_splitters) (0.23.0)\r\n",
      "Requirement already satisfied: anyio in /home/michal/.local/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_text_splitters) (4.10.0)\r\n",
      "Requirement already satisfied: certifi in /home/michal/anaconda3/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_text_splitters) (2025.8.3)\r\n",
      "Requirement already satisfied: httpcore==1.* in /home/michal/.local/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_text_splitters) (1.0.9)\r\n",
      "Requirement already satisfied: idna in /home/michal/anaconda3/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_text_splitters) (3.7)\r\n",
      "Requirement already satisfied: h11>=0.16 in /home/michal/.local/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_text_splitters) (0.16.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain_text_splitters) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/michal/anaconda3/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain_text_splitters) (2.33.2)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain_text_splitters) (0.4.0)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/michal/anaconda3/lib/python3.13/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_text_splitters) (3.3.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/michal/anaconda3/lib/python3.13/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_text_splitters) (2.5.0)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/michal/.local/lib/python3.13/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_text_splitters) (1.3.1)\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "eb8d5442171267e3",
   "metadata": {},
   "source": "### Building VectorStore (FAISS) and Retriever"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-10T11:18:35.253514Z",
     "start_time": "2025-11-10T11:18:25.551569Z"
    }
   },
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "docs = [\n",
    "    \"LangChain is a framework for working with LLM.\",\n",
    "    \"RAG combines context retrieval with answer generation.\",\n",
    "    \"FAISS is a library for storing and searching embeddings.\",\n",
    "    \"Retriever is used to find the most similar documents to the user's queries. The retriever can return a variable number of matching documents, specified in the k parameter. The retriever uses various text similarity algorithms, e.g., cosine matching, Euclidean distance, MMR.\"\n",
    "]\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=20)\n",
    "split = splitter.create_documents(docs)\n",
    "\n",
    "print(f\"Number of chunks: {len(split)}\")\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_documents(split, embedding=embeddings)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    "\n",
    "query = \"Why use a retriever?\"\n",
    "\n",
    "context = retriever.invoke(query)\n",
    "print(\"Retrieved chunk:\")\n",
    "for i, c in enumerate(context, 1):\n",
    "    print(f\"{i}.\", c.page_content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 7\n",
      "Retrieved chunk:\n",
      "1. Retriever is used to find the most similar documents to the user's queries. The retriever can return\n",
      "2. The retriever uses various text similarity algorithms, e.g., cosine matching, Euclidean distance,\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "b38b755be95529a1",
   "metadata": {},
   "source": "### Simple chain RAG (prompt + context + LLM)"
  },
  {
   "cell_type": "code",
   "id": "a500f01ecc94fa8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T11:18:36.682290Z",
     "start_time": "2025-11-10T11:18:35.308590Z"
    }
   },
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Give precise answers based solely on CONTEXT. If there is no data, say you don't know.\"),\n",
    "    (\"system\", \"CONTEXT:\\\\n{context}\"),\n",
    "    (\"user\", \"{question}\")\n",
    "])\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(rag_chain.invoke(\"What is FAISS and what is it for?\"))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS is a library for storing and searching embeddings.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "99540ca4f91ca9c2",
   "metadata": {},
   "source": "### Example RAG - full program"
  },
  {
   "cell_type": "code",
   "id": "5c3a659781bccd03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T11:18:38.327835Z",
     "start_time": "2025-11-10T11:18:36.737391Z"
    }
   },
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "#  Model\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "#  Source documents\n",
    "docs = [\n",
    "\"LangChain is a framework for working with LLM.\",\n",
    "\"RAG combines context matching with answer generation.\",\n",
    "\"FAISS is a library for storing and retrieving embeddings.\"\n",
    "]\n",
    "\n",
    "#  Split\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=50, chunk_overlap=10)\n",
    "splits = splitter.create_documents(docs)\n",
    "\n",
    "#  Embeddings + vector store\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_documents(splits, embedding=embeddings)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    "\n",
    "#  Prompt RAG\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Respond only to context:\\n{context}\"),\n",
    "    (\"user\", \"{question}\")\n",
    "])\n",
    "\n",
    "#  Pipeline\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": lambda x: retriever.invoke(x[\"question\"]),\n",
    "        \"question\": lambda x: x[\"question\"]\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "\n",
    "print(rag_chain.invoke({\"question\": \"What is FAISS?\"}))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS is a library for storing and retrieving embeddings, which are numerical representations of data, often used in machine learning and information retrieval tasks.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "fa40afa881954fcd",
   "metadata": {},
   "source": "### RAG with loop and evaluation"
  },
  {
   "cell_type": "code",
   "id": "bf6b17249a0ef1a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T11:18:40.576618Z",
     "start_time": "2025-11-10T11:18:38.381377Z"
    }
   },
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "eval_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Evaluate answer.\"),\n",
    "    (\"user\", \"Question: {question}\\\\nAnswer: {answer}\\\\nIs the answer correct? Respond with only 'yes' or 'no'.\")\n",
    "])\n",
    "\n",
    "def rag_with_eval(question, max_retries):\n",
    "    for attempt in range(max_retries):\n",
    "        context = retriever.invoke(question)\n",
    "        answer = (prompt | llm | StrOutputParser()).invoke({\"context\": context, \"question\": question})\n",
    "        eval_result = (eval_prompt | llm | StrOutputParser()).invoke({\"question\": question, \"answer\": answer})\n",
    "        print(f\"Evaluation result {eval_result}\")\n",
    "        if \"yes\" in eval_result.lower():\n",
    "            return f\"✅ Answer approved:\\\\n{answer}\"\n",
    "        print(f\"❌ Answer: {answer}\\\\n rejected, retrying...\")\n",
    "    return \"Could not get the correct answer.\"\n",
    "\n",
    "print(rag_with_eval(\"What is RAG?\", max_retries=3))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result Yes.\n",
      "✅ Answer approved:\\nRAG stands for Retrieval-Augmented Generation. It combines context matching with answer generation, allowing for more accurate and contextually relevant responses by retrieving information from a knowledge base before generating an answer.\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
