{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain 1.X.X+ – New Syntax: Create_Agent, Messages, Structured Output, Memory, Middleware, Streaming, MCP\n",
    "\n",
    "This notebook is an **additional supplement** to the course – it demonstrates several key elements of the new LangChain (1.x) syntax, particularly the API around `create_agent`.\n",
    "The course uses examples using langchain_classic in many places, which can be replaced by the simplified LangChain syntax in versions above 1.x."
   ],
   "id": "15234553dfc72ae"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Instalacja bibliotek",
   "id": "7ebcee7b434ca1fe"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-23T21:00:29.577918434Z",
     "start_time": "2026-01-23T21:00:27.640215533Z"
    }
   },
   "source": "!pip install -q langchain python-dotenv langchain_mcp_adapters fastmcp",
   "id": "aec4a0e85b079adb",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-23T21:00:29.693190490Z",
     "start_time": "2026-01-23T21:00:29.581631724Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ],
   "id": "50ec4267dd9f57f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create_agent\n",
    "\n",
    "In the new syntax, the agent is created by `create_agent(model=..., tools=[...], ...)` and invoked by `invoke()`."
   ],
   "id": "76139e9b5a11b788"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-23T21:00:47.097717910Z",
     "start_time": "2026-01-23T21:00:29.707448955Z"
    }
   },
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "def rate_city(city: str) -> str:\n",
    "    \"\"\"Rate the city.\"\"\"\n",
    "    return f\"{city} is the best place in the world!\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-5-mini\",\n",
    "    tools=[rate_city],\n",
    "    system_prompt=\"You are a helpful assistant\",\n",
    ")\n",
    "\n",
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Is Poznań a nice city?.\"}]})\n",
    "\n",
    "last_msg = result[\"messages\"][-1]\n",
    "print(last_msg.content)\n"
   ],
   "id": "620d6212a116498",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Short answer: Yes — Poznań is widely considered a very pleasant city. It’s a lively regional capital with a compact, walkable center, rich history, good cultural life, and a strong student and business presence.\n",
      "\n",
      "Highlights\n",
      "- Historic Old Market Square (Stary Rynek) with the Renaissance town hall and the famous billy goats display.\n",
      "- Ostrów Tumski (Cathedral Island) — Poland’s oldest cathedral and medieval roots.\n",
      "- Parks and green spaces — Citadel Park, Lake Malta (recreation, rowing, winter toboggan), good for cycling and outdoor activities.\n",
      "- Culture and shopping — National Museum, theatres, Stary Browar (shopping + contemporary art).\n",
      "- Food scene — regional dishes (pyry z gzikiem), cafes, bakeries; try rogale świętomarcińskie (St. Martin’s croissants).\n",
      "- Student city vibe — several universities, lively nightlife and events targeted at young people.\n",
      "- Economy and transport — important business hub, good tram/bus network and an international airport with connections across Europe.\n",
      "\n",
      "Things to be aware of\n",
      "- Weather can be chilly and gray in winter; summers are pleasant but not as hot as southern Europe.\n",
      "- Less touristy than Kraków or Warsaw, so fewer tourist traps but also fewer international tourist amenities.\n",
      "- Some areas are more modern/industrial; the most charming parts are concentrated in the center and the old islands.\n",
      "\n",
      "Safety, cost, and practicalities\n",
      "- Generally safe; standard city precautions apply.\n",
      "- Cost of living is lower than Warsaw and many Western European cities, but rising in recent years.\n",
      "- Public transport and cycling infrastructure are good; the city center is very walkable.\n",
      "- Pronunciation tip: Poznań ≈ “POZ-nahn”.\n",
      "\n",
      "Who tends to like it\n",
      "- People who enjoy history without overwhelming crowds, students and young professionals, families who want parks and a calmer city life, and business travelers.\n",
      "\n",
      "If you tell me your priorities (history, nightlife, outdoors, family-friendly, budget), I can say more about whether Poznań would be a great fit for you and suggest specific places or activities.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Messages – Message Objects\n",
    "\n",
    "LangChain standardizes messages as objects (`SystemMessage`, `HumanMessage`, `AIMessage`, `ToolMessage`) and allows them to be used with chat models."
   ],
   "id": "bf46922bfbd6d84f"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-23T21:00:54.866013381Z",
     "start_time": "2026-01-23T21:00:47.171709881Z"
    }
   },
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.messages import SystemMessage, HumanMessage\n",
    "\n",
    "chat = init_chat_model(\"gpt-5-mini\")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"You are a concise assistant.\"),\n",
    "    HumanMessage(\"Write a 1-sentence summary of what LangChain is.\"),\n",
    "]\n",
    "\n",
    "ai_msg = chat.invoke(messages)  # -> AIMessage\n",
    "print(ai_msg.content)"
   ],
   "id": "72fe78325f6db316",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is an open-source framework for building applications with large language models that provides abstractions for prompts, chains, agents, memory, and integrations with external data sources and tools.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured output – `response_format` in `create_agent`\n",
    "\n",
    "Instead of parsing text, you can ask the agent to return data that conforms to a type (e.g., a Pydantic model).\n",
    "The result is then sent to `result[\"structured_response\"]`."
   ],
   "id": "3a8e8b879fcf2030"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-23T21:00:58.056980276Z",
     "start_time": "2026-01-23T21:00:54.880197472Z"
    }
   },
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "class ContactInfo(BaseModel):\n",
    "    \"\"\"Contact information for a person.\"\"\"\n",
    "    name: str = Field(description=\"The name of the person\")\n",
    "    email: str = Field(description=\"The email address\")\n",
    "    phone: str = Field(description=\"The phone number\")\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-5-mini\",\n",
    "    response_format=ContactInfo,\n",
    ")\n",
    "\n",
    "result = agent.invoke({\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"Extract contact info from: John Doe, john@example.com, (555) 123-4567\"}\n",
    "    ]\n",
    "})\n",
    "\n",
    "structured = result[\"structured_response\"]\n",
    "print(structured)\n",
    "print(type(structured))\n"
   ],
   "id": "815d89d7f5a0553f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='John Doe' email='john@example.com' phone='(555) 123-4567'\n",
      "<class '__main__.ContactInfo'>\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short‑term memory\n",
    "\n",
    "In LangChain 1.X.X, *short‑term* memory is implemented by a dedicated InMemorySaver component.\n",
    "\n",
    "- `InMemorySaver()` keeps state in the process's memory (ideal for notebooks)\n",
    "- `thread_id` identifies the \"conversation thread\" (important for multiple `invoke()`)\n"
   ],
   "id": "4d218551f2252cae"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-23T21:01:04.492271698Z",
     "start_time": "2026-01-23T21:00:58.107445576Z"
    }
   },
   "source": [
    "from langchain.agents import create_agent\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-5-mini\",\n",
    "    checkpointer=checkpointer,\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"demo-thread-1\"}}\n",
    "\n",
    "agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Hi! My name is Michael.\"}]}, config=config)\n",
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"What is my name?\"}]}, config=config)\n",
    "print(result[\"messages\"][-1].content)\n"
   ],
   "id": "ebe3710f4e4ad35",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your name is Michael.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Middleware - Human‑in‑the‑loop middleware\n",
    "\n",
    "Middleware allows you to \"hook in\" to the agent's execution.\n",
    "Typical scenario: the agent can *read* data, but actions like *sending email/writing to the database* require approval.\n",
    "Human‑in‑the‑loop – stopping before running selected tools and resuming with `Command(resume=...)`."
   ],
   "id": "208b7a469b1fe5bf"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-23T21:01:07.986949619Z",
     "start_time": "2026-01-23T21:01:04.522675951Z"
    }
   },
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import HumanInTheLoopMiddleware\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.types import Command\n",
    "\n",
    "def read_email(email_id: str) -> str:\n",
    "    \"\"\"Read email mock function\"\"\"\n",
    "    return f\"(mock) Email content for id={email_id}\"\n",
    "\n",
    "def send_email(recipient: str, subject: str, body: str) -> str:\n",
    "    \"\"\"Send email mock function\"\"\"\n",
    "    return f\"(mock) Sent email to {recipient} with subject={subject} and content={body}\"\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-5-mini\",\n",
    "    tools=[read_email, send_email],\n",
    "    checkpointer=checkpointer,\n",
    "    middleware=[\n",
    "        HumanInTheLoopMiddleware(\n",
    "            interrupt_on={\n",
    "                \"send_email\": {\"allowed_decisions\": [\"approve\", \"edit\", \"reject\"]},\n",
    "                \"read_email\": False,\n",
    "            }\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"hitl-demo\"}}\n",
    "\n",
    "paused = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Send an email to alice@example.com with subject 'Hi' and say hello.\"}]},\n",
    "    config=config,\n",
    ")\n",
    "print(\"Paused state keys:\", paused.keys())"
   ],
   "id": "ed8943c512ff4890",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paused state keys: dict_keys(['messages', '__interrupt__'])\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-23T21:01:09.963744523Z",
     "start_time": "2026-01-23T21:01:08.011239318Z"
    }
   },
   "cell_type": "code",
   "source": [
    "resumed = agent.invoke(\n",
    "    Command(resume={\"decisions\": [{\"type\": \"approve\"}]}),\n",
    "    config=config,\n",
    ")\n",
    "print(resumed[\"messages\"][-1].content)"
   ],
   "id": "3c43e143b7baceb3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done — I sent the email to alice@example.com with subject \"Hi\" and message \"Hello.\"\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Middleware - Guardrails – PII middleware\n",
    "\n",
    "We can also use guardrails as middleware, for example, to protect against sensitive data leaks in LLM responses."
   ],
   "id": "aa530874f89ba981"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-23T21:01:14.719239470Z",
     "start_time": "2026-01-23T21:01:09.987821348Z"
    }
   },
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import PIIMiddleware\n",
    "\n",
    "def echo(text: str) -> str:\n",
    "    \"\"\"Print text.\"\"\"\n",
    "    return text\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-5-mini\",\n",
    "    tools=[echo],\n",
    "    middleware=[\n",
    "        PIIMiddleware(\"email\", strategy=\"redact\", apply_to_input=True),\n",
    "        PIIMiddleware(\"credit_card\", strategy=\"mask\", apply_to_input=True),\n",
    "        PIIMiddleware(\n",
    "            \"api_key\",\n",
    "            detector=r\"sk-[a-zA-Z0-9]{32}\",\n",
    "            strategy=\"block\",\n",
    "            apply_to_input=True,\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "out = agent.invoke({\n",
    "    \"messages\": [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Extract information from text: My email is john@example.com and card is 5105-1051-0510-5100\"\n",
    "    }]\n",
    "})\n",
    "print(out[\"messages\"][-1].content)\n"
   ],
   "id": "817a34949d01b675",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"email\":\"[REDACTED_EMAIL]\",\"card_masked\":\"****-****-****-5100\",\"card_last4\":\"5100\"}\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming\n",
    "\n",
    "In LangChain, we can return partial responses or subsequent generated tokens \"on the fly\":\n",
    "- **agent progress** (`stream_mode=\"updates\"`) – event after each step\n",
    "- **tokens/model messages** (`stream_mode=\"messages\"`) – UI-friendly"
   ],
   "id": "c7328314668ba532"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-23T21:01:56.541556609Z",
     "start_time": "2026-01-23T21:01:14.770577862Z"
    }
   },
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "def rate_city(city: str) -> str:\n",
    "    \"\"\"Rate city mock tool.\"\"\"\n",
    "    return f\"The best city is {city}!\"\n",
    "\n",
    "agent = create_agent(model=\"gpt-5\", tools=[rate_city])\n",
    "\n",
    "for chunk in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Is Poznań a nice city?  Rate city and afterwards plan a trip to Poznań in 5 stages.\"}]},\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    for step, data in chunk.items():\n",
    "        last = data[\"messages\"][-1]\n",
    "        print(f\"step: {step:>6} | type={type(last).__name__}\")\n",
    "        try:\n",
    "            print(\"content_blocks:\", last.content_blocks)\n",
    "        except Exception:\n",
    "            print(\"content:\", getattr(last, \"content\", None))\n"
   ],
   "id": "bff4b1e2ae1e6262",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:  model | type=AIMessage\n",
      "content_blocks: [{'type': 'tool_call', 'id': 'call_CbzKk3CJWmId1tn7Oi7fMewg', 'name': 'rate_city', 'args': {'city': 'Poznań'}}]\n",
      "step:  tools | type=ToolMessage\n",
      "content_blocks: [{'type': 'text', 'text': 'The best city is Poznań!'}]\n",
      "step:  model | type=AIMessage\n",
      "content_blocks: [{'type': 'text', 'text': 'Rating: The best city is Poznań!\\n\\n5-stage trip plan to Poznań:\\n1) Arrival + Old Town essentials\\n- Stary Rynek (Old Market Square), colorful merchant houses, Town Hall goats at noon.\\n- Royal Castle terrace view; Rogalowe Muzeum Poznania (St. Martin croissant show).\\n- Dinner and shopping/art at Stary Browar; evening stroll around Plac Wolności.\\n\\n2) History and culture loop\\n- Ostrów Tumski (Cathedral Island): Archcathedral Basilica, underground remains.\\n- Porta Posnania interactive heritage center; Śródka district murals and cafés.\\n- National Museum (Polish masters) or BrAMA (Fort VII memory site) if you prefer 20th‑century history.\\n\\n3) Green Poznań and Lake Malta\\n- Walk/cycle around Lake Malta; Maltanka mini-rail (seasonal), New Zoo.\\n- Malta Thermal Baths (spa/waterpark) or kayaking on the Warta in summer.\\n- Park Cytadela: military museum, Wójtowicz sculptures, peaceful lawns.\\n\\n4) Neighborhoods and local flavor\\n- Jeżyce: breakfast cafés, Jeżycki Market, modern bistros.\\n- Sołacz: garden-city villas, park stroll; Wilson Park and Palm House (palmiarnia).\\n- Street-art and indie bars along ul. Taczaka/Św. Marcin; sunset on Warta river boulevards (KontenerART in summer).\\n\\n5) Day trip + food crawl + departure\\n- Half-day options: Rogalin Palace and ancient oaks; Kórnik Castle + arboretum; or Gniezno (first Polish capital).\\n- Food to try: pyry z gzikiem (potatoes with curd), duck with dumplings, St. Martin croissant, local craft beers.\\n- Pick up souvenirs at Bamberka House or Stary Browar design shops; tram to station/airport.\\n\\nTips:\\n- 2–3 days is ideal; best seasons: May–September, or Nov 11 for St. Martin croissants festival.\\n- Get a Poznań City Card for transit + museum discounts; trams are the easiest way around.'}]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCP – Model Context Protocol\n",
    "\n",
    "MCP standardizes the use of external tools through LLM.\n",
    "At LangChain, we use the `langchain-mcp-adapters` adapter and the `MultiServerMCPClient` client, which can retrieve a list of tools from multiple servers."
   ],
   "id": "96fecd1bd18c3101"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minimal MCP server (FastMCP)\n",
    "Save the code below as `math_server.py` in same folder as this notebook."
   ],
   "id": "8bbfe203a981dbee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T19:14:05.118460164Z",
     "start_time": "2026-01-01T19:14:05.036118748Z"
    }
   },
   "cell_type": "markdown",
   "source": [
    "```python\n",
    "from fastmcp import FastMCP\n",
    "\n",
    "mcp = FastMCP(\"Math\")\n",
    "\n",
    "@mcp.tool()\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"Add two numbers\"\n",
    "    return a + b\n",
    "\n",
    "@mcp.tool()\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"Multiply two numbers\"\n",
    "    return a * b\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run(transport=\"stdio\")\n",
    "```"
   ],
   "id": "21cff0693925f472"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "and run cell below:",
   "id": "584d7c2f76680d12"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-23T21:01:57.842827052Z",
     "start_time": "2026-01-23T21:01:56.593474712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import asyncio\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langchain.agents import create_agent\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def demo_mcp():\n",
    "    client = MultiServerMCPClient(\n",
    "        {\n",
    "            \"math\": {\n",
    "                \"transport\": \"stdio\",\n",
    "                \"command\": \"python\",\n",
    "                \"args\": [\"math_server.py\"],\n",
    "            },\n",
    "        }\n",
    "    )\n",
    "    tools = await client.get_tools()\n",
    "    agent = create_agent(\"gpt-5-mini\", tools)\n",
    "\n",
    "    r1 = await agent.ainvoke({\"messages\": [{\"role\": \"user\", \"content\": \"what's (3 + 5) x 12?\"}]})\n",
    "    print(r1[\"messages\"][-1].content)\n",
    "\n",
    "\n",
    "asyncio.run(demo_mcp())"
   ],
   "id": "40fd024097248f60",
   "outputs": [],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
