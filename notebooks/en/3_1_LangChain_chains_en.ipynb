{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3548fe4a952ca65f",
   "metadata": {},
   "source": [
    "## LangChain chains"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-05T06:58:34.351584Z",
     "start_time": "2025-11-05T06:58:32.840066Z"
    }
   },
   "source": [
    "!pip install -q langchain langchain-openai python-dotenv"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.3\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "cd970036ab362bbd",
   "metadata": {},
   "source": "### Simple chain: prompt → model → result"
  },
  {
   "cell_type": "code",
   "id": "e5d97fe610b0504",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T06:58:56.242041Z",
     "start_time": "2025-11-05T06:58:34.360612Z"
    }
   },
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a Python programming expert and an AI genius.\"),\n",
    "    (\"user\", \"Write a code related to {topic}\")\n",
    "])\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "result = chain.invoke({'topic': 'AGI'})\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "7c9889063b3f8268",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T06:58:56.315790Z",
     "start_time": "2025-11-05T06:58:56.313475Z"
    }
   },
   "source": [
    "print(result)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a code snippet related to Artificial General Intelligence (AGI) is a complex task, as AGI refers to a type of AI that can understand, learn, and apply knowledge across a wide range of tasks, similar to human intelligence. However, I can provide a simplified example that demonstrates some foundational concepts that could be part of an AGI system, such as learning from experience and making decisions based on that learning.\n",
      "\n",
      "Below is a Python code snippet that simulates a basic reinforcement learning agent. This agent learns to navigate a simple grid environment to reach a goal. While this is far from AGI, it illustrates some principles of learning and decision-making.\n",
      "\n",
      "```python\n",
      "import numpy as np\n",
      "import random\n",
      "\n",
      "class GridEnvironment:\n",
      "    def __init__(self, size, goal):\n",
      "        self.size = size\n",
      "        self.goal = goal\n",
      "        self.state = (0, 0)  # Start at the top-left corner\n",
      "\n",
      "    def reset(self):\n",
      "        self.state = (0, 0)\n",
      "        return self.state\n",
      "\n",
      "    def step(self, action):\n",
      "        x, y = self.state\n",
      "        if action == 'up' and x > 0:\n",
      "            x -= 1\n",
      "        elif action == 'down' and x < self.size - 1:\n",
      "            x += 1\n",
      "        elif action == 'left' and y > 0:\n",
      "            y -= 1\n",
      "        elif action == 'right' and y < self.size - 1:\n",
      "            y += 1\n",
      "\n",
      "        self.state = (x, y)\n",
      "        reward = 1 if self.state == self.goal else -0.1\n",
      "        done = self.state == self.goal\n",
      "        return self.state, reward, done\n",
      "\n",
      "class QLearningAgent:\n",
      "    def __init__(self, actions, learning_rate=0.1, discount_factor=0.9):\n",
      "        self.q_table = {}\n",
      "        self.actions = actions\n",
      "        self.learning_rate = learning_rate\n",
      "        self.discount_factor = discount_factor\n",
      "\n",
      "    def get_q_value(self, state, action):\n",
      "        return self.q_table.get((state, action), 0.0)\n",
      "\n",
      "    def choose_action(self, state, epsilon):\n",
      "        if random.random() < epsilon:\n",
      "            return random.choice(self.actions)  # Explore\n",
      "        else:\n",
      "            q_values = [self.get_q_value(state, a) for a in self.actions]\n",
      "            max_q = max(q_values)\n",
      "            return self.actions[q_values.index(max_q)]  # Exploit\n",
      "\n",
      "    def update_q_value(self, state, action, reward, next_state):\n",
      "        best_next_q = max(self.get_q_value(next_state, a) for a in self.actions)\n",
      "        current_q = self.get_q_value(state, action)\n",
      "        new_q = current_q + self.learning_rate * (reward + self.discount_factor * best_next_q - current_q)\n",
      "        self.q_table[(state, action)] = new_q\n",
      "\n",
      "def main():\n",
      "    env = GridEnvironment(size=5, goal=(4, 4))\n",
      "    agent = QLearningAgent(actions=['up', 'down', 'left', 'right'])\n",
      "    episodes = 1000\n",
      "    epsilon = 0.1\n",
      "\n",
      "    for episode in range(episodes):\n",
      "        state = env.reset()\n",
      "        done = False\n",
      "\n",
      "        while not done:\n",
      "            action = agent.choose_action(state, epsilon)\n",
      "            next_state, reward, done = env.step(action)\n",
      "            agent.update_q_value(state, action, reward, next_state)\n",
      "            state = next_state\n",
      "\n",
      "    print(\"Training complete. Q-values:\")\n",
      "    for key, value in agent.q_table.items():\n",
      "        print(f\"State: {key[0]}, Action: {key[1]}, Q-value: {value:.2f}\")\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "1. **GridEnvironment**: This class represents a simple grid where the agent can move. The goal is to reach a specific cell in the grid.\n",
      "2. **QLearningAgent**: This class implements a Q-learning agent that learns to navigate the grid by updating its Q-values based on the rewards it receives.\n",
      "3. **Main Function**: The main function initializes the environment and agent, runs multiple episodes of training, and updates the Q-values based on the agent's actions.\n",
      "\n",
      "### Note:\n",
      "This code is a basic example of reinforcement learning and does not represent AGI. AGI would require much more complexity, including advanced reasoning, understanding, and the ability to transfer knowledge across different domains.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "2cac72131d772ec2",
   "metadata": {},
   "source": "### Sequential chain: 2 models in single sequence"
  },
  {
   "cell_type": "code",
   "id": "92240f604a750d3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T06:58:58.682729Z",
     "start_time": "2025-11-05T06:58:56.367822Z"
    }
   },
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# 1) Chain: summary (input: {text} → output: str)\n",
    "summary_chain = (\n",
    "    ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"Summarize the text below in 1–2 sentences.\"),\n",
    "        (\"user\", \"{text}\")\n",
    "    ])\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 2) Adapter: replace str → {\"text\": str} and pass to next prompt\n",
    "to_dict = RunnableLambda(lambda s: {\"text\": s})\n",
    "\n",
    "# 3) Chain: translate summary to french (input: {text} → output: str)\n",
    "translate_chain = (\n",
    "    ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"Translate the text into French.\"),\n",
    "        (\"user\", \"{text}\")\n",
    "    ])\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "sequential_chain = summary_chain | to_dict | translate_chain\n",
    "input_text = \"LangChain enables the creation of AI applications by combining models, prompts, and tools into coherent pipelines.\"\n",
    "\n",
    "final_translation = sequential_chain.invoke({\"text\": input_text})\n",
    "\n",
    "print(final_translation)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain facilite le développement d'applications d'IA en intégrant des modèles, des invites et des outils dans des flux de travail structurés.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "256cc9e98cf0ddff",
   "metadata": {},
   "source": "### Branching chain: one response, two processing"
  },
  {
   "cell_type": "code",
   "id": "783d3e92e71467ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T06:59:00.126248Z",
     "start_time": "2025-11-05T06:58:58.737348Z"
    }
   },
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "# summary prompt\n",
    "prompt_summary = ChatPromptTemplate.from_template(\"Summarize: {text}\")\n",
    "\n",
    "# sentiment prompt\n",
    "prompt_sentiment = ChatPromptTemplate.from_template(\"Classify sentiment: {text}\")\n",
    "\n",
    "branch_chain = RunnableParallel(\n",
    "    summary=(prompt_summary | llm | StrOutputParser()),\n",
    "    sentiment=(prompt_sentiment | llm | StrOutputParser())\n",
    ")\n",
    "\n",
    "text = \"I am very happy with this course, I learned a lot about LangChain! Now I know that LangChain enables the creation of AI applications by combining models, prompts, and tools into coherent pipelines.\"\n",
    "result = branch_chain.invoke({\"text\": text})\n",
    "\n",
    "print(result)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'summary': 'The course was highly beneficial, providing valuable insights into LangChain, which facilitates the development of AI applications by integrating models, prompts, and tools into cohesive pipelines.', 'sentiment': 'The sentiment of the statement is positive. The speaker expresses happiness and satisfaction with the course and indicates that they have gained valuable knowledge.'}\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
