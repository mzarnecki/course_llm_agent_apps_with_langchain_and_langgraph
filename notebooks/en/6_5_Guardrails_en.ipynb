{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": [
    "## Guardrails\n",
    "Guardrails in LangChain are mechanisms that ensure model responses meet specific technical or formatting requirements.\n",
    "For example, the JsonValidityEvaluator checks whether the returned text is valid JSON â€“ if the structure is incorrect, the evaluator will return an error.\n",
    "This allows you to automatically detect and reject responses that are not suitable for further processing."
   ],
   "id": "8843f9eae98bb3a4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### JSON Format Validator\n",
    "Checks if the generated response is valid JSON"
   ],
   "id": "963e720e47fbc32e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T11:06:45.152035Z",
     "start_time": "2025-11-09T11:06:42.609677Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_classic.evaluation import JsonValidityEvaluator\n",
    "\n",
    "evaluator = JsonValidityEvaluator()\n",
    "# print(evaluator.evaluate_strings(prediction='{\"x\": 1}'))      # correct\n",
    "print(evaluator.evaluate_strings(prediction='{x: 1}'))        # incorrect\n"
   ],
   "id": "51429117cf2939bb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0, 'reasoning': 'Expecting property name enclosed in double quotes: line 1 column 2 (char 1)'}\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### JsonEqualityEvaluator\n",
    "Checks the equality of JSONs after parsing (the order of keys in JSON does not matter)"
   ],
   "id": "6cb1491ea9f8286d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T11:06:45.165096Z",
     "start_time": "2025-11-09T11:06:45.161126Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_classic.evaluation import JsonEqualityEvaluator\n",
    "\n",
    "evaluator = JsonEqualityEvaluator()\n",
    "print(evaluator.evaluate_strings(\n",
    "    prediction='{\"a\":1,\"b\":[2,3]}',\n",
    "    reference='{\"b\":[2,3],\"a\":2}',\n",
    "))\n"
   ],
   "id": "a9b6c949f0ea4ddc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': False}\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### RegexMatchEvaluator\n",
    "Checks for a match against a regular expression"
   ],
   "id": "4a367a91398ca8bb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T11:06:45.221296Z",
     "start_time": "2025-11-09T11:06:45.216936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_classic.evaluation import RegexMatchStringEvaluator\n",
    "\n",
    "evaluator = RegexMatchStringEvaluator()\n",
    "result = evaluator.evaluate_strings(\n",
    "    prediction=\"Order ID: ABC-1234\",\n",
    "    reference=r\"^Order ID: [A-Z]{3}-\\d{4}$\",\n",
    ")\n",
    "print(result['score'])\n",
    "\n",
    "iter = 3\n",
    "while result['score'] < 1.0 and iter > 0:\n",
    "    iter -= 1\n",
    "    print('run model once more')"
   ],
   "id": "a879dcfff035934",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Fallback Messages Validator\n",
    "When the main model fails (rate limit / error) automatically use the backup model."
   ],
   "id": "392b8b0fc506ff11"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T11:06:47.263172Z",
     "start_time": "2025-11-09T11:06:45.271334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "primary = ChatOpenAI(model=\"gpt-4o-miniS\", max_retries=0)\n",
    "backup  = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "chain = primary.with_fallbacks([backup])\n",
    "\n",
    "print(chain.invoke(\"Describe Python in 1 sentence.\"))\n"
   ],
   "id": "ea1d15d55ae7e062",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Python is a versatile and user-friendly programming language known for its simplicity and readability.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 14, 'total_tokens': 30, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CZxXq6wdZu8Rwff4AfMJDNDh7ABEn', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--7c27ffd5-179c-43a8-ba8d-b5e8407f2529-0' usage_metadata={'input_tokens': 14, 'output_tokens': 16, 'total_tokens': 30, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Token Limit\n",
    "Tracking and pruning history to a token limit to avoid exceeding model context."
   ],
   "id": "39f6d9c66cfb3d10"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T11:06:48.718526Z",
     "start_time": "2025-11-09T11:06:47.321205Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_core.messages.utils import trim_messages, count_tokens_approximately\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"(long conversation history here / many messages...)\"),\n",
    "]\n",
    "\n",
    "trimmed = trim_messages(\n",
    "    messages,\n",
    "    strategy=\"last\",\n",
    "    token_counter=count_tokens_approximately,\n",
    "    max_tokens=256,\n",
    "    start_on=\"human\",\n",
    "    include_system=True,\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "print(json.dumps(llm.invoke(trimmed).response_metadata, indent=4))\n"
   ],
   "id": "f4f147d4e8dd6c4f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"token_usage\": {\n",
      "        \"completion_tokens\": 51,\n",
      "        \"prompt_tokens\": 25,\n",
      "        \"total_tokens\": 76,\n",
      "        \"completion_tokens_details\": {\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"audio_tokens\": 0,\n",
      "            \"reasoning_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "        },\n",
      "        \"prompt_tokens_details\": {\n",
      "            \"audio_tokens\": 0,\n",
      "            \"cached_tokens\": 0\n",
      "        }\n",
      "    },\n",
      "    \"model_provider\": \"openai\",\n",
      "    \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"system_fingerprint\": \"fp_560af6e559\",\n",
      "    \"id\": \"chatcmpl-CZxXrZEP6NDARAHV3gEdZqJBFF6PQ\",\n",
      "    \"service_tier\": \"default\",\n",
      "    \"finish_reason\": \"stop\",\n",
      "    \"logprobs\": null\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Word Limit\n",
    "Ask for a maximum of N words, count the words after each generation. If this number is exceeded, shorten the answer."
   ],
   "id": "d3b409e890c6ac61"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T11:06:49.715631Z",
     "start_time": "2025-11-09T11:06:48.824312Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "limit = 25\n",
    "prompt = f\"Write a summary in MAX {limit} words: What is machine learning?\"\n",
    "\n",
    "resp = llm.invoke(prompt).content\n",
    "if len(resp.split()) > limit:\n",
    "    # quick fix - ask the model to shorten to the limit\n",
    "    resp = llm.invoke(f\"Shorten this to max {limit} words, without any additions:\\n\\n{resp}\").content\n",
    "\n",
    "print(resp)\n"
   ],
   "id": "44ce2da6c0d8aaab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine learning is a subset of artificial intelligence that enables systems to learn and improve from data without explicit programming.\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
