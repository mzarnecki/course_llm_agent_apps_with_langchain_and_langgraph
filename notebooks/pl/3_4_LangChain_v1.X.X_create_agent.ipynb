{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain 1.X.X+ – nowa składnia: create_agent, messages, structured output, pamięć, middleware, streaming, MCP\n",
    "\n",
    "Ten notebook jest **dodatkowym uzupełnieniem** do kursu – pokazuje kilka kluczowych elementów z nowej składni LangChain (1.x), w szczególności API wokół `create_agent`.\n",
    "Kurs w wielu miejscach wykorzystuje przykłady z uzyciem langchain_classic, które mogą zostać zastąpione przez uproszconą składnię LangChain w wersji powyżej 1.x."
   ],
   "id": "15234553dfc72ae"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Instalacja bibliotek",
   "id": "7ebcee7b434ca1fe"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T17:02:22.845291591Z",
     "start_time": "2026-01-01T17:02:21.075005962Z"
    }
   },
   "source": "!pip install -q langchain python-dotenv",
   "id": "aec4a0e85b079adb",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T17:02:22.954406730Z",
     "start_time": "2026-01-01T17:02:22.850480611Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ],
   "id": "50ec4267dd9f57f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create_agent\n",
    "\n",
    "W nowej składni agent jest tworzony przez `create_agent(model=..., tools=[...], ...)` i wywoływany przez `invoke()`."
   ],
   "id": "76139e9b5a11b788"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T17:02:39.977328909Z",
     "start_time": "2026-01-01T17:02:24.009308120Z"
    }
   },
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "def rate_city(city: str) -> str:\n",
    "    \"\"\"Zwróć pogodę dla miasta.\"\"\"\n",
    "    return f\"{city} is the best place in the world!\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-5-mini\",\n",
    "    tools=[rate_city],\n",
    "    system_prompt=\"You are a helpful assistant\",\n",
    ")\n",
    "\n",
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Is Poznań a nice city?.\"}]})\n",
    "\n",
    "last_msg = result[\"messages\"][-1]\n",
    "print(last_msg.content)\n"
   ],
   "id": "620d6212a116498",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Short answer: yes — many people think Poznań is a very nice city. Whether you’ll enjoy it depends on what you like, but it has a lot of strengths.\n",
      "\n",
      "What’s good\n",
      "- Charming Old Town and Market Square with colorful townhouses and the Renaissance Town Hall (the billy goats at noon are famous).\n",
      "- Rich history and architecture (cathedral island Ostrów Tumski, Imperial Castle, interwar and modern buildings).\n",
      "- Strong cultural life: museums, theaters, festivals (Malta Festival, St. Martin’s Day celebrations, concerts).\n",
      "- Good food scene: traditional Poznań specialties (rogal świętomarciński), cafés, and an increasing number of international and trendy restaurants.\n",
      "- Lots of green space and outdoor options (Cytadela Park, Lake Malta — kayaking, promenades, and winter skating).\n",
      "- Student city vibe (Adam Mickiewicz University and others) — lively cafés, bars, and reasonably priced nightlife.\n",
      "- Convenient transport: trams and buses, international airport nearby, and good rail connections to other Polish cities.\n",
      "- Generally safe and more affordable than Warsaw or Kraków.\n",
      "\n",
      "Possible downsides\n",
      "- Winters can be cold and gray; summers are pleasant but not guaranteed.\n",
      "- Smaller and quieter than Warsaw; if you want a very big-city feel with nonstop international options, other capitals may be preferable.\n",
      "- Some tourist services and signage are better in Polish than in English, though most younger people speak some English.\n",
      "\n",
      "Who tends to like it\n",
      "- People who appreciate history, cafés, manageable city size, green spaces, and a lively student/cultural scene.\n",
      "- Travelers who want an authentic Polish city with fewer crowds than the biggest tourist hubs.\n",
      "\n",
      "If you’re planning a visit or a move, tell me whether it’s for tourism, study, work, or relocation and I’ll give tailored tips (where to stay, what to see in a day, neighborhoods to consider, etc.).\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Messages – obiekty wiadomości\n",
    "\n",
    "LangChain standaryzuje wiadomości jako obiekty (`SystemMessage`, `HumanMessage`, `AIMessage`, `ToolMessage`) i pozwala używać ich z modelami czatu."
   ],
   "id": "bf46922bfbd6d84f"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T17:05:29.863716506Z",
     "start_time": "2026-01-01T17:05:26.262894379Z"
    }
   },
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.messages import SystemMessage, HumanMessage\n",
    "\n",
    "chat = init_chat_model(\"gpt-5-mini\")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"You are a concise assistant.\"),\n",
    "    HumanMessage(\"Write a 1-sentence summary of what LangChain is.\"),\n",
    "]\n",
    "\n",
    "ai_msg = chat.invoke(messages)  # -> AIMessage\n",
    "print(ai_msg.content)"
   ],
   "id": "72fe78325f6db316",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is an open-source framework for building applications with large language models by connecting prompts, model APIs, memory, tools, and data sources into reusable chains and agent workflows.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured output – `response_format` w `create_agent`\n",
    "\n",
    "Zamiast parsować tekst, możesz poprosić agenta o zwrócenie danych zgodnych z typem (np. Pydantic model).\n",
    "Efekt trafia wtedy do `result[\"structured_response\"]`.\n"
   ],
   "id": "3a8e8b879fcf2030"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T17:14:00.290114913Z",
     "start_time": "2026-01-01T17:13:56.462488059Z"
    }
   },
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "class ContactInfo(BaseModel):\n",
    "    \"\"\"Contact information for a person.\"\"\"\n",
    "    name: str = Field(description=\"The name of the person\")\n",
    "    email: str = Field(description=\"The email address\")\n",
    "    phone: str = Field(description=\"The phone number\")\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-5-mini\",\n",
    "    response_format=ContactInfo,\n",
    ")\n",
    "\n",
    "result = agent.invoke({\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"Extract contact info from: John Doe, john@example.com, (555) 123-4567\"}\n",
    "    ]\n",
    "})\n",
    "\n",
    "structured = result[\"structured_response\"]\n",
    "print(structured)\n",
    "print(type(structured))\n"
   ],
   "id": "815d89d7f5a0553f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='John Doe' email='john@example.com' phone='(555) 123-4567'\n",
      "<class '__main__.ContactInfo'>\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short‑term memory\n",
    "\n",
    "W LangChain 1.X.X pamięć *krótkoterminowa* jest realizowana przez dedykowany komponent InMemorySaver.\n",
    "\n",
    "- `InMemorySaver()` trzyma stan w pamięci procesu (idealne do notebooka)\n",
    "- `thread_id` identyfikuje „wątek rozmowy” (ważne przy wielokrotnych `invoke()`)\n"
   ],
   "id": "4d218551f2252cae"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T17:14:30.593379003Z",
     "start_time": "2026-01-01T17:14:22.622982496Z"
    }
   },
   "source": [
    "from langchain.agents import create_agent\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-5-mini\",\n",
    "    checkpointer=checkpointer,\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"demo-thread-1\"}}\n",
    "\n",
    "agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Hi! My name is Michał.\"}]}, config=config)\n",
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"What is my name?\"}]}, config=config)\n",
    "print(result[\"messages\"][-1].content)\n"
   ],
   "id": "ebe3710f4e4ad35",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your name is Michał.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Middleware - Human‑in‑the‑loop middleware\n",
    "\n",
    "Middleware pozwala „wpiąć się” w wykonanie agenta.\n",
    "Typowy scenariusz: agent może *odczytywać* dane, ale akcje typu *wysyłka e‑maila / zapis do bazy* wymagają akceptacji.\n",
    "Human‑in‑the‑loop – zatrzymanie przed uruchomieniem wybranych narzędzi i wznowienie przez `Command(resume=...)`.\n"
   ],
   "id": "208b7a469b1fe5bf"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T17:18:06.467357322Z",
     "start_time": "2026-01-01T17:18:02.593596897Z"
    }
   },
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import HumanInTheLoopMiddleware\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.types import Command\n",
    "\n",
    "def read_email(email_id: str) -> str:\n",
    "    \"\"\"Read email mock function\"\"\"\n",
    "    return f\"(mock) Email content for id={email_id}\"\n",
    "\n",
    "def send_email(recipient: str, subject: str, body: str) -> str:\n",
    "    \"\"\"Send email mock function\"\"\"\n",
    "    return f\"(mock) Sent email to {recipient} with subject={subject} and content={body}\"\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-5-mini\",\n",
    "    tools=[read_email, send_email],\n",
    "    checkpointer=checkpointer,\n",
    "    middleware=[\n",
    "        HumanInTheLoopMiddleware(\n",
    "            interrupt_on={\n",
    "                \"send_email\": {\"allowed_decisions\": [\"approve\", \"edit\", \"reject\"]},\n",
    "                \"read_email\": False,\n",
    "            }\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"hitl-demo\"}}\n",
    "\n",
    "paused = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Send an email to alice@example.com with subject 'Hi' and say hello.\"}]},\n",
    "    config=config,\n",
    ")\n",
    "print(\"Paused state keys:\", paused.keys())"
   ],
   "id": "ed8943c512ff4890",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paused state keys: dict_keys(['messages', '__interrupt__'])\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T17:18:09.846066948Z",
     "start_time": "2026-01-01T17:18:06.469917531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "resumed = agent.invoke(\n",
    "    Command(resume={\"decisions\": [{\"type\": \"approve\"}]}),\n",
    "    config=config,\n",
    ")\n",
    "print(resumed[\"messages\"][-1].content)"
   ],
   "id": "3c43e143b7baceb3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done — I sent the email to alice@example.com with subject \"Hi\" and body \"Hello.\"\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Middleware -Guardrails – PII middleware\n",
    "\n",
    "Jako middelware możemy też skorzystać z gurdrails czyli np. zabezpieczenia przed wyciekiem danych wrażliwych w odpowiedzi LLM."
   ],
   "id": "aa530874f89ba981"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T17:22:36.570683691Z",
     "start_time": "2026-01-01T17:22:30.589264699Z"
    }
   },
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import PIIMiddleware\n",
    "\n",
    "def echo(text: str) -> str:\n",
    "    \"\"\"Print text.\"\"\"\n",
    "    return text\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-5-mini\",\n",
    "    tools=[echo],\n",
    "    middleware=[\n",
    "        PIIMiddleware(\"email\", strategy=\"redact\", apply_to_input=True),\n",
    "        PIIMiddleware(\"credit_card\", strategy=\"mask\", apply_to_input=True),\n",
    "        PIIMiddleware(\n",
    "            \"api_key\",\n",
    "            detector=r\"sk-[a-zA-Z0-9]{32}\",\n",
    "            strategy=\"block\",\n",
    "            apply_to_input=True,\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "out = agent.invoke({\n",
    "    \"messages\": [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Extract information from text: My email is john@example.com and card is 5105-1051-0510-5100\"\n",
    "    }]\n",
    "})\n",
    "print(out[\"messages\"][-1].content)\n"
   ],
   "id": "817a34949d01b675",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"email\": \"[REDACTED_EMAIL]\",\n",
      "  \"card_masked\": \"****-****-****-5100\",\n",
      "  \"card_last4\": \"5100\",\n",
      "  \"notes\": \"Full card number not present (only last 4 digits shown).\"\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming\n",
    "\n",
    "W LangChain możemy zwracać  częsciowe odpowiedzi lub kolejne wygenerowane tokeny \"w locie\":\n",
    "- **postęp agenta** (`stream_mode=\"updates\"`) – event po każdym kroku\n",
    "- **tokeny/model messages** (`stream_mode=\"messages\"`) – UI-friendly\n"
   ],
   "id": "c7328314668ba532"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T17:27:20.165443553Z",
     "start_time": "2026-01-01T17:26:51.965511715Z"
    }
   },
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "def rate_city(city: str) -> str:\n",
    "    \"\"\"Rate city mock tool.\"\"\"\n",
    "    return f\"The best city is {city}!\"\n",
    "\n",
    "agent = create_agent(model=\"gpt-5\", tools=[rate_city])\n",
    "\n",
    "for chunk in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Is Poznań a nice city?\"}]},\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    for step, data in chunk.items():\n",
    "        last = data[\"messages\"][-1]\n",
    "        print(f\"step: {step:>6} | type={type(last).__name__}\")\n",
    "        try:\n",
    "            print(\"content_blocks:\", last.content_blocks)\n",
    "        except Exception:\n",
    "            print(\"content:\", getattr(last, \"content\", None))\n"
   ],
   "id": "bff4b1e2ae1e6262",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:  model | type=AIMessage\n",
      "content_blocks: [{'type': 'tool_call', 'id': 'call_lcIRbDvuliB5EyjBpIWHSh4d', 'name': 'rate_city', 'args': {'city': 'Poznań'}}]\n",
      "step:  tools | type=ToolMessage\n",
      "content_blocks: [{'type': 'text', 'text': 'The best city is Poznań!'}]\n",
      "step:  model | type=AIMessage\n",
      "content_blocks: [{'type': 'text', 'text': 'Short answer: yes—many people find Poznań a very nice city.\\n\\nHighlights\\n- Charming Old Market Square with colorful townhouses and the Renaissance Town Hall (watch the mechanical goats at noon).\\n- Ostrów Tumski island and Poland’s oldest cathedral; rich early Polish history.\\n- Stary Browar (art + shopping) and plenty of cafes, craft beer spots, and restaurants.\\n- Green spaces like Cytadela Park and walks around Lake Malta; good tram network; generally safe.\\n- Lively student vibe and prices typically lower than Warsaw or Kraków. Don’t miss rogale świętomarcińskie (St. Martin’s croissants).\\n\\nConsiderations\\n- Winters can be grey and chilly; air quality can dip in colder months.\\n- Nightlife and “wow” factor are a bit more modest than in bigger tourist magnets.\\n- Ongoing tram/road works can cause detours.\\n\\nWho will like it\\n- Great for a relaxed weekend city break, food and coffee lovers, history buffs, and families.\\n- Good base for day trips to Rogalin Palace, Wielkopolski National Park, or Gniezno.\\n\\nBest time to visit\\n- May–September for parks and lake activities; Nov 11 for St. Martin’s Day festivities; December for the Christmas market.'}]\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCP – Model Context Protocol\n",
    "\n",
    "MCP standaryzuje wykorzystuje zewnetrznych narzędzi przez LLM.\n",
    "W LangChain używamy adaptera `langchain-mcp-adapters` i klienta `MultiServerMCPClient`, który potrafi pobrać listę narzędzi z wielu serwerów.\n"
   ],
   "id": "96fecd1bd18c3101"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T17:30:55.683430763Z",
     "start_time": "2026-01-01T17:30:55.630347092Z"
    }
   },
   "source": [
    "try:\n",
    "    import nest_asyncio\n",
    "    nest_asyncio.apply()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "async def demo_mcp():\n",
    "    client = MultiServerMCPClient(\n",
    "        {\n",
    "            \"math\": {\n",
    "                \"transport\": \"stdio\",\n",
    "                \"command\": \"python\",\n",
    "                \"args\": [\"/path/to/math_server.py\"],\n",
    "            },\n",
    "        }\n",
    "    )\n",
    "    tools = await client.get_tools()\n",
    "    agent = create_agent(\"gpt-5-mini\", tools)\n",
    "\n",
    "    r1 = await agent.ainvoke({\"messages\": [{\"role\": \"user\", \"content\": \"what's (3 + 5) x 12?\"}]})\n",
    "    print(r1[\"messages\"][-1].content)\n",
    "\n",
    "# Odkomentuj poniżej, aby uruchomić\n",
    "# asyncio.run(demo_mcp())\n"
   ],
   "id": "2ea2e05c485e74a1",
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimalny MCP server (FastMCP)\n",
    "\n",
    "Zapisz poniższy kod jako `math_server.py` i uruchom `python math_server.py`.\n"
   ],
   "id": "8bbfe203a981dbee"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T17:30:57.984358053Z",
     "start_time": "2026-01-01T17:30:57.940005517Z"
    }
   },
   "source": [
    "MATH_SERVER = r\"\"\"\n",
    "from fastmcp import FastMCP\n",
    "\n",
    "mcp = FastMCP(\"Math\")\n",
    "\n",
    "@mcp.tool()\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"Add two numbers\"\n",
    "    return a + b\n",
    "\n",
    "@mcp.tool()\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"Multiply two numbers\"\n",
    "    return a * b\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run(transport=\"stdio\")\n",
    "\"\"\"\n",
    "print(MATH_SERVER[:400] + \"\\n...\")\n"
   ],
   "id": "3cf43b80f7ca5589",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "from fastmcp import FastMCP\n",
      "\n",
      "mcp = FastMCP(\"Math\")\n",
      "\n",
      "@mcp.tool()\n",
      "def add(a: int, b: int) -> int:\n",
      "    \"Add two numbers\"\n",
      "    return a + b\n",
      "\n",
      "@mcp.tool()\n",
      "def multiply(a: int, b: int) -> int:\n",
      "    \"Multiply two numbers\"\n",
      "    return a * b\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    mcp.run(transport=\"stdio\")\n",
      "\n",
      "...\n"
     ]
    }
   ],
   "execution_count": 27
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
