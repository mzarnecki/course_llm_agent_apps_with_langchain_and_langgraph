{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain 1.X.X+ – nowa składnia: create_agent, messages, structured output, pamięć, middleware, streaming, MCP\n",
    "\n",
    "Ten notebook jest **dodatkowym uzupełnieniem** do kursu – pokazuje kilka kluczowych elementów z nowej składni LangChain (1.x), w szczególności API wokół `create_agent`.\n",
    "Kurs w wielu miejscach wykorzystuje przykłady z uzyciem langchain_classic, które mogą zostać zastąpione przez uproszconą składnię LangChain w wersji powyżej 1.x."
   ],
   "id": "15234553dfc72ae"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Instalacja bibliotek",
   "id": "7ebcee7b434ca1fe"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "!pip install -q langchain python-dotenv langchain_mcp_adapters fastmcp",
   "id": "aec4a0e85b079adb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T10:57:15.668825220Z",
     "start_time": "2026-01-02T10:57:15.535794611Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ],
   "id": "50ec4267dd9f57f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create_agent\n",
    "\n",
    "W nowej składni agent jest tworzony przez `create_agent(model=..., tools=[...], ...)` i wywoływany przez `invoke()`."
   ],
   "id": "76139e9b5a11b788"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T10:58:49.570511926Z",
     "start_time": "2026-01-02T10:58:23.175205449Z"
    }
   },
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "def rate_city(city: str) -> str:\n",
    "    \"\"\"Rate the city.\"\"\"\n",
    "    return f\"{city} is the best place in the world!\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-5-mini\",\n",
    "    tools=[rate_city],\n",
    "    system_prompt=\"You are a helpful assistant\",\n",
    ")\n",
    "\n",
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Is Poznań a nice city?.\"}]})\n",
    "\n",
    "last_msg = result[\"messages\"][-1]\n",
    "print(last_msg.content)\n"
   ],
   "id": "620d6212a116498",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Short answer: yes — Poznań is generally considered a very nice city, especially for history, culture, students and a relaxed, lived-in Polish city vibe.\n",
      "\n",
      "Reasons people like Poznań\n",
      "- Beautiful Old Town (Stary Rynek) with the Renaissance Town Hall and the famous mechanical goats that butt heads at noon.\n",
      "- Rich history: Cathedral Island (Ostrów Tumski), churches, and museums (National Museum, Archeological Museum).\n",
      "- Green space: Lake Malta (recreation, rowing, walking), Citadel Park (large park, monuments, views).\n",
      "- Vibrant cultural scene: Malta Festival, theatres, concerts and active contemporary arts.\n",
      "- Student energy: Adam Mickiewicz University gives the city a lively cafe/bar/nightlife scene and affordable cultural offerings.\n",
      "- Food and local specialties: Poznań’s St. Martin’s croissant (rogale świętomarcińskie), good cafes and craft beer.\n",
      "- Good transport links: international airport (Poznań–Ławica), rail connections to Warsaw, Berlin and other cities; compact city centre that's easy to walk.\n",
      "- Generally more affordable and less touristy than Kraków or Warsaw, which many people like.\n",
      "\n",
      "Things to consider\n",
      "- Winters can be cold and grey; best visited spring–early autumn.\n",
      "- Smaller tourist offer than Poland’s biggest cities if you want nonstop landmark-hopping, but it’s stronger for living, studying or a relaxed city break.\n",
      "- Some neighborhoods outside the center are more ordinary residential areas.\n",
      "\n",
      "If you tell me whether you’re planning a short visit, a move, or just curious, I can give tailored tips (where to stay, what to see in a day, or neighborhoods to live in).\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Messages – obiekty wiadomości\n",
    "\n",
    "LangChain standaryzuje wiadomości jako obiekty (`SystemMessage`, `HumanMessage`, `AIMessage`, `ToolMessage`) i pozwala używać ich z modelami czatu."
   ],
   "id": "bf46922bfbd6d84f"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T10:59:39.203270080Z",
     "start_time": "2026-01-02T10:59:35.547301428Z"
    }
   },
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.messages import SystemMessage, HumanMessage\n",
    "\n",
    "chat = init_chat_model(\"gpt-5-mini\")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"You are a concise assistant.\"),\n",
    "    HumanMessage(\"Write a 1-sentence summary of what LangChain is.\"),\n",
    "]\n",
    "\n",
    "ai_msg = chat.invoke(messages)  # -> AIMessage\n",
    "print(ai_msg.content)"
   ],
   "id": "72fe78325f6db316",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is an open-source framework for building applications with large language models by composing chains, prompts, agents, memory, and integrations (e.g., vector stores, tools, and external data) to connect LLMs to real-world workflows.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured output – `response_format` w `create_agent`\n",
    "\n",
    "Zamiast parsować tekst, możesz poprosić agenta o zwrócenie danych zgodnych z typem (np. Pydantic model).\n",
    "Efekt trafia wtedy do `result[\"structured_response\"]`.\n"
   ],
   "id": "3a8e8b879fcf2030"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T11:00:57.945390416Z",
     "start_time": "2026-01-02T11:00:54.529857563Z"
    }
   },
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "class ContactInfo(BaseModel):\n",
    "    \"\"\"Contact information for a person.\"\"\"\n",
    "    name: str = Field(description=\"The name of the person\")\n",
    "    email: str = Field(description=\"The email address\")\n",
    "    phone: str = Field(description=\"The phone number\")\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-5-mini\",\n",
    "    response_format=ContactInfo,\n",
    ")\n",
    "\n",
    "result = agent.invoke({\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"Extract contact info from: John Doe, john@example.com, (555) 123-4567\"}\n",
    "    ]\n",
    "})\n",
    "\n",
    "structured = result[\"structured_response\"]\n",
    "print(structured)\n",
    "print(type(structured))\n"
   ],
   "id": "815d89d7f5a0553f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='John Doe' email='john@example.com' phone='(555) 123-4567'\n",
      "<class '__main__.ContactInfo'>\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short‑term memory\n",
    "\n",
    "W LangChain 1.X.X pamięć *krótkoterminowa* jest realizowana przez dedykowany komponent InMemorySaver.\n",
    "\n",
    "- `InMemorySaver()` trzyma stan w pamięci procesu (idealne do notebooka)\n",
    "- `thread_id` identyfikuje „wątek rozmowy” (ważne przy wielokrotnych `invoke()`)\n"
   ],
   "id": "4d218551f2252cae"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T11:01:59.382987020Z",
     "start_time": "2026-01-02T11:01:49.509199325Z"
    }
   },
   "source": [
    "from langchain.agents import create_agent\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-5-mini\",\n",
    "    checkpointer=checkpointer,\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"demo-thread-1\"}}\n",
    "\n",
    "agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Hi! My name is Michał.\"}]}, config=config)\n",
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"What is my name?\"}]}, config=config)\n",
    "print(result[\"messages\"][-1].content)\n"
   ],
   "id": "ebe3710f4e4ad35",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your name is Michał.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Middleware - Human‑in‑the‑loop middleware\n",
    "\n",
    "Middleware pozwala „wpiąć się” w wykonanie agenta.\n",
    "Typowy scenariusz: agent może *odczytywać* dane, ale akcje typu *wysyłka e‑maila / zapis do bazy* wymagają akceptacji.\n",
    "Human‑in‑the‑loop – zatrzymanie przed uruchomieniem wybranych narzędzi i wznowienie przez `Command(resume=...)`.\n"
   ],
   "id": "208b7a469b1fe5bf"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T11:03:39.436028018Z",
     "start_time": "2026-01-02T11:03:35.950194118Z"
    }
   },
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import HumanInTheLoopMiddleware\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.types import Command\n",
    "\n",
    "def read_email(email_id: str) -> str:\n",
    "    \"\"\"Read email mock function\"\"\"\n",
    "    return f\"(mock) Email content for id={email_id}\"\n",
    "\n",
    "def send_email(recipient: str, subject: str, body: str) -> str:\n",
    "    \"\"\"Send email mock function\"\"\"\n",
    "    return f\"(mock) Sent email to {recipient} with subject={subject} and content={body}\"\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-5-mini\",\n",
    "    tools=[read_email, send_email],\n",
    "    checkpointer=checkpointer,\n",
    "    middleware=[\n",
    "        HumanInTheLoopMiddleware(\n",
    "            interrupt_on={\n",
    "                \"send_email\": {\"allowed_decisions\": [\"approve\", \"edit\", \"reject\"]},\n",
    "                \"read_email\": False,\n",
    "            }\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"hitl-demo\"}}\n",
    "\n",
    "paused = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Send an email to alice@example.com with subject 'Hi' and say hello.\"}]},\n",
    "    config=config,\n",
    ")\n",
    "print(\"Paused state keys:\", paused.keys())"
   ],
   "id": "ed8943c512ff4890",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paused state keys: dict_keys(['messages', '__interrupt__'])\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T11:03:48.584229836Z",
     "start_time": "2026-01-02T11:03:46.509216823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "resumed = agent.invoke(\n",
    "    Command(resume={\"decisions\": [{\"type\": \"approve\"}]}),\n",
    "    config=config,\n",
    ")\n",
    "print(resumed[\"messages\"][-1].content)"
   ],
   "id": "3c43e143b7baceb3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done — I sent the email to alice@example.com with subject \"Hi\" and body \"Hello.\"\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Middleware -Guardrails – PII middleware\n",
    "\n",
    "Jako middelware możemy też skorzystać z gurdrails czyli np. zabezpieczenia przed wyciekiem danych wrażliwych w odpowiedzi LLM."
   ],
   "id": "aa530874f89ba981"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T11:04:49.268717027Z",
     "start_time": "2026-01-02T11:04:43.966550338Z"
    }
   },
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import PIIMiddleware\n",
    "\n",
    "def echo(text: str) -> str:\n",
    "    \"\"\"Print text.\"\"\"\n",
    "    return text\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-5-mini\",\n",
    "    tools=[echo],\n",
    "    middleware=[\n",
    "        PIIMiddleware(\"email\", strategy=\"redact\", apply_to_input=True),\n",
    "        PIIMiddleware(\"credit_card\", strategy=\"mask\", apply_to_input=True),\n",
    "        PIIMiddleware(\n",
    "            \"api_key\",\n",
    "            detector=r\"sk-[a-zA-Z0-9]{32}\",\n",
    "            strategy=\"block\",\n",
    "            apply_to_input=True,\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "out = agent.invoke({\n",
    "    \"messages\": [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Extract information from text: My email is john@example.com and card is 5105-1051-0510-5100\"\n",
    "    }]\n",
    "})\n",
    "print(out[\"messages\"][-1].content)\n"
   ],
   "id": "817a34949d01b675",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted fields:\n",
      "- Email: [REDACTED_EMAIL]\n",
      "- Card (masked): ****-****-****-5100\n",
      "- Card last 4 digits: 5100\n",
      "\n",
      "Note: The email appears to be already redacted in the input. If you want a different output format (JSON, CSV, etc.), tell me which.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming\n",
    "\n",
    "W LangChain możemy zwracać  częsciowe odpowiedzi lub kolejne wygenerowane tokeny \"w locie\":\n",
    "- **postęp agenta** (`stream_mode=\"updates\"`) – event po każdym kroku\n",
    "- **tokeny/model messages** (`stream_mode=\"messages\"`) – UI-friendly\n"
   ],
   "id": "c7328314668ba532"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T11:07:23.772975911Z",
     "start_time": "2026-01-02T11:06:53.376333221Z"
    }
   },
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "def rate_city(city: str) -> str:\n",
    "    \"\"\"Rate city mock tool.\"\"\"\n",
    "    return f\"The best city is {city}!\"\n",
    "\n",
    "agent = create_agent(model=\"gpt-5\", tools=[rate_city])\n",
    "\n",
    "for chunk in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Is Poznań a nice city? Rate city and afterwards plan a trip to Poznań in 5 stages.\"}]},\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    for step, data in chunk.items():\n",
    "        last = data[\"messages\"][-1]\n",
    "        print(f\"step: {step:>6} | type={type(last).__name__}\")\n",
    "        try:\n",
    "            print(\"content_blocks:\", last.content_blocks)\n",
    "        except Exception:\n",
    "            print(\"content:\", getattr(last, \"content\", None))\n"
   ],
   "id": "bff4b1e2ae1e6262",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:  model | type=AIMessage\n",
      "content_blocks: [{'type': 'tool_call', 'id': 'call_X2n1l0Y8fCFsQhSzVCzeOOob', 'name': 'rate_city', 'args': {'city': 'Poznań'}}]\n",
      "step:  tools | type=ToolMessage\n",
      "content_blocks: [{'type': 'text', 'text': 'The best city is Poznań!'}]\n",
      "step:  model | type=AIMessage\n",
      "content_blocks: [{'type': 'text', 'text': 'Rating: The best city is Poznań!\\n\\n5-stage trip plan to Poznań\\n\\n1) Old Town essentials (Stare Miasto)\\n- Stary Rynek (Main Square) and Renaissance Town Hall; see the mechanical goats at noon.\\n- Poznań Fara (Baroque parish church).\\n- Climb the Royal Castle tower for views.\\n- Try a rogal świętomarciński (St. Martin’s croissant); consider the Rogal Museum show.\\n\\n2) Cathedral Island and Śródka\\n- Ostrów Tumski: Archcathedral Basilica (site tied to Poland’s first rulers).\\n- Porta Posnania interactive museum for the city’s origins.\\n- Walk over Bishop Jordan Bridge to Śródka for the mural and cozy eateries.\\n\\n3) Culture and architecture loop\\n- Stary Browar (art center + design-forward mall).\\n- Imperial Castle District: Zamek Cesarski, Adam Mickiewicz Square, Opera/Philharmonic exteriors.\\n- National Museum (Polish art) if you have time.\\n\\n4) Green and active Poznań\\n- Malta Lake: lakeside walk or bike; in season ride the Maltanka miniature railway; Termy Maltańskie (spa/waterpark).\\n- Park Cytadela for sculptures and history; Sołacz Park for a quieter stroll.\\n\\n5) Food, nightlife, and day trips\\n- Eat local: pyry z gzikiem (potatoes with cottage cheese), szare kluski, duck with modra kapusta; craft beer at Brovaria on the square.\\n- Nightlife on Wrocławska Street; cafés in Jeżyce and along Św. Marcin.\\n- Day trips: Rogalin Palace and ancient oaks; Kórnik Castle and arboretum; Gniezno (first Polish capital).\\n- Practical: get a 24–72h tram/bus ticket or Poznań City Card; most sights are walkable; fly via Ławica Airport or take fast trains from Warsaw/Berlin.'}]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCP – Model Context Protocol\n",
    "\n",
    "MCP standaryzuje wykorzystuje zewnetrznych narzędzi przez LLM.\n",
    "W LangChain używamy adaptera `langchain-mcp-adapters` i klienta `MultiServerMCPClient`, który potrafi pobrać listę narzędzi z wielu serwerów.\n"
   ],
   "id": "96fecd1bd18c3101"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minimalny MCP server (FastMCP)\n",
    "Zapisz poniższy kod jako `math_server.py` w tym samym katalogu co ten notebook.\n"
   ],
   "id": "8bbfe203a981dbee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T19:19:23.202877631Z",
     "start_time": "2026-01-01T19:19:23.124570733Z"
    }
   },
   "cell_type": "markdown",
   "source": [
    "```python\n",
    "from fastmcp import FastMCP\n",
    "\n",
    "mcp = FastMCP(\"Math\")\n",
    "\n",
    "@mcp.tool()\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"Add two numbers\"\n",
    "    return a + b\n",
    "\n",
    "@mcp.tool()\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"Multiply two numbers\"\n",
    "    return a * b\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run(transport=\"stdio\")\n",
    "```"
   ],
   "id": "b65c79d3cb1eddc3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "następnie uruchom:",
   "id": "611fdca64d65e877"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T11:10:02.410819668Z",
     "start_time": "2026-01-02T11:09:55.572448607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "async def demo_mcp():\n",
    "    client = MultiServerMCPClient(\n",
    "        {\n",
    "            \"math\": {\n",
    "                \"transport\": \"stdio\",\n",
    "                \"command\": \"python\",\n",
    "                \"args\": [\"math_server.py\"],\n",
    "            },\n",
    "        }\n",
    "    )\n",
    "    tools = await client.get_tools()\n",
    "    agent = create_agent(\"gpt-5-mini\", tools)\n",
    "\n",
    "    r1 = await agent.ainvoke({\"messages\": [{\"role\": \"user\", \"content\": \"what's (3 + 5) x 12?\"}]})\n",
    "    print(r1[\"messages\"][-1].content)\n",
    "\n",
    "# Odkomentuj poniżej, aby uruchomić\n",
    "# asyncio.run(demo_mcp())"
   ],
   "id": "528d84eeb8d809fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3 + 5) × 12 = 8 × 12 = 96.\n"
     ]
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
