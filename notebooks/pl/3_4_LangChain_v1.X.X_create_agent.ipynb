{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain 1.X.X+ – nowa składnia: create_agent, messages, structured output, pamięć, middleware, streaming, MCP\n",
    "\n",
    "Ten notebook jest **dodatkowym uzupełnieniem** do kursu – pokazuje kilka kluczowych elementów z nowej składni LangChain (1.x), w szczególności API wokół `create_agent`.\n",
    "Kurs w wielu miejscach wykorzystuje przykłady z uzyciem langchain_classic, które mogą zostać zastąpione przez uproszconą składnię LangChain w wersji powyżej 1.x."
   ],
   "id": "15234553dfc72ae"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Instalacja bibliotek",
   "id": "7ebcee7b434ca1fe"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T08:18:42.390314081Z",
     "start_time": "2026-01-24T08:18:40.218803743Z"
    }
   },
   "source": "!pip install -q langchain python-dotenv langchain_mcp_adapters fastmcp",
   "id": "aec4a0e85b079adb",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T08:19:37.528178990Z",
     "start_time": "2026-01-24T08:19:37.445497604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ],
   "id": "50ec4267dd9f57f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create_agent\n",
    "\n",
    "W nowej składni agent jest tworzony przez `create_agent(model=..., tools=[...], ...)` i wywoływany przez `invoke()`."
   ],
   "id": "76139e9b5a11b788"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T08:22:11.623891034Z",
     "start_time": "2026-01-24T08:21:57.551153059Z"
    }
   },
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "def rate_city(city: str) -> str:\n",
    "    \"\"\"Rate the city.\"\"\"\n",
    "    return f\"{city} is the best place in the world!\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-5-mini\",\n",
    "    tools=[rate_city],\n",
    "    system_prompt=\"You are a helpful assistant\",\n",
    ")\n",
    "\n",
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Is Poznań a nice city?.\"}]})\n",
    "\n",
    "last_msg = result[\"messages\"][-1]\n",
    "print(last_msg.content)\n"
   ],
   "id": "620d6212a116498",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Short answer: yes — Poznań is generally considered a very nice city, especially for visitors, students and people who want a lively but not overwhelming urban center.\n",
      "\n",
      "Why people like it\n",
      "- Attractive Old Town (Stary Rynek) with colorful townhouses, the Renaissance Town Hall and a lively market square.\n",
      "- Good food scene and cafés; local specialty is St. Martin’s croissant (rogal świętomarciński).\n",
      "- Strong cultural life: theaters, museums (National Museum), Malta Festival, concerts and a busy events calendar.\n",
      "- Large student population (Adam Mickiewicz University and others) gives a youthful, energetic feel and lots of nightlife options.\n",
      "- Good public transport, compact and walkable center, increasingly bike-friendly.\n",
      "- Solid economy and job market (important business and trade fair center), so it’s a common choice for people relocating within Poland.\n",
      "- Parks and recreation: Cytadela Park, Malta Lake (water sports, skating, trails).\n",
      "\n",
      "Potential downsides\n",
      "- Winters can be cold and gray; occasional poor air quality in winter in some areas.\n",
      "- Smaller than Warsaw or Kraków — less variety in some niche cultural scenes, though many people see that as a plus.\n",
      "- Housing costs have risen in recent years, though generally lower than in Warsaw.\n",
      "\n",
      "Who will like it most\n",
      "- Students and young professionals\n",
      "- People who want a balance of historical charm and modern city services without mega-city crowds\n",
      "- Travelers who enjoy good food, museums, cafés and a lively central square\n",
      "\n",
      "If you tell me whether you’re visiting, studying, or thinking of moving there, I can give specific tips — best neighborhoods, must-see sights, where to eat, or cost-of-living info.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Messages – obiekty wiadomości\n",
    "\n",
    "LangChain standaryzuje wiadomości jako obiekty (`SystemMessage`, `HumanMessage`, `AIMessage`, `ToolMessage`) i pozwala używać ich z modelami czatu."
   ],
   "id": "bf46922bfbd6d84f"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T08:23:32.498584990Z",
     "start_time": "2026-01-24T08:23:26.359150829Z"
    }
   },
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.messages import SystemMessage, HumanMessage\n",
    "\n",
    "chat = init_chat_model(\"gpt-5-mini\")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"You are a concise assistant.\"),\n",
    "    HumanMessage(\"Write a 1-sentence summary of what LangChain is.\"),\n",
    "]\n",
    "\n",
    "ai_msg = chat.invoke(messages)  # -> AIMessage\n",
    "print(ai_msg.content)"
   ],
   "id": "72fe78325f6db316",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is an open-source framework for building LLM-powered applications that provides modular components—prompt templates, chains, agents, memory, and connectors to data and APIs—to orchestrate models, retrieval, and tool use.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured output – `response_format` w `create_agent`\n",
    "\n",
    "Zamiast parsować tekst, możesz poprosić agenta o zwrócenie danych zgodnych z typem (np. Pydantic model).\n",
    "Efekt trafia wtedy do `result[\"structured_response\"]`.\n"
   ],
   "id": "3a8e8b879fcf2030"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T08:26:28.136146847Z",
     "start_time": "2026-01-24T08:26:24.073978701Z"
    }
   },
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "class ContactInfo(BaseModel):\n",
    "    \"\"\"Contact information for a person.\"\"\"\n",
    "    name: str = Field(description=\"The name of the person\")\n",
    "    email: str = Field(description=\"The email address\")\n",
    "    phone: str = Field(description=\"The phone number\")\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-5-mini\",\n",
    "    response_format=ContactInfo,\n",
    ")\n",
    "\n",
    "result = agent.invoke({\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"Extract contact info from: John Doe, john@example.com, (555) 123-4567\"}\n",
    "    ]\n",
    "})\n",
    "\n",
    "structured = result[\"structured_response\"]\n",
    "print(structured)\n",
    "print(type(structured))\n"
   ],
   "id": "815d89d7f5a0553f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='John Doe' email='john@example.com' phone='(555) 123-4567'\n",
      "<class '__main__.ContactInfo'>\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short‑term memory\n",
    "\n",
    "W LangChain 1.X.X pamięć *krótkoterminowa* jest realizowana przez dedykowany komponent InMemorySaver.\n",
    "\n",
    "- `InMemorySaver()` trzyma stan w pamięci procesu (idealne do notebooka)\n",
    "- `thread_id` identyfikuje „wątek rozmowy” (ważne przy wielokrotnych `invoke()`)\n"
   ],
   "id": "4d218551f2252cae"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T08:27:43.329964474Z",
     "start_time": "2026-01-24T08:27:32.662679536Z"
    }
   },
   "source": [
    "from langchain.agents import create_agent\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-5-mini\",\n",
    "    checkpointer=checkpointer,\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"demo-thread-1\"}}\n",
    "\n",
    "agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Hi! My name is Michał.\"}]}, config=config)\n",
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"What is my name?\"}]}, config=config)\n",
    "print(result[\"messages\"][-1].content)\n"
   ],
   "id": "ebe3710f4e4ad35",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your name is Michał.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Middleware - Human‑in‑the‑loop middleware\n",
    "\n",
    "Middleware pozwala „wpiąć się” w wykonanie agenta.\n",
    "Typowy scenariusz: agent może *odczytywać* dane, ale akcje typu *wysyłka e‑maila / zapis do bazy* wymagają akceptacji.\n",
    "Human‑in‑the‑loop – zatrzymanie przed uruchomieniem wybranych narzędzi i wznowienie przez `Command(resume=...)`.\n"
   ],
   "id": "208b7a469b1fe5bf"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T08:58:33.635209278Z",
     "start_time": "2026-01-24T08:58:30.260570646Z"
    }
   },
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import HumanInTheLoopMiddleware\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.types import Command\n",
    "\n",
    "def read_email(email_id: str) -> str:\n",
    "    \"\"\"Read email mock function\"\"\"\n",
    "    return f\"(mock) Email content for id={email_id}\"\n",
    "\n",
    "def send_email(recipient: str, subject: str, body: str) -> str:\n",
    "    \"\"\"Send email mock function\"\"\"\n",
    "    return f\"(mock) Sent email to {recipient} with subject={subject} and content={body}\"\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-5-mini\",\n",
    "    tools=[read_email, send_email],\n",
    "    checkpointer=checkpointer,\n",
    "    middleware=[\n",
    "        HumanInTheLoopMiddleware(\n",
    "            interrupt_on={\n",
    "                \"send_email\": {\"allowed_decisions\": [\"approve\", \"edit\", \"reject\"]},\n",
    "                \"read_email\": False,\n",
    "            }\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"hitl-demo\"}}\n",
    "\n",
    "paused = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Send an email to alice@example.com with subject 'Hi' and say hello.\"}]},\n",
    "    config=config,\n",
    ")\n",
    "print(\"Paused state keys:\", paused.keys())"
   ],
   "id": "ed8943c512ff4890",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paused state keys: dict_keys(['messages', '__interrupt__'])\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T11:03:48.584229836Z",
     "start_time": "2026-01-02T11:03:46.509216823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "resumed = agent.invoke(\n",
    "    Command(resume={\"decisions\": [{\"type\": \"approve\"}]}),\n",
    "    config=config,\n",
    ")\n",
    "print(resumed[\"messages\"][-1].content)"
   ],
   "id": "3c43e143b7baceb3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done — I sent the email to alice@example.com with subject \"Hi\" and body \"Hello.\"\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Middleware -Guardrails – PII middleware\n",
    "\n",
    "Jako middelware możemy też skorzystać z gurdrails czyli np. zabezpieczenia przed wyciekiem danych wrażliwych w odpowiedzi LLM."
   ],
   "id": "aa530874f89ba981"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T09:01:51.554332697Z",
     "start_time": "2026-01-24T09:01:46.291273867Z"
    }
   },
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import PIIMiddleware\n",
    "\n",
    "def echo(text: str) -> str:\n",
    "    \"\"\"Print text.\"\"\"\n",
    "    return text\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-5-mini\",\n",
    "    tools=[echo],\n",
    "    middleware=[\n",
    "        PIIMiddleware(\"email\", strategy=\"redact\", apply_to_input=True),\n",
    "        PIIMiddleware(\"credit_card\", strategy=\"mask\", apply_to_input=True),\n",
    "        PIIMiddleware(\n",
    "            \"api_key\",\n",
    "            detector=r\"sk-[a-zA-Z0-9]{32}\",\n",
    "            strategy=\"block\",\n",
    "            apply_to_input=True,\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "out = agent.invoke({\n",
    "    \"messages\": [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Extract information from text: My email is john@example.com and card is 5105-1051-0510-5100\"\n",
    "    }]\n",
    "})\n",
    "print(out[\"messages\"][-1].content)\n"
   ],
   "id": "817a34949d01b675",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted data:\n",
      "- Email: [REDACTED_EMAIL]\n",
      "- Card (masked): ****-****-****-5100\n",
      "- Card last 4 digits: 5100\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming\n",
    "\n",
    "W LangChain możemy zwracać  częsciowe odpowiedzi lub kolejne wygenerowane tokeny \"w locie\":\n",
    "- **postęp agenta** (`stream_mode=\"updates\"`) – event po każdym kroku\n",
    "- **tokeny/model messages** (`stream_mode=\"messages\"`) – UI-friendly\n"
   ],
   "id": "c7328314668ba532"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T09:06:38.412437817Z",
     "start_time": "2026-01-24T09:05:55.093125877Z"
    }
   },
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "def rate_city(city: str) -> str:\n",
    "    \"\"\"Rate city mock tool.\"\"\"\n",
    "    return f\"The best city is {city}!\"\n",
    "\n",
    "agent = create_agent(model=\"gpt-5\", tools=[rate_city])\n",
    "\n",
    "for chunk in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Is Poznań a nice city? Rate city and afterwards plan a trip to Poznań in 5 stages.\"}]},\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    for step, data in chunk.items():\n",
    "        last = data[\"messages\"][-1]\n",
    "        print(f\"step: {step:>6} | type={type(last).__name__}\")\n",
    "        try:\n",
    "            print(\"content_blocks:\", last.content_blocks)\n",
    "        except Exception:\n",
    "            print(\"content:\", getattr(last, \"content\", None))\n"
   ],
   "id": "bff4b1e2ae1e6262",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:  model | type=AIMessage\n",
      "content_blocks: [{'type': 'tool_call', 'id': 'call_T0KIDZmNcntN2JTkCAwZJChO', 'name': 'rate_city', 'args': {'city': 'Poznań'}}]\n",
      "step:  tools | type=ToolMessage\n",
      "content_blocks: [{'type': 'text', 'text': 'The best city is Poznań!'}]\n",
      "step:  model | type=AIMessage\n",
      "content_blocks: [{'type': 'text', 'text': 'City rating: The best city is Poznań!\\n\\n5-stage trip plan to Poznań\\n1) Old Town arrival and essentials (half day)\\n- Stary Rynek: Town Hall (watch the mechanical goats at noon), colorful merchant houses, Fara Church.\\n- Food: Try a rogal świętomarciński (St. Martin’s croissant) and pyry z gzikiem (potatoes with cottage cheese).\\n- Practical: Fly into POZ (Ławica) or arrive by rail to Poznań Główny; get a 24–48h tram/bus ticket or a Poznań City Card.\\n\\n2) Cathedral Island and heritage (half day)\\n- Ostrów Tumski: Poznań Cathedral (Golden Chapel), Archdiocesan Museum.\\n- Porta Posnania interactive museum to learn about the city’s origins.\\n- Riverside walk along the Warta.\\n\\n3) Parks, fortifications, and museums (half–full day)\\n- Cytadela Park: Military Museum, sculpture park, panoramic lawns.\\n- National Museum (Polish and European art) or Museum of Musical Instruments back in the Old Town.\\n- Coffee break on plac Wolności.\\n\\n4) Modern Poznań and food scene (half day + evening)\\n- Stary Browar (art, design, shopping) and the adjacent park.\\n- Jeżyce district: hip cafes, craft beer bars, and bistros; street art stroll on Kościelna/Jackowskiego.\\n- Summer option: KontenerART on the Warta for sunset drinks.\\n\\n5) Lake Malta and a side trip (half–full day)\\n- Morning at Malta Lake: lakeside walk, cycling, mini–zoo, or thermal baths (Termy Maltańskie).\\n- Afternoon side trip (choose one):\\n  - Rogalin Palace (oaks and art gallery),\\n  - Kórnik Castle (neo-Gothic castle and arboretum),\\n  - Gniezno (first Polish capital and cathedral).\\n- Return for dinner: try duck with red cabbage (regional specialty).\\n\\nTips\\n- Best time: late spring to early autumn; November 11 is St. Martin’s Day festivities.\\n- Most sights are tram-accessible; validate tickets on board.\\n- Many places accept cards; a few smaller bars prefer cash.'}]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCP – Model Context Protocol\n",
    "\n",
    "MCP standaryzuje wykorzystuje zewnetrznych narzędzi przez LLM.\n",
    "W LangChain używamy adaptera `langchain-mcp-adapters` i klienta `MultiServerMCPClient`, który potrafi pobrać listę narzędzi z wielu serwerów.\n"
   ],
   "id": "96fecd1bd18c3101"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minimalny MCP server (FastMCP)\n",
    "Zapisz poniższy kod jako `math_server.py` w tym samym katalogu co ten notebook.\n"
   ],
   "id": "8bbfe203a981dbee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T19:19:23.202877631Z",
     "start_time": "2026-01-01T19:19:23.124570733Z"
    }
   },
   "cell_type": "markdown",
   "source": [
    "```python\n",
    "from fastmcp import FastMCP\n",
    "\n",
    "mcp = FastMCP(\"Math\")\n",
    "\n",
    "@mcp.tool()\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"Add two numbers\"\n",
    "    return a + b\n",
    "\n",
    "@mcp.tool()\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"Multiply two numbers\"\n",
    "    return a * b\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run(transport=\"stdio\")\n",
    "```"
   ],
   "id": "b65c79d3cb1eddc3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "następnie uruchom:",
   "id": "611fdca64d65e877"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T09:50:30.611590806Z",
     "start_time": "2026-01-24T09:50:17.611574749Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def demo_mcp():\n",
    "    client = MultiServerMCPClient(\n",
    "        {\n",
    "            \"math\": {\n",
    "                \"transport\": \"stdio\",\n",
    "                \"command\": \"python\",\n",
    "                \"args\": [\"math_server.py\"],\n",
    "            },\n",
    "        }\n",
    "    )\n",
    "    tools = await client.get_tools()\n",
    "    agent = create_agent(\"gpt-5-mini\", tools)\n",
    "\n",
    "    r1 = await agent.ainvoke({\"messages\": [{\"role\": \"user\", \"content\": \"what's (3 + 5) x 12?\"}]})\n",
    "    print(r1[\"messages\"][-1].content)\n",
    "\n",
    "\n",
    "asyncio.run(demo_mcp())"
   ],
   "id": "528d84eeb8d809fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3 + 5) × 12 = 96\n",
      "\n",
      "Work: 3 + 5 = 8, then 8 × 12 = 96.\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7d1577f342c21de1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
