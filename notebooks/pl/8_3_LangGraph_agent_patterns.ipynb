{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02846c5e",
   "metadata": {},
   "source": "## Architektury agentów"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Instalacja bibliotek",
   "id": "971acb42af2cb236"
  },
  {
   "cell_type": "code",
   "id": "77f9b81c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T07:18:25.236590Z",
     "start_time": "2025-11-10T07:18:23.029790Z"
    }
   },
   "source": "%pip install -U langgraph langchain langchain-openai",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph in /home/michal/anaconda3/lib/python3.13/site-packages (1.0.2)\r\n",
      "Requirement already satisfied: langchain in /home/michal/anaconda3/lib/python3.13/site-packages (1.0.5)\r\n",
      "Requirement already satisfied: langchain-openai in /home/michal/anaconda3/lib/python3.13/site-packages (1.0.2)\r\n",
      "Requirement already satisfied: langchain-core>=0.1 in /home/michal/anaconda3/lib/python3.13/site-packages (from langgraph) (1.0.4)\r\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langgraph) (2.1.1)\r\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /home/michal/anaconda3/lib/python3.13/site-packages (from langgraph) (1.0.2)\r\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /home/michal/anaconda3/lib/python3.13/site-packages (from langgraph) (0.2.4)\r\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /home/michal/anaconda3/lib/python3.13/site-packages (from langgraph) (2.11.10)\r\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langgraph) (3.5.0)\r\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph) (1.10.0)\r\n",
      "Requirement already satisfied: httpx>=0.25.2 in /home/michal/anaconda3/lib/python3.13/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\r\n",
      "Requirement already satisfied: orjson>=3.10.1 in /home/michal/anaconda3/lib/python3.13/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.10.14)\r\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core>=0.1->langgraph) (1.33)\r\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core>=0.1->langgraph) (0.4.42)\r\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core>=0.1->langgraph) (24.2)\r\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core>=0.1->langgraph) (6.0.2)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core>=0.1->langgraph) (9.0.0)\r\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core>=0.1->langgraph) (4.15.0)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/michal/anaconda3/lib/python3.13/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph) (3.0.0)\r\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\r\n",
      "Requirement already satisfied: requests>=2.0.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.32.5)\r\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (0.23.0)\r\n",
      "Requirement already satisfied: anyio in /home/michal/.local/lib/python3.13/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.10.0)\r\n",
      "Requirement already satisfied: certifi in /home/michal/anaconda3/lib/python3.13/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.8.3)\r\n",
      "Requirement already satisfied: httpcore==1.* in /home/michal/.local/lib/python3.13/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\r\n",
      "Requirement already satisfied: idna in /home/michal/anaconda3/lib/python3.13/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.7)\r\n",
      "Requirement already satisfied: h11>=0.16 in /home/michal/.local/lib/python3.13/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from pydantic>=2.7.4->langgraph) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/michal/anaconda3/lib/python3.13/site-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from pydantic>=2.7.4->langgraph) (0.4.0)\r\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-openai) (2.7.1)\r\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-openai) (0.11.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\r\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.10.0)\r\n",
      "Requirement already satisfied: sniffio in /home/michal/.local/lib/python3.13/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\r\n",
      "Requirement already satisfied: tqdm>4 in /home/michal/anaconda3/lib/python3.13/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\r\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/michal/anaconda3/lib/python3.13/site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.11.6)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/michal/anaconda3/lib/python3.13/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (3.3.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/michal/anaconda3/lib/python3.13/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Import bibliotek i konfiguracja",
   "id": "6cffa241fe838685"
  },
  {
   "cell_type": "code",
   "id": "4f251900",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T07:18:29.252156Z",
     "start_time": "2025-11-10T07:18:25.261588Z"
    }
   },
   "source": [
    "import operator\n",
    "from typing import Annotated, List, TypedDict, Literal\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "8b1b1578",
   "metadata": {},
   "source": [
    "### Sequential Agent\n",
    "Sequential Agent prowadzi wewnętrzne rozumowanie w kilku krokach (tzw. scratchpad), ale nie używa narzędzi; stosowany tam, gdzie wystarczy czysta analiza i dedukcja."
   ]
  },
  {
   "cell_type": "code",
   "id": "b5bfcd8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T07:18:29.524556Z",
     "start_time": "2025-11-10T07:18:29.308259Z"
    }
   },
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    steps: Annotated[List[str], operator.add]\n",
    "    answer: str\n",
    "\n",
    "def plan_node(state: State) -> dict:\n",
    "    sys = (\n",
    "        \"You are a careful planner. Break the user's question into 2-4 concise steps. \"\n",
    "        \"Do not solve. Return only a numbered list of steps; no extra text.\"\n",
    "    )\n",
    "    messages = [(\"system\", sys), (\"user\", state[\"question\"])]\n",
    "    resp = llm.invoke(messages)\n",
    "    raw = resp.content\n",
    "    steps = []\n",
    "    for line in str(raw).splitlines():\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        line = line.lstrip(\"-• \").split(\". \", 1)[-1] if \". \" in line[:4] else line.lstrip(\"-• \")\n",
    "        steps.append(line)\n",
    "    return {\"steps\": steps}\n",
    "\n",
    "def solve_node(state: State) -> dict:\n",
    "    \"\"\"Use the planned steps to derive the final answer only.\"\"\"\n",
    "    sys = (\n",
    "        \"Use the provided steps to solve the problem. \"\n",
    "        \"Return only the final answer, no reasoning.\"\n",
    "    )\n",
    "    messages = [\n",
    "        (\"system\", sys),\n",
    "        (\"user\", f\"Question: {state['question']}\\nSteps: {state['steps']}\"),\n",
    "    ]\n",
    "    resp = llm.invoke(messages)\n",
    "    return {\"answer\": str(resp.content).strip()}\n",
    "\n",
    "# Wire up the graph\n",
    "graph = StateGraph(State)\n",
    "graph.add_node(\"plan\", plan_node)\n",
    "graph.add_node(\"solve\", solve_node)\n",
    "\n",
    "graph.add_edge(START, \"plan\")\n",
    "graph.add_edge(\"plan\", \"solve\")\n",
    "graph.add_edge(\"solve\", END)\n",
    "\n",
    "cot_graph = graph.compile()\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "90243e2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T07:18:31.636217Z",
     "start_time": "2025-11-10T07:18:29.529948Z"
    }
   },
   "source": [
    "state = {\n",
    "    \"question\": \"If a book has 350 pages and I read 14 pages per day, how many days to finish?\",\n",
    "    \"steps\": [],\n",
    "    \"answer\": \"\"\n",
    "}\n",
    "out = cot_graph.invoke(state)\n",
    "print(\"Final answer:\", out[\"answer\"])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final answer: 25 days\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "bec1a754",
   "metadata": {},
   "source": [
    "### Custom Agent\n",
    "Custom Agent daje pełną elstyczność. Samodzielnie definiujemy logikę, routing i węzły."
   ]
  },
  {
   "cell_type": "code",
   "id": "c7cbc302",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T07:18:31.699286Z",
     "start_time": "2025-11-10T07:18:31.687977Z"
    }
   },
   "source": [
    "class CustomState(TypedDict):\n",
    "    input: str\n",
    "    task: Literal[\"math\", \"capitalize\", \"count\"]\n",
    "    result: str\n",
    "\n",
    "def route(state: CustomState) -> str:\n",
    "    \"\"\"Deterministic router based on a simple protocol in the input.\"\"\"\n",
    "    text = state[\"input\"].strip().lower()\n",
    "    if text.startswith(\"math:\"):\n",
    "        return \"math\"\n",
    "    if text.startswith(\"capitalize:\"):\n",
    "        return \"capitalize\"\n",
    "    if text.startswith(\"count:\"):\n",
    "        return \"count\"\n",
    "    return \"count\"\n",
    "\n",
    "def do_math(state: CustomState) -> dict:\n",
    "    expr = state[\"input\"].split(\":\", 1)[-1].strip()\n",
    "    allowed = set(\"0123456789+-*/(). \")\n",
    "    if any(c not in allowed for c in expr):\n",
    "        return {\"result\": \"Error: unsupported characters in math expression.\"}\n",
    "    try:\n",
    "        res = eval(expr, {\"__builtins__\": {}})\n",
    "    except Exception as e:\n",
    "        res = f\"Error: {e}\"\n",
    "    return {\"result\": str(res)}\n",
    "\n",
    "def do_capitalize(state: CustomState) -> dict:\n",
    "    text = state[\"input\"].split(\":\", 1)[-1].strip()\n",
    "    return {\"result\": text.upper()}\n",
    "\n",
    "def do_count(state: CustomState) -> dict:\n",
    "    text = state[\"input\"].split(\":\", 1)[-1].strip()\n",
    "    tokens = [t for t in text.split() if t]\n",
    "    return {\"result\": f\"words={len(tokens)} chars={len(text)}\"}\n",
    "\n",
    "graph = StateGraph(CustomState)\n",
    "graph.add_node(\"math\", do_math)\n",
    "graph.add_node(\"capitalize\", do_capitalize)\n",
    "graph.add_node(\"count\", do_count)\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    START,\n",
    "    route,\n",
    "    {\n",
    "        \"math\": \"math\",\n",
    "        \"capitalize\": \"capitalize\",\n",
    "        \"count\": \"count\",\n",
    "    },\n",
    ")\n",
    "graph.add_edge(\"math\", END)\n",
    "graph.add_edge(\"capitalize\", END)\n",
    "graph.add_edge(\"count\", END)\n",
    "\n",
    "custom_agent = graph.compile(debug=True)\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "279f8804",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T07:18:31.750884Z",
     "start_time": "2025-11-10T07:18:31.744193Z"
    }
   },
   "source": [
    "for user_input in [\n",
    "    \"math: (12 + 8) * 3\",\n",
    "    \"capitalize: langgraph is great!\",\n",
    "    \"count: How many words are here?\",\n",
    "]:\n",
    "    out = custom_agent.invoke({\"input\": user_input, \"task\": \"count\", \"result\": \"\"})\n",
    "    print(f\"Input: {user_input}\\nResult: {out['result']}\\n---\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m[values]\u001B[0m {'input': 'math: (12 + 8) * 3', 'task': 'count', 'result': ''}\n",
      "\u001B[1m[updates]\u001B[0m {'math': {'result': '60'}}\n",
      "\u001B[1m[values]\u001B[0m {'input': 'math: (12 + 8) * 3', 'task': 'count', 'result': '60'}\n",
      "Input: math: (12 + 8) * 3\n",
      "Result: 60\n",
      "---\n",
      "\u001B[1m[values]\u001B[0m {'input': 'capitalize: langgraph is great!', 'task': 'count', 'result': ''}\n",
      "\u001B[1m[updates]\u001B[0m {'capitalize': {'result': 'LANGGRAPH IS GREAT!'}}\n",
      "\u001B[1m[values]\u001B[0m {'input': 'capitalize: langgraph is great!', 'task': 'count', 'result': 'LANGGRAPH IS GREAT!'}\n",
      "Input: capitalize: langgraph is great!\n",
      "Result: LANGGRAPH IS GREAT!\n",
      "---\n",
      "\u001B[1m[values]\u001B[0m {'input': 'count: How many words are here?', 'task': 'count', 'result': ''}\n",
      "\u001B[1m[updates]\u001B[0m {'count': {'result': 'words=5 chars=24'}}\n",
      "\u001B[1m[values]\u001B[0m {'input': 'count: How many words are here?', 'task': 'count', 'result': 'words=5 chars=24'}\n",
      "Input: count: How many words are here?\n",
      "Result: words=5 chars=24\n",
      "---\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Supervisor",
   "id": "83e0ed41aeb9d07e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T07:38:14.364306Z",
     "start_time": "2025-11-10T07:37:50.042514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SupervisorState(TypedDict):\n",
    "    \"\"\"State for supervisor pattern with multiple agents.\"\"\"\n",
    "    topic: str\n",
    "    messages: Annotated[List[str], operator.add]\n",
    "    next_agent: str\n",
    "    final_answer: str\n",
    "\n",
    "\n",
    "def researcher_agent(state: SupervisorState) -> dict:\n",
    "    \"\"\"Researcher agent gathers information about the topic.\"\"\"\n",
    "    sys = (\n",
    "        \"You are a researcher. Your job is to gather key facts and information \"\n",
    "        \"about the given topic. Provide 2-3 key points. Be concise.\"\n",
    "    )\n",
    "    messages_for_llm = [\n",
    "        (\"system\", sys),\n",
    "        (\"user\", f\"Research this topic: {state['topic']}\")\n",
    "    ]\n",
    "    resp = llm.invoke(messages_for_llm)\n",
    "    research_msg = f\"RESEARCHER: {resp.content}\"\n",
    "    return {\"messages\": [research_msg]}\n",
    "\n",
    "\n",
    "def expert_agent(state: SupervisorState) -> dict:\n",
    "    \"\"\"Expert agent analyzes and provides insights based on research.\"\"\"\n",
    "    sys = (\n",
    "        \"You are an expert analyst. Review the research provided and give \"\n",
    "        \"your expert analysis and conclusions. Be specific and insightful.\"\n",
    "    )\n",
    "    # Get context from previous messages\n",
    "    context = \"\\n\".join(state[\"messages\"])\n",
    "    messages_for_llm = [\n",
    "        (\"system\", sys),\n",
    "        (\"user\", f\"Topic: {state['topic']}\\n\\nPrevious research:\\n{context}\\n\\nProvide your expert analysis.\")\n",
    "    ]\n",
    "    resp = llm.invoke(messages_for_llm)\n",
    "    expert_msg = f\"EXPERT: {resp.content}\"\n",
    "    return {\"messages\": [expert_msg]}\n",
    "\n",
    "\n",
    "def supervisor_agent(state: SupervisorState) -> dict:\n",
    "    \"\"\"Supervisor decides which agent should act next or if discussion should end.\"\"\"\n",
    "    sys = (\n",
    "        \"You are a supervisor managing a research discussion between a RESEARCHER and an EXPERT. \"\n",
    "        \"Based on the conversation so far, decide what should happen next:\\n\"\n",
    "        \"- Return 'researcher' if we need initial research or more information\\n\"\n",
    "        \"- Return 'expert' if research is done and we need expert analysis\\n\"\n",
    "        \"- Return 'end' if both research and expert analysis are complete\\n\\n\"\n",
    "        \"Respond with ONLY one word: researcher, expert, or end\"\n",
    "    )\n",
    "\n",
    "    context = \"\\n\".join(state[\"messages\"]) if state[\"messages\"] else \"No discussion yet\"\n",
    "    messages_for_llm = [\n",
    "        (\"system\", sys),\n",
    "        (\"user\", f\"Topic: {state['topic']}\\n\\nConversation:\\n{context}\\n\\nWhat's next?\")\n",
    "    ]\n",
    "    resp = llm.invoke(messages_for_llm)\n",
    "    next_step = resp.content.strip().lower()\n",
    "\n",
    "    # Ensure valid response\n",
    "    if next_step not in [\"researcher\", \"expert\", \"end\"]:\n",
    "        next_step = \"end\"\n",
    "\n",
    "    return {\"next_agent\": next_step}\n",
    "\n",
    "\n",
    "def finalize_answer(state: SupervisorState) -> dict:\n",
    "    \"\"\"Compile final answer from the discussion.\"\"\"\n",
    "    sys = (\n",
    "        \"Summarize the research discussion into a clear, concise final answer. \"\n",
    "        \"Include key findings and expert insights.\"\n",
    "    )\n",
    "    context = \"\\n\".join(state[\"messages\"])\n",
    "    messages_for_llm = [\n",
    "        (\"system\", sys),\n",
    "        (\"user\", f\"Topic: {state['topic']}\\n\\nDiscussion:\\n{context}\\n\\nProvide final summary:\")\n",
    "    ]\n",
    "    resp = llm.invoke(messages_for_llm)\n",
    "    return {\"final_answer\": resp.content}\n",
    "\n",
    "\n",
    "def route_supervisor(state: SupervisorState) -> str:\n",
    "    \"\"\"Route based on supervisor's decision.\"\"\"\n",
    "    next_agent = state.get(\"next_agent\", \"researcher\")\n",
    "    if next_agent == \"end\":\n",
    "        return \"finalize\"\n",
    "    return next_agent\n",
    "\n",
    "supervisor_graph = StateGraph(SupervisorState)\n",
    "\n",
    "supervisor_graph.add_node(\"supervisor\", supervisor_agent)\n",
    "supervisor_graph.add_node(\"researcher\", researcher_agent)\n",
    "supervisor_graph.add_node(\"expert\", expert_agent)\n",
    "supervisor_graph.add_node(\"finalize\", finalize_answer)\n",
    "\n",
    "supervisor_graph.add_edge(START, \"supervisor\")\n",
    "\n",
    "supervisor_graph.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    route_supervisor,\n",
    "    {\n",
    "        \"researcher\": \"researcher\",\n",
    "        \"expert\": \"expert\",\n",
    "        \"finalize\": \"finalize\"\n",
    "    }\n",
    ")\n",
    "\n",
    "supervisor_graph.add_edge(\"researcher\", \"supervisor\")\n",
    "supervisor_graph.add_edge(\"expert\", \"supervisor\")\n",
    "\n",
    "supervisor_graph.add_edge(\"finalize\", END)\n",
    "\n",
    "supervisor_agent_graph = supervisor_graph.compile(debug=True)\n",
    "\n",
    "topic = \"What are the main benefits of using LangGraph for building AI agents?\"\n",
    "\n",
    "initial_state = {\n",
    "    \"topic\": topic,\n",
    "    \"messages\": [],\n",
    "    \"next_agent\": \"\",\n",
    "    \"final_answer\": \"\"\n",
    "}\n",
    "\n",
    "result = supervisor_agent_graph.invoke(initial_state)\n",
    "\n",
    "print(f\"TOPIC: {topic}\\n\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nDISCUSSION:\")\n",
    "print(\"-\" * 80)\n",
    "for msg in result[\"messages\"]:\n",
    "    print(f\"\\n{msg}\\n\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nFINAL ANSWER:\\n{result['final_answer']}\")\n"
   ],
   "id": "68458fef5529f946",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m[values]\u001B[0m {'topic': 'What are the main benefits of using LangGraph for building AI agents?', 'messages': [], 'next_agent': '', 'final_answer': ''}\n",
      "\u001B[1m[updates]\u001B[0m {'supervisor': {'next_agent': 'researcher'}}\n",
      "\u001B[1m[values]\u001B[0m {'topic': 'What are the main benefits of using LangGraph for building AI agents?', 'messages': [], 'next_agent': 'researcher', 'final_answer': ''}\n",
      "\u001B[1m[updates]\u001B[0m {'researcher': {'messages': ['RESEARCHER: 1. **Modular Design**: LangGraph offers a modular architecture that allows developers to easily integrate various components and functionalities, facilitating the rapid development and customization of AI agents.\\n\\n2. **Enhanced Natural Language Processing**: It leverages advanced natural language processing capabilities, enabling AI agents to understand and generate human-like responses, improving user interaction and engagement.\\n\\n3. **Scalability and Flexibility**: LangGraph is designed to be scalable, allowing developers to build AI agents that can handle varying workloads and adapt to different use cases, making it suitable for both small projects and large-scale applications.']}}\n",
      "\u001B[1m[values]\u001B[0m {'topic': 'What are the main benefits of using LangGraph for building AI agents?', 'messages': ['RESEARCHER: 1. **Modular Design**: LangGraph offers a modular architecture that allows developers to easily integrate various components and functionalities, facilitating the rapid development and customization of AI agents.\\n\\n2. **Enhanced Natural Language Processing**: It leverages advanced natural language processing capabilities, enabling AI agents to understand and generate human-like responses, improving user interaction and engagement.\\n\\n3. **Scalability and Flexibility**: LangGraph is designed to be scalable, allowing developers to build AI agents that can handle varying workloads and adapt to different use cases, making it suitable for both small projects and large-scale applications.'], 'next_agent': 'researcher', 'final_answer': ''}\n",
      "\u001B[1m[updates]\u001B[0m {'supervisor': {'next_agent': 'expert'}}\n",
      "\u001B[1m[values]\u001B[0m {'topic': 'What are the main benefits of using LangGraph for building AI agents?', 'messages': ['RESEARCHER: 1. **Modular Design**: LangGraph offers a modular architecture that allows developers to easily integrate various components and functionalities, facilitating the rapid development and customization of AI agents.\\n\\n2. **Enhanced Natural Language Processing**: It leverages advanced natural language processing capabilities, enabling AI agents to understand and generate human-like responses, improving user interaction and engagement.\\n\\n3. **Scalability and Flexibility**: LangGraph is designed to be scalable, allowing developers to build AI agents that can handle varying workloads and adapt to different use cases, making it suitable for both small projects and large-scale applications.'], 'next_agent': 'expert', 'final_answer': ''}\n",
      "\u001B[1m[updates]\u001B[0m {'expert': {'messages': ['EXPERT: The research highlights several key benefits of using LangGraph for building AI agents, each of which plays a crucial role in the development and deployment of effective AI solutions. Here’s a detailed analysis of the points raised:\\n\\n1. **Modular Design**:\\n   - **Analysis**: The modular architecture of LangGraph is a significant advantage for developers. It allows for the separation of concerns, meaning that different functionalities can be developed, tested, and maintained independently. This modularity not only accelerates the development process but also enhances the ability to customize AI agents to meet specific needs. Developers can easily swap out components or add new features without overhauling the entire system, which is particularly beneficial in agile development environments where requirements may evolve rapidly.\\n   - **Conclusion**: The modular design fosters innovation and experimentation, enabling teams to iterate quickly and respond to user feedback effectively. This flexibility can lead to more robust and user-centric AI solutions.\\n\\n2. **Enhanced Natural Language Processing**:\\n   - **Analysis**: The emphasis on advanced natural language processing (NLP) capabilities is critical in today’s AI landscape, where user interaction is often mediated through conversational interfaces. LangGraph’s ability to understand and generate human-like responses can significantly enhance user experience, making interactions more intuitive and engaging. This is particularly important in applications such as customer service, virtual assistants, and educational tools, where effective communication is paramount.\\n   - **Conclusion**: By improving the quality of interactions, LangGraph can help organizations build stronger relationships with users, leading to higher satisfaction and retention rates. The enhanced NLP capabilities position LangGraph as a competitive choice for developers focused on creating conversational AI.\\n\\n3. **Scalability and Flexibility**:\\n   - **Analysis**: Scalability is a critical factor for any technology that aims to support a wide range of applications, from small-scale projects to enterprise-level solutions. LangGraph’s design allows developers to scale their AI agents seamlessly, accommodating increased workloads without compromising performance. This flexibility is essential for businesses that anticipate growth or fluctuating demand, as it ensures that their AI solutions can evolve alongside their needs.\\n   - **Conclusion**: The ability to scale effectively means that organizations can invest in LangGraph with confidence, knowing that their AI agents can grow and adapt over time. This adaptability is a key differentiator in a market where businesses are increasingly looking for long-term, sustainable technology solutions.\\n\\n**Overall Insights**:\\nLangGraph presents a compelling option for developers looking to build AI agents due to its modular design, advanced NLP capabilities, and scalability. These features not only streamline the development process but also enhance the end-user experience, making it easier for organizations to deploy effective AI solutions that can adapt to changing needs. As AI continues to evolve, tools like LangGraph that prioritize flexibility and user engagement will likely become increasingly valuable in the tech landscape. \\n\\nIn conclusion, LangGraph stands out as a robust framework for AI agent development, offering significant advantages that can lead to more efficient development cycles, improved user interactions, and scalable solutions that meet diverse business needs.']}}\n",
      "\u001B[1m[values]\u001B[0m {'topic': 'What are the main benefits of using LangGraph for building AI agents?', 'messages': ['RESEARCHER: 1. **Modular Design**: LangGraph offers a modular architecture that allows developers to easily integrate various components and functionalities, facilitating the rapid development and customization of AI agents.\\n\\n2. **Enhanced Natural Language Processing**: It leverages advanced natural language processing capabilities, enabling AI agents to understand and generate human-like responses, improving user interaction and engagement.\\n\\n3. **Scalability and Flexibility**: LangGraph is designed to be scalable, allowing developers to build AI agents that can handle varying workloads and adapt to different use cases, making it suitable for both small projects and large-scale applications.', 'EXPERT: The research highlights several key benefits of using LangGraph for building AI agents, each of which plays a crucial role in the development and deployment of effective AI solutions. Here’s a detailed analysis of the points raised:\\n\\n1. **Modular Design**:\\n   - **Analysis**: The modular architecture of LangGraph is a significant advantage for developers. It allows for the separation of concerns, meaning that different functionalities can be developed, tested, and maintained independently. This modularity not only accelerates the development process but also enhances the ability to customize AI agents to meet specific needs. Developers can easily swap out components or add new features without overhauling the entire system, which is particularly beneficial in agile development environments where requirements may evolve rapidly.\\n   - **Conclusion**: The modular design fosters innovation and experimentation, enabling teams to iterate quickly and respond to user feedback effectively. This flexibility can lead to more robust and user-centric AI solutions.\\n\\n2. **Enhanced Natural Language Processing**:\\n   - **Analysis**: The emphasis on advanced natural language processing (NLP) capabilities is critical in today’s AI landscape, where user interaction is often mediated through conversational interfaces. LangGraph’s ability to understand and generate human-like responses can significantly enhance user experience, making interactions more intuitive and engaging. This is particularly important in applications such as customer service, virtual assistants, and educational tools, where effective communication is paramount.\\n   - **Conclusion**: By improving the quality of interactions, LangGraph can help organizations build stronger relationships with users, leading to higher satisfaction and retention rates. The enhanced NLP capabilities position LangGraph as a competitive choice for developers focused on creating conversational AI.\\n\\n3. **Scalability and Flexibility**:\\n   - **Analysis**: Scalability is a critical factor for any technology that aims to support a wide range of applications, from small-scale projects to enterprise-level solutions. LangGraph’s design allows developers to scale their AI agents seamlessly, accommodating increased workloads without compromising performance. This flexibility is essential for businesses that anticipate growth or fluctuating demand, as it ensures that their AI solutions can evolve alongside their needs.\\n   - **Conclusion**: The ability to scale effectively means that organizations can invest in LangGraph with confidence, knowing that their AI agents can grow and adapt over time. This adaptability is a key differentiator in a market where businesses are increasingly looking for long-term, sustainable technology solutions.\\n\\n**Overall Insights**:\\nLangGraph presents a compelling option for developers looking to build AI agents due to its modular design, advanced NLP capabilities, and scalability. These features not only streamline the development process but also enhance the end-user experience, making it easier for organizations to deploy effective AI solutions that can adapt to changing needs. As AI continues to evolve, tools like LangGraph that prioritize flexibility and user engagement will likely become increasingly valuable in the tech landscape. \\n\\nIn conclusion, LangGraph stands out as a robust framework for AI agent development, offering significant advantages that can lead to more efficient development cycles, improved user interactions, and scalable solutions that meet diverse business needs.'], 'next_agent': 'expert', 'final_answer': ''}\n",
      "\u001B[1m[updates]\u001B[0m {'supervisor': {'next_agent': 'end'}}\n",
      "\u001B[1m[values]\u001B[0m {'topic': 'What are the main benefits of using LangGraph for building AI agents?', 'messages': ['RESEARCHER: 1. **Modular Design**: LangGraph offers a modular architecture that allows developers to easily integrate various components and functionalities, facilitating the rapid development and customization of AI agents.\\n\\n2. **Enhanced Natural Language Processing**: It leverages advanced natural language processing capabilities, enabling AI agents to understand and generate human-like responses, improving user interaction and engagement.\\n\\n3. **Scalability and Flexibility**: LangGraph is designed to be scalable, allowing developers to build AI agents that can handle varying workloads and adapt to different use cases, making it suitable for both small projects and large-scale applications.', 'EXPERT: The research highlights several key benefits of using LangGraph for building AI agents, each of which plays a crucial role in the development and deployment of effective AI solutions. Here’s a detailed analysis of the points raised:\\n\\n1. **Modular Design**:\\n   - **Analysis**: The modular architecture of LangGraph is a significant advantage for developers. It allows for the separation of concerns, meaning that different functionalities can be developed, tested, and maintained independently. This modularity not only accelerates the development process but also enhances the ability to customize AI agents to meet specific needs. Developers can easily swap out components or add new features without overhauling the entire system, which is particularly beneficial in agile development environments where requirements may evolve rapidly.\\n   - **Conclusion**: The modular design fosters innovation and experimentation, enabling teams to iterate quickly and respond to user feedback effectively. This flexibility can lead to more robust and user-centric AI solutions.\\n\\n2. **Enhanced Natural Language Processing**:\\n   - **Analysis**: The emphasis on advanced natural language processing (NLP) capabilities is critical in today’s AI landscape, where user interaction is often mediated through conversational interfaces. LangGraph’s ability to understand and generate human-like responses can significantly enhance user experience, making interactions more intuitive and engaging. This is particularly important in applications such as customer service, virtual assistants, and educational tools, where effective communication is paramount.\\n   - **Conclusion**: By improving the quality of interactions, LangGraph can help organizations build stronger relationships with users, leading to higher satisfaction and retention rates. The enhanced NLP capabilities position LangGraph as a competitive choice for developers focused on creating conversational AI.\\n\\n3. **Scalability and Flexibility**:\\n   - **Analysis**: Scalability is a critical factor for any technology that aims to support a wide range of applications, from small-scale projects to enterprise-level solutions. LangGraph’s design allows developers to scale their AI agents seamlessly, accommodating increased workloads without compromising performance. This flexibility is essential for businesses that anticipate growth or fluctuating demand, as it ensures that their AI solutions can evolve alongside their needs.\\n   - **Conclusion**: The ability to scale effectively means that organizations can invest in LangGraph with confidence, knowing that their AI agents can grow and adapt over time. This adaptability is a key differentiator in a market where businesses are increasingly looking for long-term, sustainable technology solutions.\\n\\n**Overall Insights**:\\nLangGraph presents a compelling option for developers looking to build AI agents due to its modular design, advanced NLP capabilities, and scalability. These features not only streamline the development process but also enhance the end-user experience, making it easier for organizations to deploy effective AI solutions that can adapt to changing needs. As AI continues to evolve, tools like LangGraph that prioritize flexibility and user engagement will likely become increasingly valuable in the tech landscape. \\n\\nIn conclusion, LangGraph stands out as a robust framework for AI agent development, offering significant advantages that can lead to more efficient development cycles, improved user interactions, and scalable solutions that meet diverse business needs.'], 'next_agent': 'end', 'final_answer': ''}\n",
      "\u001B[1m[updates]\u001B[0m {'finalize': {'final_answer': \"LangGraph offers several key benefits for building AI agents, making it a compelling choice for developers. \\n\\n1. **Modular Design**: Its modular architecture allows for easy integration and customization of components, facilitating rapid development and enabling teams to iterate quickly in response to user feedback.\\n\\n2. **Enhanced Natural Language Processing**: LangGraph's advanced NLP capabilities improve user interactions by enabling AI agents to understand and generate human-like responses, which is crucial for applications like customer service and virtual assistants.\\n\\n3. **Scalability and Flexibility**: The framework is designed to scale seamlessly, accommodating varying workloads and adapting to different use cases, which is essential for businesses anticipating growth or fluctuating demands.\\n\\nOverall, LangGraph streamlines the development process, enhances user engagement, and provides scalable solutions, positioning it as a valuable tool in the evolving AI landscape.\"}}\n",
      "\u001B[1m[values]\u001B[0m {'topic': 'What are the main benefits of using LangGraph for building AI agents?', 'messages': ['RESEARCHER: 1. **Modular Design**: LangGraph offers a modular architecture that allows developers to easily integrate various components and functionalities, facilitating the rapid development and customization of AI agents.\\n\\n2. **Enhanced Natural Language Processing**: It leverages advanced natural language processing capabilities, enabling AI agents to understand and generate human-like responses, improving user interaction and engagement.\\n\\n3. **Scalability and Flexibility**: LangGraph is designed to be scalable, allowing developers to build AI agents that can handle varying workloads and adapt to different use cases, making it suitable for both small projects and large-scale applications.', 'EXPERT: The research highlights several key benefits of using LangGraph for building AI agents, each of which plays a crucial role in the development and deployment of effective AI solutions. Here’s a detailed analysis of the points raised:\\n\\n1. **Modular Design**:\\n   - **Analysis**: The modular architecture of LangGraph is a significant advantage for developers. It allows for the separation of concerns, meaning that different functionalities can be developed, tested, and maintained independently. This modularity not only accelerates the development process but also enhances the ability to customize AI agents to meet specific needs. Developers can easily swap out components or add new features without overhauling the entire system, which is particularly beneficial in agile development environments where requirements may evolve rapidly.\\n   - **Conclusion**: The modular design fosters innovation and experimentation, enabling teams to iterate quickly and respond to user feedback effectively. This flexibility can lead to more robust and user-centric AI solutions.\\n\\n2. **Enhanced Natural Language Processing**:\\n   - **Analysis**: The emphasis on advanced natural language processing (NLP) capabilities is critical in today’s AI landscape, where user interaction is often mediated through conversational interfaces. LangGraph’s ability to understand and generate human-like responses can significantly enhance user experience, making interactions more intuitive and engaging. This is particularly important in applications such as customer service, virtual assistants, and educational tools, where effective communication is paramount.\\n   - **Conclusion**: By improving the quality of interactions, LangGraph can help organizations build stronger relationships with users, leading to higher satisfaction and retention rates. The enhanced NLP capabilities position LangGraph as a competitive choice for developers focused on creating conversational AI.\\n\\n3. **Scalability and Flexibility**:\\n   - **Analysis**: Scalability is a critical factor for any technology that aims to support a wide range of applications, from small-scale projects to enterprise-level solutions. LangGraph’s design allows developers to scale their AI agents seamlessly, accommodating increased workloads without compromising performance. This flexibility is essential for businesses that anticipate growth or fluctuating demand, as it ensures that their AI solutions can evolve alongside their needs.\\n   - **Conclusion**: The ability to scale effectively means that organizations can invest in LangGraph with confidence, knowing that their AI agents can grow and adapt over time. This adaptability is a key differentiator in a market where businesses are increasingly looking for long-term, sustainable technology solutions.\\n\\n**Overall Insights**:\\nLangGraph presents a compelling option for developers looking to build AI agents due to its modular design, advanced NLP capabilities, and scalability. These features not only streamline the development process but also enhance the end-user experience, making it easier for organizations to deploy effective AI solutions that can adapt to changing needs. As AI continues to evolve, tools like LangGraph that prioritize flexibility and user engagement will likely become increasingly valuable in the tech landscape. \\n\\nIn conclusion, LangGraph stands out as a robust framework for AI agent development, offering significant advantages that can lead to more efficient development cycles, improved user interactions, and scalable solutions that meet diverse business needs.'], 'next_agent': 'end', 'final_answer': \"LangGraph offers several key benefits for building AI agents, making it a compelling choice for developers. \\n\\n1. **Modular Design**: Its modular architecture allows for easy integration and customization of components, facilitating rapid development and enabling teams to iterate quickly in response to user feedback.\\n\\n2. **Enhanced Natural Language Processing**: LangGraph's advanced NLP capabilities improve user interactions by enabling AI agents to understand and generate human-like responses, which is crucial for applications like customer service and virtual assistants.\\n\\n3. **Scalability and Flexibility**: The framework is designed to scale seamlessly, accommodating varying workloads and adapting to different use cases, which is essential for businesses anticipating growth or fluctuating demands.\\n\\nOverall, LangGraph streamlines the development process, enhances user engagement, and provides scalable solutions, positioning it as a valuable tool in the evolving AI landscape.\"}\n",
      "TOPIC: What are the main benefits of using LangGraph for building AI agents?\n",
      "\n",
      "================================================================================\n",
      "\n",
      "DISCUSSION:\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "RESEARCHER: 1. **Modular Design**: LangGraph offers a modular architecture that allows developers to easily integrate various components and functionalities, facilitating the rapid development and customization of AI agents.\n",
      "\n",
      "2. **Enhanced Natural Language Processing**: It leverages advanced natural language processing capabilities, enabling AI agents to understand and generate human-like responses, improving user interaction and engagement.\n",
      "\n",
      "3. **Scalability and Flexibility**: LangGraph is designed to be scalable, allowing developers to build AI agents that can handle varying workloads and adapt to different use cases, making it suitable for both small projects and large-scale applications.\n",
      "\n",
      "\n",
      "EXPERT: The research highlights several key benefits of using LangGraph for building AI agents, each of which plays a crucial role in the development and deployment of effective AI solutions. Here’s a detailed analysis of the points raised:\n",
      "\n",
      "1. **Modular Design**:\n",
      "   - **Analysis**: The modular architecture of LangGraph is a significant advantage for developers. It allows for the separation of concerns, meaning that different functionalities can be developed, tested, and maintained independently. This modularity not only accelerates the development process but also enhances the ability to customize AI agents to meet specific needs. Developers can easily swap out components or add new features without overhauling the entire system, which is particularly beneficial in agile development environments where requirements may evolve rapidly.\n",
      "   - **Conclusion**: The modular design fosters innovation and experimentation, enabling teams to iterate quickly and respond to user feedback effectively. This flexibility can lead to more robust and user-centric AI solutions.\n",
      "\n",
      "2. **Enhanced Natural Language Processing**:\n",
      "   - **Analysis**: The emphasis on advanced natural language processing (NLP) capabilities is critical in today’s AI landscape, where user interaction is often mediated through conversational interfaces. LangGraph’s ability to understand and generate human-like responses can significantly enhance user experience, making interactions more intuitive and engaging. This is particularly important in applications such as customer service, virtual assistants, and educational tools, where effective communication is paramount.\n",
      "   - **Conclusion**: By improving the quality of interactions, LangGraph can help organizations build stronger relationships with users, leading to higher satisfaction and retention rates. The enhanced NLP capabilities position LangGraph as a competitive choice for developers focused on creating conversational AI.\n",
      "\n",
      "3. **Scalability and Flexibility**:\n",
      "   - **Analysis**: Scalability is a critical factor for any technology that aims to support a wide range of applications, from small-scale projects to enterprise-level solutions. LangGraph’s design allows developers to scale their AI agents seamlessly, accommodating increased workloads without compromising performance. This flexibility is essential for businesses that anticipate growth or fluctuating demand, as it ensures that their AI solutions can evolve alongside their needs.\n",
      "   - **Conclusion**: The ability to scale effectively means that organizations can invest in LangGraph with confidence, knowing that their AI agents can grow and adapt over time. This adaptability is a key differentiator in a market where businesses are increasingly looking for long-term, sustainable technology solutions.\n",
      "\n",
      "**Overall Insights**:\n",
      "LangGraph presents a compelling option for developers looking to build AI agents due to its modular design, advanced NLP capabilities, and scalability. These features not only streamline the development process but also enhance the end-user experience, making it easier for organizations to deploy effective AI solutions that can adapt to changing needs. As AI continues to evolve, tools like LangGraph that prioritize flexibility and user engagement will likely become increasingly valuable in the tech landscape. \n",
      "\n",
      "In conclusion, LangGraph stands out as a robust framework for AI agent development, offering significant advantages that can lead to more efficient development cycles, improved user interactions, and scalable solutions that meet diverse business needs.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "FINAL ANSWER:\n",
      "LangGraph offers several key benefits for building AI agents, making it a compelling choice for developers. \n",
      "\n",
      "1. **Modular Design**: Its modular architecture allows for easy integration and customization of components, facilitating rapid development and enabling teams to iterate quickly in response to user feedback.\n",
      "\n",
      "2. **Enhanced Natural Language Processing**: LangGraph's advanced NLP capabilities improve user interactions by enabling AI agents to understand and generate human-like responses, which is crucial for applications like customer service and virtual assistants.\n",
      "\n",
      "3. **Scalability and Flexibility**: The framework is designed to scale seamlessly, accommodating varying workloads and adapting to different use cases, which is essential for businesses anticipating growth or fluctuating demands.\n",
      "\n",
      "Overall, LangGraph streamlines the development process, enhances user engagement, and provides scalable solutions, positioning it as a valuable tool in the evolving AI landscape.\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
