{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": "## Criteria evaluator",
   "id": "8843f9eae98bb3a4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T10:39:29.601718Z",
     "start_time": "2025-11-09T10:39:28.222655Z"
    }
   },
   "cell_type": "code",
   "source": "! pip install langchain",
   "id": "7ed73b5635c08dd3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /home/michal/anaconda3/lib/python3.13/site-packages (1.0.4)\r\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain) (1.0.3)\r\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain) (1.0.2)\r\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain) (2.11.10)\r\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (1.33)\r\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (0.4.41)\r\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (24.2)\r\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (6.0.2)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (9.0.0)\r\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (4.15.0)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/michal/anaconda3/lib/python3.13/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain) (3.0.0)\r\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (2.1.1)\r\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /home/michal/anaconda3/lib/python3.13/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.2)\r\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /home/michal/anaconda3/lib/python3.13/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.4)\r\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.5.0)\r\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.10.0)\r\n",
      "Requirement already satisfied: httpx>=0.25.2 in /home/michal/anaconda3/lib/python3.13/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\r\n",
      "Requirement already satisfied: orjson>=3.10.1 in /home/michal/anaconda3/lib/python3.13/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.10.14)\r\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (1.0.0)\r\n",
      "Requirement already satisfied: requests>=2.0.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (2.32.5)\r\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (0.23.0)\r\n",
      "Requirement already satisfied: anyio in /home/michal/.local/lib/python3.13/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (4.10.0)\r\n",
      "Requirement already satisfied: certifi in /home/michal/anaconda3/lib/python3.13/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (2025.8.3)\r\n",
      "Requirement already satisfied: httpcore==1.* in /home/michal/.local/lib/python3.13/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\r\n",
      "Requirement already satisfied: idna in /home/michal/anaconda3/lib/python3.13/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.7)\r\n",
      "Requirement already satisfied: h11>=0.16 in /home/michal/.local/lib/python3.13/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/michal/anaconda3/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/michal/anaconda3/lib/python3.13/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (3.3.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/michal/anaconda3/lib/python3.13/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (2.5.0)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/michal/.local/lib/python3.13/site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.3.1)\r\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T10:39:29.614549Z",
     "start_time": "2025-11-09T10:39:29.609731Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ],
   "id": "4314476479fc9ff2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Prosta ewaluacja za pomocą kryteriów\n",
    "Criteria evaluator w LangChain służy do oceniania wyników modeli LLM według zadanego kryterium, np. correctness (poprawność)."
   ],
   "id": "6bb58b1026d0c7b3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T10:39:33.448957Z",
     "start_time": "2025-11-09T10:39:29.661010Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_classic.evaluation import load_evaluator\n",
    "import json\n",
    "\n",
    "# 1) Użyjemy ewaluatora z referencją (labeled_criteria)\n",
    "evaluator = load_evaluator(\"labeled_criteria\", criteria=\"correctness\")\n",
    "\n",
    "# 2) Porównujemy odpowiedź modelu z referencją\n",
    "result = evaluator.evaluate_strings(\n",
    "    prediction=\"2 + 2 = 4\",\n",
    "    input=\"Policz 2 + 2\",\n",
    "    reference=\"4\",\n",
    ")\n",
    "\n",
    "print(json.dumps(result, indent=4))"
   ],
   "id": "4cfeb05a83149965",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"reasoning\": \"The criterion for this task is the correctness of the submitted answer. The input asks to calculate 2 + 2. The submitted answer is 2 + 2 = 4. The reference answer is 4. The submitted answer matches the reference answer, which means the submission is correct, accurate, and factual. Therefore, the submission meets the criterion.\\n\\nY\",\n",
      "    \"value\": \"Y\",\n",
      "    \"score\": 1\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Import bibliotek i konfiguracja LangSmith",
   "id": "ac46d5ee26a3d0c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T10:39:33.504228Z",
     "start_time": "2025-11-09T10:39:33.501213Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from langsmith import Client\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Włącz śledzenie LangSmith (wymaga konta LangSmith):\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"kurs-demo\"\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "# os.environ[\"LANGSMITH_API_KEY\"] = \"<TWÓJ_KLUCZ>\" #załączony w .env"
   ],
   "id": "cf17db6aeeff602",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Wygenerowanie odpowiedzi LLM",
   "id": "e9d4774abf0ed3af"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T10:39:36.816219Z",
     "start_time": "2025-11-09T10:39:33.550097Z"
    }
   },
   "cell_type": "code",
   "source": [
    "client = Client()\n",
    "dataset_inputs = [\n",
    "    \"Why people don't have 3 legs?\",\n",
    "    \"Why people are not flying?\",\n",
    "]\n",
    "\n",
    "llm_test= ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.1,max_tokens=256)\n",
    "llm_gen = ChatOpenAI(model=\"gpt-4o\", temperature=0.1,max_tokens=256)\n",
    "\n",
    "dataset_outputs = [\n",
    "    {\"result\": llm_test.invoke(dataset_inputs[0])},\n",
    "    {\"result\": llm_test.invoke(dataset_inputs[1])},\n",
    "]\n",
    "print(dataset_outputs)"
   ],
   "id": "27480c014402c055",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'result': AIMessage(content='People do not have three legs because humans are typically born with two legs as part of their natural anatomy. The human body has evolved over millions of years to have two legs for walking and running efficiently. Having a third leg would likely be unnecessary and could potentially hinder movement and balance. Additionally, having an odd number of legs would not be symmetrical and could cause issues with coordination and stability.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 78, 'prompt_tokens': 16, 'total_tokens': 94, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CZx7V734Ub0Fy3FLYsWHRKojzvhEc', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--229fa692-4c71-4d4c-a139-419f90be6bcb-0', usage_metadata={'input_tokens': 16, 'output_tokens': 78, 'total_tokens': 94, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}, {'result': AIMessage(content='There are several reasons why people may not be flying, including:\\n\\n1. Fear of COVID-19: Many people are hesitant to fly due to concerns about contracting the virus while traveling in close quarters with others.\\n\\n2. Travel restrictions: Some countries have implemented travel restrictions or quarantine requirements, making it difficult or impossible for people to fly to certain destinations.\\n\\n3. Economic uncertainty: The pandemic has caused financial hardship for many people, leading them to cut back on non-essential expenses like travel.\\n\\n4. Reduced flight options: Airlines have cut back on routes and flights due to decreased demand, making it harder for people to find convenient or affordable options for air travel.\\n\\n5. Environmental concerns: Some people are choosing to avoid flying due to the environmental impact of air travel, such as carbon emissions and fuel consumption.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 161, 'prompt_tokens': 13, 'total_tokens': 174, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CZx7WDganJJckjPCzD8Lz5wjNjFAV', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--369875ff-16f7-426f-bc3b-d7131370d7d8-0', usage_metadata={'input_tokens': 13, 'output_tokens': 161, 'total_tokens': 174, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}]\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Custom evaluator",
   "id": "acc9841b5f96eb6d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T10:39:36.870558Z",
     "start_time": "2025-11-09T10:39:36.868718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_classic.smith import RunEvalConfig\n",
    "from langsmith.evaluation import EvaluationResult, run_evaluator\n"
   ],
   "id": "8023eabc8a50335e",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T10:39:36.919402Z",
     "start_time": "2025-11-09T10:39:36.915527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@run_evaluator\n",
    "def custom_evaluator(run) -> EvaluationResult:\n",
    "    \"\"\"\n",
    "    checks if output contains specific word\n",
    "    :param run:\n",
    "    :return: int\n",
    "    \"\"\"\n",
    "    generated = run.outputs[\"generations\"][0][0][\"text\"]\n",
    "    if 'human' in generated:\n",
    "        score = 1\n",
    "    else:\n",
    "        score = 0\n",
    "    return EvaluationResult(key=\"result\", score=score)\n",
    "\n",
    "eval_config = RunEvalConfig(\n",
    "    custom_evaluator=[custom_evaluator],\n",
    "    evaluators=[\n",
    "        \"criteria\",\n",
    "        \"qa\",         # bezpośrednio oceń odpowiedź jako \"poprawną\" lub \"niepoprawną\" na podstawie odpowiedzi referencyjnej\n",
    "        \"context_qa\", # użyj podanego kontekstu odniesienia w celu ustalenia poprawności\n",
    "        \"cot_qa\",     # chain of thought \"reasoning\"\n",
    "        RunEvalConfig.Criteria(name=\"insensitivity\"),\n",
    "        RunEvalConfig.Criteria(name=\"relevance\"),\n",
    "        RunEvalConfig.Criteria(name=\"helpfulness\"),\n",
    "        RunEvalConfig.Criteria(name=\"maliciousness\"),\n",
    "        RunEvalConfig.Criteria(name=\"harmfulness\"),\n",
    "        RunEvalConfig.Criteria(name=\"coherence\"),\n",
    "        RunEvalConfig.Criteria(name=\"conciseness\"),\n",
    "        RunEvalConfig.Criteria(name=\"misogyny\"),\n",
    "        RunEvalConfig.Criteria(name=\"criminality\"),\n",
    "        RunEvalConfig.Criteria(name=\"controversiality\"),\n",
    "        RunEvalConfig.Criteria( # własne zdefiniowane kryteria, które dotyczą problemu wystepujacego w generowanych odpowiedziach\n",
    "            name={\n",
    "                \"valuation\": \"Do texts contain valuation of subject, like glorifying some characteristic or judging someone?\"\n",
    "                \"Respond Y if they do, N if they're entirely objective and stick to the facts without additions.\"\n",
    "            }\n",
    "        )\n",
    "    ],\n",
    ")"
   ],
   "id": "4ba85a0d2f3c7b5b",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Uruchomienie i integracja z LangSmith",
   "id": "bd0f9d94d74fa847"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T10:39:38.721222Z",
     "start_time": "2025-11-09T10:39:36.966957Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import uuid\n",
    "\n",
    "dataset_name = \"existential questions run:\" + uuid.uuid4().__str__() #wymagana zmiana parametru przy każdym uruchomieniu\n",
    "\n",
    "dataset = client.create_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    description=\"evaluate LLM output\",\n",
    ")\n",
    "client.create_examples(\n",
    "    inputs=[{\"question\": q} for q in dataset_inputs],\n",
    "    outputs=dataset_outputs,\n",
    "    dataset_id=dataset.id,\n",
    ")"
   ],
   "id": "6bb2665b8e63ae60",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'example_ids': ['25d47eab-10d6-4327-a8ae-9e9dffb0668a',\n",
       "  '87ae9cd8-84b4-4f1e-b82f-813d8ca2a499'],\n",
       " 'count': 2}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T10:39:38.829317Z",
     "start_time": "2025-11-09T10:39:38.777621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#in case of error ‘model is currently loading;’, wait couple of minutes and run notebook again\n",
    "scores = client.run_on_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    llm_or_chain_factory=llm_gen,\n",
    "    evaluation=eval_config,\n",
    "    verbose=True,\n",
    "    project_name=dataset_name,\n",
    ")\n",
    "print(scores)"
   ],
   "id": "ae68836866445a56",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "The client.run_on_dataset function requires the langchainpackage to run.\nInstall with pip install langchain",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/lib/python3.13/site-packages/langsmith/client.py:7225\u001B[39m, in \u001B[36mClient.run_on_dataset\u001B[39m\u001B[34m(self, dataset_name, llm_or_chain_factory, evaluation, concurrency_level, project_name, project_metadata, dataset_version, verbose, input_mapper, revision_id, **kwargs)\u001B[39m\n\u001B[32m   7224\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m7225\u001B[39m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlangchain\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01msmith\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m   7226\u001B[39m         run_on_dataset \u001B[38;5;28;01mas\u001B[39;00m _run_on_dataset,  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[32m   7227\u001B[39m     )\n\u001B[32m   7228\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'langchain.smith'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[31mImportError\u001B[39m                               Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[31]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m#in case of error ‘model is currently loading;’, wait couple of minutes and run notebook again\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m scores = \u001B[43mclient\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun_on_dataset\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m      3\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdataset_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdataset_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      4\u001B[39m \u001B[43m    \u001B[49m\u001B[43mllm_or_chain_factory\u001B[49m\u001B[43m=\u001B[49m\u001B[43mllm_gen\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      5\u001B[39m \u001B[43m    \u001B[49m\u001B[43mevaluation\u001B[49m\u001B[43m=\u001B[49m\u001B[43meval_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      6\u001B[39m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m      7\u001B[39m \u001B[43m    \u001B[49m\u001B[43mproject_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdataset_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      8\u001B[39m \u001B[43m)\u001B[49m\n\u001B[32m      9\u001B[39m \u001B[38;5;28mprint\u001B[39m(scores)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/lib/python3.13/site-packages/langsmith/client.py:7229\u001B[39m, in \u001B[36mClient.run_on_dataset\u001B[39m\u001B[34m(self, dataset_name, llm_or_chain_factory, evaluation, concurrency_level, project_name, project_metadata, dataset_version, verbose, input_mapper, revision_id, **kwargs)\u001B[39m\n\u001B[32m   7225\u001B[39m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlangchain\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01msmith\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m   7226\u001B[39m         run_on_dataset \u001B[38;5;28;01mas\u001B[39;00m _run_on_dataset,  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[32m   7227\u001B[39m     )\n\u001B[32m   7228\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m7229\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\n\u001B[32m   7230\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mThe client.run_on_dataset function requires the langchain\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   7231\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mpackage to run.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mInstall with pip install langchain\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   7232\u001B[39m     )\n\u001B[32m   7233\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m _run_on_dataset(\n\u001B[32m   7234\u001B[39m     dataset_name=dataset_name,\n\u001B[32m   7235\u001B[39m     llm_or_chain_factory=llm_or_chain_factory,\n\u001B[32m   (...)\u001B[39m\u001B[32m   7245\u001B[39m     **kwargs,\n\u001B[32m   7246\u001B[39m )\n",
      "\u001B[31mImportError\u001B[39m: The client.run_on_dataset function requires the langchainpackage to run.\nInstall with pip install langchain"
     ]
    }
   ],
   "execution_count": 31
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
