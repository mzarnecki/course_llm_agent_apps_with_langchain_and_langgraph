{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c85647bfca48639",
   "metadata": {},
   "source": [
    "## LangChain Hello World i rodzaje zadań realizowanych z wykorzystaniem LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfb04be88376bce",
   "metadata": {},
   "source": [
    "### Instalacja bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2999805064e37d83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T05:05:50.078884Z",
     "start_time": "2025-09-20T05:05:48.552278Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-openai in /home/michal/anaconda3/lib/python3.13/site-packages (0.3.33)\r\n",
      "Requirement already satisfied: python-dotenv in /home/michal/anaconda3/lib/python3.13/site-packages (1.1.0)\r\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.76 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-openai) (0.3.76)\r\n",
      "Requirement already satisfied: openai<2.0.0,>=1.104.2 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-openai) (1.107.3)\r\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-openai) (0.11.0)\r\n",
      "Requirement already satisfied: langsmith>=0.3.45 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.76->langchain-openai) (0.4.19)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.76->langchain-openai) (9.0.0)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.76->langchain-openai) (1.33)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.76->langchain-openai) (6.0.2)\r\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.76->langchain-openai) (4.15.0)\r\n",
      "Requirement already satisfied: packaging>=23.2 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.76->langchain-openai) (24.2)\r\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.76->langchain-openai) (2.11.7)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/michal/anaconda3/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.76->langchain-openai) (3.0.0)\r\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/michal/.local/lib/python3.13/site-packages (from openai<2.0.0,>=1.104.2->langchain-openai) (4.10.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from openai<2.0.0,>=1.104.2->langchain-openai) (1.9.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/michal/.local/lib/python3.13/site-packages (from openai<2.0.0,>=1.104.2->langchain-openai) (0.28.1)\r\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from openai<2.0.0,>=1.104.2->langchain-openai) (0.10.0)\r\n",
      "Requirement already satisfied: sniffio in /home/michal/.local/lib/python3.13/site-packages (from openai<2.0.0,>=1.104.2->langchain-openai) (1.3.1)\r\n",
      "Requirement already satisfied: tqdm>4 in /home/michal/anaconda3/lib/python3.13/site-packages (from openai<2.0.0,>=1.104.2->langchain-openai) (4.67.1)\r\n",
      "Requirement already satisfied: idna>=2.8 in /home/michal/anaconda3/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.104.2->langchain-openai) (3.7)\r\n",
      "Requirement already satisfied: certifi in /home/michal/anaconda3/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.104.2->langchain-openai) (2025.8.3)\r\n",
      "Requirement already satisfied: httpcore==1.* in /home/michal/.local/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.104.2->langchain-openai) (1.0.9)\r\n",
      "Requirement already satisfied: h11>=0.16 in /home/michal/.local/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.104.2->langchain-openai) (0.16.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.76->langchain-openai) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/michal/anaconda3/lib/python3.13/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.76->langchain-openai) (2.33.2)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.76->langchain-openai) (0.4.0)\r\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/michal/anaconda3/lib/python3.13/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\r\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.5)\r\n",
      "Requirement already satisfied: orjson>=3.9.14 in /home/michal/anaconda3/lib/python3.13/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.76->langchain-openai) (3.10.14)\r\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.76->langchain-openai) (1.0.0)\r\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.76->langchain-openai) (0.23.0)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/michal/anaconda3/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.3.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/michal/anaconda3/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.5.0)\r\n"
     ]
    }
   ],
   "source": [
    "# przed uruchomeiniem notebooka upewnij się, że posiadasz zainstalowane środowisko Python i Jupyter Notebook - zalecana instalacja środowiska Anaconda https://www.anaconda.com/docs/getting-started/anaconda/install\n",
    "# instalacja potrzebnych pakietów (tylko raz)\n",
    "!pip install langchain-openai python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387b2d7785918f08",
   "metadata": {},
   "source": [
    "### LangChain Hello world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T19:10:37.618774Z",
     "start_time": "2025-10-02T19:10:31.601272Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odpowiedź modelu:\n",
      "\n",
      "Cześć! Mam nadzieję, że masz wspaniały dzień! Pozdrawiam serdecznie!\n"
     ]
    }
   ],
   "source": [
    "# import bibliotek\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# wczytanie zmiennych środowiskowych z pliku .env\n",
    "load_dotenv()\n",
    "\n",
    "# pobranie klucza OpenAI\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"Brak klucza API w pliku .env!\")\n",
    "\n",
    "# utworzenie klienta API OpenAI z wybranym modelem\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, api_key=api_key)\n",
    "\n",
    "# prosty prompt i request do API LLM\n",
    "response = llm.invoke(\"Napisz krótkie pozdrowienie w języku polskim.\")\n",
    "\n",
    "print(\"Odpowiedź modelu:\\n\")\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1124603ed27c0a9",
   "metadata": {},
   "source": [
    "### Generowanie tekstu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bcecd4b93ac98f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T19:24:05.087359Z",
     "start_time": "2025-10-02T19:23:44.564730Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odpowiedź modelu:\n",
      "\n",
      "Oto przepis na nietypowy, słodki sernik z tuńczykiem, brokułem i cebulą. To połączenie smaków może być zaskakujące, ale spróbujmy!\n",
      "\n",
      "### Słodki sernik z tuńczykiem, brokułem i cebulą\n",
      "\n",
      "#### Składniki:\n",
      "\n",
      "**Na spód:**\n",
      "- 200 g herbatników (np. digestive)\n",
      "- 100 g masła\n",
      "\n",
      "**Na masę serową:**\n",
      "- 500 g twarogu (najlepiej zmielonego)\n",
      "- 200 g serka mascarpone\n",
      "- 3 jajka\n",
      "- 100 g cukru\n",
      "- 1 łyżeczka ekstraktu waniliowego\n",
      "- 1 puszka tuńczyka w sosie własnym (około 200 g)\n",
      "- 200 g ugotowanego brokuła (można użyć mrożonego)\n",
      "- 1 mała cebula, drobno posiekana\n",
      "- Sól i pieprz do smaku\n",
      "\n",
      "**Na wierzch:**\n",
      "- 100 g śmietany kremówki\n",
      "- 2 łyżki cukru pudru\n",
      "- Kilka gałązek świeżej bazylii lub natki pietruszki do dekoracji\n",
      "\n",
      "#### Przygotowanie:\n",
      "\n",
      "1. **Przygotowanie spodu:**\n",
      "   - Herbatniki pokrusz na drobno (możesz użyć blendera).\n",
      "   - Roztop masło i wymieszaj z pokruszonymi herbatnikami.\n",
      "   - Wyłóż dno tortownicy (o średnicy 24 cm) papierem do pieczenia i wciśnij mieszankę herbatnikową, tworząc równą warstwę. Wstaw do lodówki na czas przygotowania masy serowej.\n",
      "\n",
      "2. **Przygotowanie masy serowej:**\n",
      "   - W dużej misce połącz twaróg, serek mascarpone, jajka, cukier i ekstrakt waniliowy. Miksuj do uzyskania gładkiej konsystencji.\n",
      "   - Odsącz tuńczyka i dodaj go do masy serowej. Wymieszaj.\n",
      "   - Ugotowane brokuły podziel na mniejsze różyczki i dodaj do masy. Dodaj również posiekaną cebulę. Dopraw solą i pieprzem do smaku.\n",
      "   - Dokładnie wymieszaj wszystkie składniki.\n",
      "\n",
      "3. **Pieczenie:**\n",
      "   - Wylej masę serową na przygotowany spód z herbatników.\n",
      "   - Piecz w piekarniku nagrzanym do 180°C przez około 45-50 minut, aż sernik się zetnie i lekko zrumieni.\n",
      "   - Po upieczeniu wyłącz piekarnik i pozostaw sernik w środku na kolejne 30 minut, aby stopniowo ostygł.\n",
      "\n",
      "4. **Przygotowanie wierzchu:**\n",
      "   - Ubij śmietanę kremówkę z cukrem pudrem na sztywno.\n",
      "   - Po ostudzeniu sernika, nałóż ubitą śmietanę na wierzch.\n",
      "\n",
      "5. **Podanie:**\n",
      "   - Przed podaniem schłodź sernik w lodówce przez co najmniej 2 godziny.\n",
      "   - Udekoruj świeżą bazylią lub natką pietruszki.\n",
      "\n",
      "### Smacznego!\n",
      "Ten nietypowy sernik z tuńczykiem, brokułem i cebulą z pewnością zaskoczy Twoich gości!\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(\"Wygeneruj przepis na słodki sernik z tuńczykiem, brokułem i cebulą.\")\n",
    "\n",
    "print(\"Odpowiedź modelu:\\n\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ee48d932b337f",
   "metadata": {},
   "source": [
    "### Klasyfikacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29165f1f81b5a7b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T19:25:35.057451Z",
     "start_time": "2025-10-02T19:25:30.278624Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The government announced new tax reforms today.\n",
      "Politics\n",
      "The local team won the championship in a thrilling match.\n",
      "Sport\n",
      "New advancements in AI are reshaping the tech industry.\n",
      "Technology\n",
      "The art exhibit showcased contemporary works by emerging artists.\n",
      "Culture\n",
      "New guidelines for a healthy diet were published by the health department.\n",
      "Health\n"
     ]
    }
   ],
   "source": [
    "articles = [\n",
    "    \"The government announced new tax reforms today.\",\n",
    "    \"The local team won the championship in a thrilling match.\",\n",
    "    \"New advancements in AI are reshaping the tech industry.\",\n",
    "    \"The art exhibit showcased contemporary works by emerging artists.\",\n",
    "    \"New guidelines for a healthy diet were published by the health department.\"\n",
    "]\n",
    "for subject in articles:\n",
    "    response = llm.invoke(\"Classify texts into groups Politics, Sport, Technology, Culture, Health. Return only single word with category.\"\n",
    "    f\"Text: {subject}\")\n",
    "\n",
    "    print(subject)\n",
    "    print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b544986e777e52a",
   "metadata": {},
   "source": [
    "### Analiza sentymentu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4bc685457491afc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T19:26:29.241990Z",
     "start_time": "2025-10-02T19:26:26.948077Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odpowiedź modelu:\n",
      "\n",
      "positiv\n",
      "Odpowiedź modelu:\n",
      "\n",
      "negativ\n",
      "Odpowiedź modelu:\n",
      "\n",
      "neutral\n"
     ]
    }
   ],
   "source": [
    "# Przykładowe recenzje\n",
    "reviews = [\n",
    "    \"This product is amazing! I loved it.\",\n",
    "    \"I am very disappointed. The product broke after one use.\",\n",
    "    \"It's okay, does the job but nothing special.\"\n",
    "]\n",
    "for review in reviews:\n",
    "    response = llm.invoke(f\"Oceń sentyment recenzji. Zwróć tylko jedno słowo (positiv, negativ, neutral): {review}\")\n",
    "\n",
    "    print(\"Odpowiedź modelu:\\n\")\n",
    "    print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe6391cfa987531",
   "metadata": {},
   "source": [
    "### Analiza dokumentu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ecaf0f4709cf23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T19:27:51.749776Z",
     "start_time": "2025-10-02T19:27:35.887244Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odpowiedź modelu:\n",
      "\n",
      "W analizowanym dokumencie znajdują się następujące informacje dotyczące rocznego przychodu firmy:\n",
      "\n",
      "1. **Umsatzerlöse (Przychody ze sprzedaży)**:\n",
      "   - W 2019 roku wyniosły **55.680 milionów EUR**.\n",
      "   - W 2018 roku wyniosły **59.248 milionów EUR**.\n",
      "   - Zmiana w przychodach w 2019 roku w porównaniu do 2018 roku wyniosła **-6,0%**.\n",
      "\n",
      "2. **Operatives Ergebnis (Wynik operacyjny)**:\n",
      "   - W 2019 roku wyniósł **4.509 milionów EUR**.\n",
      "   - W 2018 roku wyniósł **3.529 milionów EUR**.\n",
      "   - Zmiana w wyniku operacyjnym w 2019 roku w porównaniu do 2018 roku wyniosła **27,8%**.\n",
      "\n",
      "3. **Ergebnis vor Steuern (Wynik przed opodatkowaniem)**:\n",
      "   - W 2019 roku wyniósł **5.223 milionów EUR**.\n",
      "   - W 2018 roku wyniósł **4.361 milionów EUR**.\n",
      "   - Zmiana w wyniku przed opodatkowaniem w 2019 roku w porównaniu do 2018 roku wyniosła **19,8%**.\n",
      "\n",
      "4. **Ergebnis nach Steuern (Wynik po opodatkowaniu)**:\n",
      "   - W 2019 roku wyniósł **3.943 milionów EUR**.\n",
      "   - W 2018 roku wyniósł **3.463 milionów EUR**.\n",
      "   - Zmiana w wyniku po opodatkowaniu w 2019 roku w porównaniu do 2018 roku wyniosła **13,9%**.\n",
      "\n",
      "Podsumowując, przychody firmy w 2019 roku spadły w porównaniu do roku 2018, podczas gdy wyniki operacyjne oraz wyniki przed i po opodatkowaniu wzrosły.\n"
     ]
    }
   ],
   "source": [
    "file = open(\"../../data/annual_report.html\", \"r\")\n",
    "document = file.read()\n",
    "response = llm.invoke(f\"Przeanalizuj załączony dokument i znajdź informacje na temat rocznego przychodu firmy. {document}\")\n",
    "print(\"Odpowiedź modelu:\\n\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80dd7cc21e40740",
   "metadata": {},
   "source": [
    "### Tłumaczenia maszynowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "817c691daa758421",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T19:28:39.172592Z",
     "start_time": "2025-10-02T19:28:37.634989Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odpowiedź modelu:\n",
      "\n",
      "Jestem obcokrajowcem i nie mówię płynnie po niemiecku.\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(\"Przetłumacz poniższy tekst na język polski:\\n I'm foreigner and I don't speak german fluently.\")\n",
    "\n",
    "print(\"Odpowiedź modelu:\\n\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c5e19db3285a8a",
   "metadata": {},
   "source": [
    "### Question answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "189b2679404bf9c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T07:08:14.121908Z",
     "start_time": "2025-09-15T07:08:12.283819Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odpowiedź modelu:\n",
      "\n",
      "Chains w LangChain służą do tworzenia przepływów danych pomiędzy promptami, modelami i parserami. Umożliwiają one zorganizowanie i zarządzanie interakcjami pomiędzy różnymi komponentami w procesie przetwarzania języka naturalnego.\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(\"Odpowiedz na poniżesze pytania w oparciu o załączony tekst:\\n\"\n",
    "\"LangChain to framework do pracy z dużymi modelami językowymi.\\n\"\n",
    "\"Chains w LangChain to przepływy danych pomiędzy promptami, modelami i parserami.\\n\"\n",
    "\"Retriever pozwala wyszukiwać informacje w bazie wektorowej.\\n\"\n",
    "\"Pytanie: Do czego służą Chains w LangChain?\")\n",
    "\n",
    "print(\"Odpowiedź modelu:\\n\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c12729c6b0a3c77",
   "metadata": {},
   "source": [
    "### Sumaryzacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82e5c070f2c9b660",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T07:05:46.825083Z",
     "start_time": "2025-09-15T07:05:26.114512Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odpowiedź modelu:\n",
      "\n",
      "„Nad Niemnem” Elizy Orzeszkowej to powieść, która wprowadza czytelnika w malowniczy świat letniego dnia, pełnego radości i harmonii z naturą. Opis pierwszego rozdziału ukazuje idylliczny krajobraz, w którym wszystko tętni życiem. Słońce świeci na błękitnym niebie, a przyroda emanuje kolorami i zapachami. W powietrzu unosi się radość, a dźwięki ptaków i owadów tworzą symfonię letniego dnia.\n",
      "\n",
      "W tle tego pięknego pejzażu wznoszą się niewielkie wzgórza, porośnięte lasami, które kontrastują z wysokim brzegiem rzeki Niemen. Opisany krajobraz jest pełen detali, takich jak dzikie grusze, krzywe wierzby i słupiaste topole, które dodają mu charakteru. Orzeszkowa maluje obraz ziemi, gdzie natura i człowiek współistnieją w harmonii. Dwór oraz szereg mniejszych dworków, które pojawiają się w opisie, tworzą obraz społeczności wiejskiej, w której życie toczy się w rytmie natury.\n",
      "\n",
      "W powieści można dostrzec nie tylko piękno przyrody, ale także życie codzienne mieszkańców. Drogi, które przerzynają równinę, są świadectwem ludzkiej obecności i działalności. Miedze, porośnięte kwiatami, przyciągają uwagę, a ich kolorystyka wprowadza dodatkowy element radości do opisanego krajobrazu. Orzeszkowa w sposób mistrzowski łączy opisy przyrody z życiem ludzi, co sprawia, że czytelnik może poczuć się częścią tej idyllicznej scenerii.\n",
      "\n",
      "Powieść „Nad Niemnem” jest nie tylko opisem piękna natury, ale także refleksją nad życiem, relacjami międzyludzkimi oraz wartościami, które kształtują społeczność. Orzeszkowa, poprzez swoje opisy, ukazuje, jak bliskość natury wpływa na życie ludzi, ich codzienne zmagania oraz radości. W ten sposób powieść staje się nie tylko literackim dziełem, ale także głęboką analizą życia w zgodzie z otaczającym światem.\n",
      "\n",
      "Warto zauważyć, że Orzeszkowa nie tylko maluje piękne obrazy, ale także wprowadza do swojej narracji elementy refleksji nad losem jednostki w społeczeństwie. W opisie dworków i ich mieszkańców można dostrzec różnorodność postaw i charakterów, co zapowiada dalszy rozwój fabuły i zawirowania, które będą miały miejsce w życiu bohaterów.\n",
      "\n",
      "Podsumowując, pierwszy rozdział „Nad Niemnem” to wprowadzenie do świata, w którym natura i człowiek współistnieją w harmonii. Orzeszkowa z niezwykłą wrażliwością opisuje piękno otaczającego świata, jednocześnie zapowiadając głębsze refleksje nad życiem i relacjami międzyludzkimi. To dzieło, które zachwyca nie tylko literackim kunsztem, ale także głębią myśli i emocji, które towarzyszą bohaterom w ich codziennym życiu.\n"
     ]
    }
   ],
   "source": [
    "file = open(\"../../data/nad_niemnem.txt\", \"r\")\n",
    "document = file.read()\n",
    "response = llm.invoke(f\"Napisz krótkie podsumowanie (ok. 500 słów) załączonego tekstu.\\n{document[:1800]}\")\n",
    "\n",
    "print(\"Odpowiedź modelu:\\n\")\n",
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
