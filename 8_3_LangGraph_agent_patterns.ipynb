{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02846c5e",
   "metadata": {},
   "source": "## Typy agentóþw w LangGraph – ReAct, Chain‑of‑Thought, Custom"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Instalacja bibliotek",
   "id": "971acb42af2cb236"
  },
  {
   "cell_type": "code",
   "id": "77f9b81c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T06:15:27.072903Z",
     "start_time": "2025-09-17T06:15:23.520021Z"
    }
   },
   "source": "%pip install -U langgraph langchain langchain-openai",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph in /home/michal/anaconda3/lib/python3.13/site-packages (1.0.0a1)\r\n",
      "Requirement already satisfied: langchain in /home/michal/anaconda3/lib/python3.13/site-packages (1.0.0a3)\r\n",
      "Requirement already satisfied: langchain-openai in /home/michal/anaconda3/lib/python3.13/site-packages (0.3.32)\r\n",
      "Collecting langchain-openai\r\n",
      "  Downloading langchain_openai-0.3.33-py3-none-any.whl.metadata (2.4 kB)\r\n",
      "Requirement already satisfied: langchain-core>=0.1 in /home/michal/anaconda3/lib/python3.13/site-packages (from langgraph) (0.3.75)\r\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langgraph) (2.1.1)\r\n",
      "Requirement already satisfied: langgraph-prebuilt==0.7.0a1 in /home/michal/anaconda3/lib/python3.13/site-packages (from langgraph) (0.7.0a1)\r\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /home/michal/anaconda3/lib/python3.13/site-packages (from langgraph) (0.2.4)\r\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /home/michal/anaconda3/lib/python3.13/site-packages (from langgraph) (2.11.7)\r\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langgraph) (3.5.0)\r\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph) (1.10.0)\r\n",
      "Requirement already satisfied: httpx>=0.25.2 in /home/michal/.local/lib/python3.13/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\r\n",
      "Requirement already satisfied: orjson>=3.10.1 in /home/michal/anaconda3/lib/python3.13/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.10.14)\r\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.11 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain) (0.3.11)\r\n",
      "Requirement already satisfied: langsmith>=0.3.45 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core>=0.1->langgraph) (0.4.19)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core>=0.1->langgraph) (9.0.0)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core>=0.1->langgraph) (1.33)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core>=0.1->langgraph) (6.0.2)\r\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core>=0.1->langgraph) (4.15.0)\r\n",
      "Requirement already satisfied: packaging>=23.2 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core>=0.1->langgraph) (24.2)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/michal/anaconda3/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\r\n",
      "Collecting langchain-core>=0.1 (from langgraph)\r\n",
      "  Using cached langchain_core-0.3.76-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "Collecting openai<2.0.0,>=1.104.2 (from langchain-openai)\r\n",
      "  Downloading openai-1.107.3-py3-none-any.whl.metadata (29 kB)\r\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-openai) (0.11.0)\r\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/michal/.local/lib/python3.13/site-packages (from openai<2.0.0,>=1.104.2->langchain-openai) (4.10.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from openai<2.0.0,>=1.104.2->langchain-openai) (1.9.0)\r\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from openai<2.0.0,>=1.104.2->langchain-openai) (0.10.0)\r\n",
      "Requirement already satisfied: sniffio in /home/michal/.local/lib/python3.13/site-packages (from openai<2.0.0,>=1.104.2->langchain-openai) (1.3.1)\r\n",
      "Requirement already satisfied: tqdm>4 in /home/michal/anaconda3/lib/python3.13/site-packages (from openai<2.0.0,>=1.104.2->langchain-openai) (4.67.1)\r\n",
      "Requirement already satisfied: idna>=2.8 in /home/michal/anaconda3/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.104.2->langchain-openai) (3.7)\r\n",
      "Requirement already satisfied: certifi in /home/michal/anaconda3/lib/python3.13/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.8.3)\r\n",
      "Requirement already satisfied: httpcore==1.* in /home/michal/.local/lib/python3.13/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\r\n",
      "Requirement already satisfied: h11>=0.16 in /home/michal/.local/lib/python3.13/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from pydantic>=2.7.4->langgraph) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/michal/anaconda3/lib/python3.13/site-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from pydantic>=2.7.4->langgraph) (0.4.0)\r\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/michal/anaconda3/lib/python3.13/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\r\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.5)\r\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\r\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (0.23.0)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/michal/anaconda3/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.3.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/michal/anaconda3/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.5.0)\r\n",
      "Downloading langchain_openai-0.3.33-py3-none-any.whl (74 kB)\r\n",
      "Using cached langchain_core-0.3.76-py3-none-any.whl (447 kB)\r\n",
      "Downloading openai-1.107.3-py3-none-any.whl (947 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m947.6/947.6 kB\u001B[0m \u001B[31m10.0 MB/s\u001B[0m  \u001B[33m0:00:00\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: openai, langchain-core, langchain-openai\r\n",
      "\u001B[2K  Attempting uninstall: openai\r\n",
      "\u001B[2K    Found existing installation: openai 1.102.0\r\n",
      "\u001B[2K    Uninstalling openai-1.102.0:\r\n",
      "\u001B[2K      Successfully uninstalled openai-1.102.0\r\n",
      "\u001B[2K  Attempting uninstall: langchain-core━━━━━━━━━━\u001B[0m \u001B[32m0/3\u001B[0m [openai]\r\n",
      "\u001B[2K    Found existing installation: langchain-core 0.3.750/3\u001B[0m [openai]\r\n",
      "\u001B[2K    Uninstalling langchain-core-0.3.75:━━━━━\u001B[0m \u001B[32m0/3\u001B[0m [openai]\r\n",
      "\u001B[2K      Successfully uninstalled langchain-core-0.3.752m0/3\u001B[0m [openai]\r\n",
      "\u001B[2K  Attempting uninstall: langchain-openai━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1/3\u001B[0m [langchain-core]\r\n",
      "\u001B[2K    Found existing installation: langchain-openai 0.3.32━━━━━━\u001B[0m \u001B[32m1/3\u001B[0m [langchain-core]\r\n",
      "\u001B[2K    Uninstalling langchain-openai-0.3.32:━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1/3\u001B[0m [langchain-core]\r\n",
      "\u001B[2K      Successfully uninstalled langchain-openai-0.3.32━━━━━━━━\u001B[0m \u001B[32m1/3\u001B[0m [langchain-core]\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3/3\u001B[0m [langchain-openai]gchain-core]\r\n",
      "\u001B[1A\u001B[2KSuccessfully installed langchain-core-0.3.76 langchain-openai-0.3.33 openai-1.107.3\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "4f251900",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T06:15:31.468518Z",
     "start_time": "2025-09-17T06:15:27.084458Z"
    }
   },
   "source": [
    "\n",
    "# Imports & config\n",
    "import os\n",
    "import operator\n",
    "from typing import Annotated, List, TypedDict, Literal\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# You can override via environment: export OPENAI_MODEL=\"gpt-4o-mini\" (or a reasoning model)\n",
    "MODEL = os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\")\n",
    "llm = ChatOpenAI(model=MODEL, temperature=0)\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "6c4eba90",
   "metadata": {},
   "source": [
    "### ReAct Agent\n",
    "ReAct Agent łączy rozumowanie krok po kroku z wykonywaniem akcji poprzez narzędzia, np. kalkulator czy wyszukiwarkę; świetny do dynamicznych problemów wymagających integracji z zewnętrznymi funkcjami."
   ]
  },
  {
   "cell_type": "code",
   "id": "e9a470d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T06:15:40.831447Z",
     "start_time": "2025-09-17T06:15:31.544207Z"
    }
   },
   "source": [
    "\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "@tool\n",
    "def calculator(expr: str) -> str:\n",
    "    \"\"\"Safely evaluate a basic arithmetic expression (digits and + - * / ( ) .).\"\"\"\n",
    "    import math\n",
    "    allowed = set(\"0123456789+-*/(). \")\n",
    "    if any(c not in allowed for c in expr):\n",
    "        raise ValueError(\"Only basic arithmetic characters are allowed.\")\n",
    "    # Provide a tiny globals dict (no builtins), and a math namespace with sqrt, etc.\n",
    "    return str(eval(expr, {\"__builtins__\": {}}, {\"sqrt\": math.sqrt}))  # type: ignore[name-defined]\n",
    "\n",
    "@tool\n",
    "def lookup_country_capital(country: str) -> str:\n",
    "    \"\"\"Return a country's capital using a tiny built-in table.\"\"\"\n",
    "    capitals = {\n",
    "        \"poland\": \"Warsaw\",\n",
    "        \"germany\": \"Berlin\",\n",
    "        \"france\": \"Paris\",\n",
    "        \"spain\": \"Madrid\",\n",
    "        \"italy\": \"Rome\",\n",
    "    }\n",
    "    return capitals.get(country.strip().lower(), \"Unknown\")\n",
    "\n",
    "tools = [calculator, lookup_country_capital]\n",
    "\n",
    "react_agent = create_react_agent(llm, tools)\n",
    "\n",
    "# Try it!\n",
    "prompt = (\n",
    "    \"Compute sqrt(144) with the calculator, then add the number of letters in the capital of Germany. \"\n",
    "    \"Return only the final integer result.\"\n",
    ")\n",
    "\n",
    "result = react_agent.invoke({ \"messages\": [(\"user\", prompt)] })\n",
    "print(result[\"messages\"][-1].content)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14219/51448629.py:27: LangGraphDeprecatedSinceV10: create_react_agent has been moved to langchain.agents. Please update your import to 'from langchain.agents import create_react_agent'. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
      "  react_agent = create_react_agent(llm, tools)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final integer result is 18.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "10198139",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T06:15:44.716748Z",
     "start_time": "2025-09-17T06:15:40.897536Z"
    }
   },
   "source": [
    "\n",
    "# (Optional) Streaming view – see intermediate steps as the agent reasons and calls tools\n",
    "for event in react_agent.stream({ \"messages\": [(\"user\", \"What is 5*7 + sqrt(81)? Return only a number.\")] }, stream_mode=\"values\"):\n",
    "    last = event[\"messages\"][-1]\n",
    "    role = getattr(last, \"type\", \"assistant\")\n",
    "    print(f\"[{role}] {last.content}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[human] What is 5*7 + sqrt(81)? Return only a number.\n",
      "[ai] \n",
      "[tool] Error: ValueError('Only basic arithmetic characters are allowed.')\n",
      " Please fix your mistakes.\n",
      "[ai] \n",
      "[tool] 44\n",
      "[ai] The result is 44.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "8b1b1578",
   "metadata": {},
   "source": [
    "### Chain‑of‑Thought\n",
    "Chain-of-Thought Agent prowadzi wewnętrzne rozumowanie w kilku krokach (tzw. scratchpad), ale nie używa narzędzi; stosowany tam, gdzie wystarczy czysta analiza i dedukcja."
   ]
  },
  {
   "cell_type": "code",
   "id": "b5bfcd8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T06:15:44.786423Z",
     "start_time": "2025-09-17T06:15:44.773946Z"
    }
   },
   "source": [
    "\n",
    "class CoTState(TypedDict):\n",
    "    question: str\n",
    "    # Accumulate steps across nodes if desired\n",
    "    steps: Annotated[List[str], operator.add]\n",
    "    answer: str\n",
    "\n",
    "def plan_node(state: CoTState) -> dict:\n",
    "    \"\"\"Ask the LLM to propose a compact plan (steps) without solving yet.\"\"\"\n",
    "    sys = (\n",
    "        \"You are a careful planner. Break the user's question into 2-4 concise steps. \"\n",
    "        \"Do not solve. Return only a numbered list of steps; no extra text.\"\n",
    "    )\n",
    "    messages = [(\"system\", sys), (\"user\", state[\"question\"])]\n",
    "    resp = llm.invoke(messages)\n",
    "    # Normalize into a list of strings (one per step)\n",
    "    raw = resp.content\n",
    "    steps = []\n",
    "    for line in str(raw).splitlines():\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        # strip possible numbering like \"1. \", \"- \", etc.\n",
    "        line = line.lstrip(\"-• \").split(\". \", 1)[-1] if \". \" in line[:4] else line.lstrip(\"-• \")\n",
    "        steps.append(line)\n",
    "    return {\"steps\": steps}\n",
    "\n",
    "def solve_node(state: CoTState) -> dict:\n",
    "    \"\"\"Use the planned steps to derive the final answer only.\"\"\"\n",
    "    sys = (\n",
    "        \"Use the provided steps to solve the problem. \"\n",
    "        \"Return only the final answer, no reasoning.\"\n",
    "    )\n",
    "    messages = [\n",
    "        (\"system\", sys),\n",
    "        (\"user\", f\"Question: {state['question']}\\nSteps: {state['steps']}\"),\n",
    "    ]\n",
    "    resp = llm.invoke(messages)\n",
    "    return {\"answer\": str(resp.content).strip()}\n",
    "\n",
    "# Wire up the graph\n",
    "graph = StateGraph(CoTState)\n",
    "graph.add_node(\"plan\", plan_node)\n",
    "graph.add_node(\"solve\", solve_node)\n",
    "graph.add_edge(START, \"plan\")\n",
    "graph.add_edge(\"plan\", \"solve\")\n",
    "graph.add_edge(\"solve\", END)\n",
    "cot_graph = graph.compile()\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "90243e2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T06:15:47.394677Z",
     "start_time": "2025-09-17T06:15:44.840452Z"
    }
   },
   "source": [
    "# Run the CoT graph\n",
    "state = {\n",
    "    \"question\": \"If a book has 350 pages and I read 14 pages per day, how many days to finish?\",\n",
    "    \"steps\": [],\n",
    "    \"answer\": \"\"\n",
    "}\n",
    "out = cot_graph.invoke(state)\n",
    "print(\"Final answer:\", out[\"answer\"])\n",
    "\n",
    "# If you're teaching and want to peek at the internal scratchpad (not for end users):\n",
    "# print(\"Planned steps:\", out[\"steps\"])\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final answer: 25 days\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "bec1a754",
   "metadata": {},
   "source": [
    "### Custom Agent\n",
    "Custom Agent daje pełną elstyczność, można samemu zdefiniować logikę, routing i węzły; używany, gdy żaden gotowy wzorzec nie pasuje do specyfiki zadania."
   ]
  },
  {
   "cell_type": "code",
   "id": "c7cbc302",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T06:15:47.468585Z",
     "start_time": "2025-09-17T06:15:47.454550Z"
    }
   },
   "source": [
    "\n",
    "class CustomState(TypedDict):\n",
    "    input: str\n",
    "    task: Literal[\"math\", \"capitalize\", \"count\"]\n",
    "    result: str\n",
    "\n",
    "def route(state: CustomState) -> str:\n",
    "    \"\"\"Deterministic router based on a simple protocol in the input.\"\"\"\n",
    "    text = state[\"input\"].strip().lower()\n",
    "    if text.startswith(\"math:\"):\n",
    "        return \"math\"\n",
    "    if text.startswith(\"capitalize:\"):\n",
    "        return \"capitalize\"\n",
    "    if text.startswith(\"count:\"):\n",
    "        return \"count\"\n",
    "    # default fallback\n",
    "    return \"count\"\n",
    "\n",
    "def do_math(state: CustomState) -> dict:\n",
    "    expr = state[\"input\"].split(\":\", 1)[-1].strip()\n",
    "    allowed = set(\"0123456789+-*/(). \")\n",
    "    if any(c not in allowed for c in expr):\n",
    "        return {\"result\": \"Error: unsupported characters in math expression.\"}\n",
    "    try:\n",
    "        res = eval(expr, {\"__builtins__\": {}})\n",
    "    except Exception as e:\n",
    "        res = f\"Error: {e}\"\n",
    "    return {\"result\": str(res)}\n",
    "\n",
    "def do_capitalize(state: CustomState) -> dict:\n",
    "    text = state[\"input\"].split(\":\", 1)[-1].strip()\n",
    "    return {\"result\": text.upper()}\n",
    "\n",
    "def do_count(state: CustomState) -> dict:\n",
    "    text = state[\"input\"].split(\":\", 1)[-1].strip()\n",
    "    tokens = [t for t in text.split() if t]\n",
    "    return {\"result\": f\"words={len(tokens)} chars={len(text)}\"}\n",
    "\n",
    "g = StateGraph(CustomState)\n",
    "g.add_node(\"math\", do_math)\n",
    "g.add_node(\"capitalize\", do_capitalize)\n",
    "g.add_node(\"count\", do_count)\n",
    "\n",
    "# Conditional edges from router\n",
    "g.add_conditional_edges(\n",
    "    START,\n",
    "    route,\n",
    "    {\n",
    "        \"math\": \"math\",\n",
    "        \"capitalize\": \"capitalize\",\n",
    "        \"count\": \"count\",\n",
    "    },\n",
    ")\n",
    "g.add_edge(\"math\", END)\n",
    "g.add_edge(\"capitalize\", END)\n",
    "g.add_edge(\"count\", END)\n",
    "\n",
    "custom_agent = g.compile()\n"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "279f8804",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T06:15:47.534478Z",
     "start_time": "2025-09-17T06:15:47.520323Z"
    }
   },
   "source": [
    "\n",
    "# Try several inputs\n",
    "for user_input in [\n",
    "    \"math: (12 + 8) * 3\",\n",
    "    \"capitalize: langgraph is great!\",\n",
    "    \"count: How many words are here?\",\n",
    "]:\n",
    "    out = custom_agent.invoke({\"input\": user_input, \"task\": \"count\", \"result\": \"\"})\n",
    "    print(f\"Input: {user_input}\\nResult: {out['result']}\\n---\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: math: (12 + 8) * 3\n",
      "Result: 60\n",
      "---\n",
      "Input: capitalize: langgraph is great!\n",
      "Result: LANGGRAPH IS GREAT!\n",
      "---\n",
      "Input: count: How many words are here?\n",
      "Result: words=5 chars=24\n",
      "---\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
