{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02846c5e",
   "metadata": {},
   "source": "## Architektury agentów"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Instalacja bibliotek",
   "id": "971acb42af2cb236"
  },
  {
   "cell_type": "code",
   "id": "77f9b81c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T18:10:52.041700Z",
     "start_time": "2025-10-19T18:10:49.212732Z"
    }
   },
   "source": "%pip install -U langgraph langchain langchain-openai",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph in /home/michal/anaconda3/lib/python3.13/site-packages (0.6.10)\r\n",
      "Collecting langgraph\r\n",
      "  Using cached langgraph-1.0.0-py3-none-any.whl.metadata (7.4 kB)\r\n",
      "Requirement already satisfied: langchain in /home/michal/anaconda3/lib/python3.13/site-packages (0.3.27)\r\n",
      "Collecting langchain\r\n",
      "  Using cached langchain-1.0.0-py3-none-any.whl.metadata (4.6 kB)\r\n",
      "Requirement already satisfied: langchain-openai in /home/michal/anaconda3/lib/python3.13/site-packages (0.3.35)\r\n",
      "Collecting langchain-openai\r\n",
      "  Using cached langchain_openai-1.0.0-py3-none-any.whl.metadata (1.8 kB)\r\n",
      "Requirement already satisfied: langchain-core>=0.1 in /home/michal/anaconda3/lib/python3.13/site-packages (from langgraph) (0.3.79)\r\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langgraph) (2.1.1)\r\n",
      "Collecting langgraph-prebuilt<1.1.0,>=1.0.0 (from langgraph)\r\n",
      "  Using cached langgraph_prebuilt-1.0.0-py3-none-any.whl.metadata (5.0 kB)\r\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /home/michal/anaconda3/lib/python3.13/site-packages (from langgraph) (0.2.4)\r\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /home/michal/anaconda3/lib/python3.13/site-packages (from langgraph) (2.11.7)\r\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langgraph) (3.5.0)\r\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph) (1.10.0)\r\n",
      "Requirement already satisfied: httpx>=0.25.2 in /home/michal/.local/lib/python3.13/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\r\n",
      "Requirement already satisfied: orjson>=3.10.1 in /home/michal/anaconda3/lib/python3.13/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.10.14)\r\n",
      "Collecting langchain-core>=0.1 (from langgraph)\r\n",
      "  Using cached langchain_core-1.0.0-py3-none-any.whl.metadata (3.4 kB)\r\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core>=0.1->langgraph) (1.33)\r\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core>=0.1->langgraph) (0.4.30)\r\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core>=0.1->langgraph) (24.2)\r\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core>=0.1->langgraph) (6.0.2)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core>=0.1->langgraph) (9.0.0)\r\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-core>=0.1->langgraph) (4.15.0)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/michal/anaconda3/lib/python3.13/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph) (3.0.0)\r\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\r\n",
      "Requirement already satisfied: requests>=2.0.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.32.5)\r\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (0.23.0)\r\n",
      "Requirement already satisfied: anyio in /home/michal/.local/lib/python3.13/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.10.0)\r\n",
      "Requirement already satisfied: certifi in /home/michal/anaconda3/lib/python3.13/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.8.3)\r\n",
      "Requirement already satisfied: httpcore==1.* in /home/michal/.local/lib/python3.13/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\r\n",
      "Requirement already satisfied: idna in /home/michal/anaconda3/lib/python3.13/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.7)\r\n",
      "Requirement already satisfied: h11>=0.16 in /home/michal/.local/lib/python3.13/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from pydantic>=2.7.4->langgraph) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/michal/anaconda3/lib/python3.13/site-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from pydantic>=2.7.4->langgraph) (0.4.0)\r\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-openai) (2.5.0)\r\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from langchain-openai) (0.11.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\r\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /home/michal/anaconda3/lib/python3.13/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.10.0)\r\n",
      "Requirement already satisfied: sniffio in /home/michal/.local/lib/python3.13/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\r\n",
      "Requirement already satisfied: tqdm>4 in /home/michal/anaconda3/lib/python3.13/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\r\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/michal/anaconda3/lib/python3.13/site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.11.6)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/michal/anaconda3/lib/python3.13/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (3.3.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/michal/anaconda3/lib/python3.13/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\r\n",
      "Using cached langgraph-1.0.0-py3-none-any.whl (155 kB)\r\n",
      "Using cached langgraph_prebuilt-1.0.0-py3-none-any.whl (28 kB)\r\n",
      "Using cached langchain-1.0.0-py3-none-any.whl (106 kB)\r\n",
      "Using cached langchain_core-1.0.0-py3-none-any.whl (467 kB)\r\n",
      "Using cached langchain_openai-1.0.0-py3-none-any.whl (80 kB)\r\n",
      "Installing collected packages: langchain-core, langchain-openai, langgraph-prebuilt, langgraph, langchain\r\n",
      "\u001B[2K  Attempting uninstall: langchain-core\r\n",
      "\u001B[2K    Found existing installation: langchain-core 0.3.79\r\n",
      "\u001B[2K    Uninstalling langchain-core-0.3.79:\r\n",
      "\u001B[2K      Successfully uninstalled langchain-core-0.3.79\r\n",
      "\u001B[2K  Attempting uninstall: langchain-openai━━━━━━━━\u001B[0m \u001B[32m0/5\u001B[0m [langchain-core]\r\n",
      "\u001B[2K    Found existing installation: langchain-openai 0.3.355\u001B[0m [langchain-core]\r\n",
      "\u001B[2K    Uninstalling langchain-openai-0.3.35:━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1/5\u001B[0m [langchain-openai]\r\n",
      "\u001B[2K      Successfully uninstalled langchain-openai-0.3.35━━━━━━━━\u001B[0m \u001B[32m1/5\u001B[0m [langchain-openai]\r\n",
      "\u001B[2K  Attempting uninstall: langgraph-prebuilt━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1/5\u001B[0m [langchain-openai]\r\n",
      "\u001B[2K    Found existing installation: langgraph-prebuilt 0.6.4━━━━━\u001B[0m \u001B[32m1/5\u001B[0m [langchain-openai]\r\n",
      "\u001B[2K    Uninstalling langgraph-prebuilt-0.6.4:━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1/5\u001B[0m [langchain-openai]\r\n",
      "\u001B[2K      Successfully uninstalled langgraph-prebuilt-0.6.4━━━━━━━\u001B[0m \u001B[32m1/5\u001B[0m [langchain-openai]\r\n",
      "\u001B[2K  Attempting uninstall: langgraph━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1/5\u001B[0m [langchain-openai]\r\n",
      "\u001B[2K    Found existing installation: langgraph 0.6.10━━━━━━━━━━━━━\u001B[0m \u001B[32m1/5\u001B[0m [langchain-openai]\r\n",
      "\u001B[2K    Uninstalling langgraph-0.6.10:━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1/5\u001B[0m [langchain-openai]\r\n",
      "\u001B[2K      Successfully uninstalled langgraph-0.6.10━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1/5\u001B[0m [langchain-openai]\r\n",
      "\u001B[2K  Attempting uninstall: langchain[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3/5\u001B[0m [langgraph]ai]\r\n",
      "\u001B[2K    Found existing installation: langchain 0.3.27━━━━━━━━━━━━━\u001B[0m \u001B[32m3/5\u001B[0m [langgraph]\r\n",
      "\u001B[2K    Uninstalling langchain-0.3.27:━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━\u001B[0m \u001B[32m4/5\u001B[0m [langchain]\r\n",
      "\u001B[2K      Successfully uninstalled langchain-0.3.27[0m\u001B[90m━━━━━━━\u001B[0m \u001B[32m4/5\u001B[0m [langchain]\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m5/5\u001B[0m [langchain]0m [langchain]\r\n",
      "\u001B[1A\u001B[2K\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "langgraph-supervisor 0.0.29 requires langgraph<0.7.0,>=0.6.0, but you have langgraph 1.0.0 which is incompatible.\u001B[0m\u001B[31m\r\n",
      "\u001B[0mSuccessfully installed langchain-1.0.0 langchain-core-1.0.0 langchain-openai-1.0.0 langgraph-1.0.0 langgraph-prebuilt-1.0.0\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Import bibliotek i konfiguracja",
   "id": "6cffa241fe838685"
  },
  {
   "cell_type": "code",
   "id": "4f251900",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T18:29:13.779836Z",
     "start_time": "2025-10-19T18:29:13.771544Z"
    }
   },
   "source": [
    "import operator\n",
    "from typing import Annotated, List, TypedDict, Literal\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "id": "8b1b1578",
   "metadata": {},
   "source": [
    "### Sequential Agent\n",
    "Sequential Agent prowadzi wewnętrzne rozumowanie w kilku krokach (tzw. scratchpad), ale nie używa narzędzi; stosowany tam, gdzie wystarczy czysta analiza i dedukcja."
   ]
  },
  {
   "cell_type": "code",
   "id": "b5bfcd8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T18:30:21.627795Z",
     "start_time": "2025-10-19T18:30:21.618739Z"
    }
   },
   "source": [
    "class State(TypedDict):\n",
    "    question: str\n",
    "    steps: Annotated[List[str], operator.add]\n",
    "    answer: str\n",
    "\n",
    "def plan_node(state: State) -> dict:\n",
    "    sys = (\n",
    "        \"You are a careful planner. Break the user's question into 2-4 concise steps. \"\n",
    "        \"Do not solve. Return only a numbered list of steps; no extra text.\"\n",
    "    )\n",
    "    messages = [(\"system\", sys), (\"user\", state[\"question\"])]\n",
    "    resp = llm.invoke(messages)\n",
    "    raw = resp.content\n",
    "    steps = []\n",
    "    for line in str(raw).splitlines():\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        line = line.lstrip(\"-• \").split(\". \", 1)[-1] if \". \" in line[:4] else line.lstrip(\"-• \")\n",
    "        steps.append(line)\n",
    "    return {\"steps\": steps}\n",
    "\n",
    "def solve_node(state: State) -> dict:\n",
    "    \"\"\"Use the planned steps to derive the final answer only.\"\"\"\n",
    "    sys = (\n",
    "        \"Use the provided steps to solve the problem. \"\n",
    "        \"Return only the final answer, no reasoning.\"\n",
    "    )\n",
    "    messages = [\n",
    "        (\"system\", sys),\n",
    "        (\"user\", f\"Question: {state['question']}\\nSteps: {state['steps']}\"),\n",
    "    ]\n",
    "    resp = llm.invoke(messages)\n",
    "    return {\"answer\": str(resp.content).strip()}\n",
    "\n",
    "# Wire up the graph\n",
    "graph = StateGraph(State)\n",
    "graph.add_node(\"plan\", plan_node)\n",
    "graph.add_node(\"solve\", solve_node)\n",
    "\n",
    "graph.add_edge(START, \"plan\")\n",
    "graph.add_edge(\"plan\", \"solve\")\n",
    "graph.add_edge(\"solve\", END)\n",
    "\n",
    "cot_graph = graph.compile()\n"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "90243e2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T18:30:38.628601Z",
     "start_time": "2025-10-19T18:30:36.401003Z"
    }
   },
   "source": [
    "state = {\n",
    "    \"question\": \"If a book has 350 pages and I read 14 pages per day, how many days to finish?\",\n",
    "    \"steps\": [],\n",
    "    \"answer\": \"\"\n",
    "}\n",
    "out = cot_graph.invoke(state)\n",
    "print(\"Final answer:\", out[\"answer\"])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final answer: 25 days\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "id": "bec1a754",
   "metadata": {},
   "source": [
    "### Custom Agent\n",
    "Custom Agent daje pełną elstyczność. Samodzielnie definiujemy logikę, routing i węzły."
   ]
  },
  {
   "cell_type": "code",
   "id": "c7cbc302",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T18:32:41.866468Z",
     "start_time": "2025-10-19T18:32:41.856483Z"
    }
   },
   "source": [
    "class CustomState(TypedDict):\n",
    "    input: str\n",
    "    task: Literal[\"math\", \"capitalize\", \"count\"]\n",
    "    result: str\n",
    "\n",
    "def route(state: CustomState) -> str:\n",
    "    \"\"\"Deterministic router based on a simple protocol in the input.\"\"\"\n",
    "    text = state[\"input\"].strip().lower()\n",
    "    if text.startswith(\"math:\"):\n",
    "        return \"math\"\n",
    "    if text.startswith(\"capitalize:\"):\n",
    "        return \"capitalize\"\n",
    "    if text.startswith(\"count:\"):\n",
    "        return \"count\"\n",
    "    return \"count\"\n",
    "\n",
    "def do_math(state: CustomState) -> dict:\n",
    "    expr = state[\"input\"].split(\":\", 1)[-1].strip()\n",
    "    allowed = set(\"0123456789+-*/(). \")\n",
    "    if any(c not in allowed for c in expr):\n",
    "        return {\"result\": \"Error: unsupported characters in math expression.\"}\n",
    "    try:\n",
    "        res = eval(expr, {\"__builtins__\": {}})\n",
    "    except Exception as e:\n",
    "        res = f\"Error: {e}\"\n",
    "    return {\"result\": str(res)}\n",
    "\n",
    "def do_capitalize(state: CustomState) -> dict:\n",
    "    text = state[\"input\"].split(\":\", 1)[-1].strip()\n",
    "    return {\"result\": text.upper()}\n",
    "\n",
    "def do_count(state: CustomState) -> dict:\n",
    "    text = state[\"input\"].split(\":\", 1)[-1].strip()\n",
    "    tokens = [t for t in text.split() if t]\n",
    "    return {\"result\": f\"words={len(tokens)} chars={len(text)}\"}\n",
    "\n",
    "graph = StateGraph(CustomState)\n",
    "graph.add_node(\"math\", do_math)\n",
    "graph.add_node(\"capitalize\", do_capitalize)\n",
    "graph.add_node(\"count\", do_count)\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    START,\n",
    "    route,\n",
    "    {\n",
    "        \"math\": \"math\",\n",
    "        \"capitalize\": \"capitalize\",\n",
    "        \"count\": \"count\",\n",
    "    },\n",
    ")\n",
    "graph.add_edge(\"math\", END)\n",
    "graph.add_edge(\"capitalize\", END)\n",
    "graph.add_edge(\"count\", END)\n",
    "\n",
    "custom_agent = graph.compile(debug=True)\n"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "279f8804",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T18:32:46.619625Z",
     "start_time": "2025-10-19T18:32:46.610881Z"
    }
   },
   "source": [
    "for user_input in [\n",
    "    \"math: (12 + 8) * 3\",\n",
    "    \"capitalize: langgraph is great!\",\n",
    "    \"count: How many words are here?\",\n",
    "]:\n",
    "    out = custom_agent.invoke({\"input\": user_input, \"task\": \"count\", \"result\": \"\"})\n",
    "    print(f\"Input: {user_input}\\nResult: {out['result']}\\n---\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m[values]\u001B[0m {'input': 'math: (12 + 8) * 3', 'task': 'count', 'result': ''}\n",
      "\u001B[1m[updates]\u001B[0m {'math': {'result': '60'}}\n",
      "\u001B[1m[values]\u001B[0m {'input': 'math: (12 + 8) * 3', 'task': 'count', 'result': '60'}\n",
      "Input: math: (12 + 8) * 3\n",
      "Result: 60\n",
      "---\n",
      "\u001B[1m[values]\u001B[0m {'input': 'capitalize: langgraph is great!', 'task': 'count', 'result': ''}\n",
      "\u001B[1m[updates]\u001B[0m {'capitalize': {'result': 'LANGGRAPH IS GREAT!'}}\n",
      "\u001B[1m[values]\u001B[0m {'input': 'capitalize: langgraph is great!', 'task': 'count', 'result': 'LANGGRAPH IS GREAT!'}\n",
      "Input: capitalize: langgraph is great!\n",
      "Result: LANGGRAPH IS GREAT!\n",
      "---\n",
      "\u001B[1m[values]\u001B[0m {'input': 'count: How many words are here?', 'task': 'count', 'result': ''}\n",
      "\u001B[1m[updates]\u001B[0m {'count': {'result': 'words=5 chars=24'}}\n",
      "\u001B[1m[values]\u001B[0m {'input': 'count: How many words are here?', 'task': 'count', 'result': 'words=5 chars=24'}\n",
      "Input: count: How many words are here?\n",
      "Result: words=5 chars=24\n",
      "---\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Supervisor",
   "id": "83e0ed41aeb9d07e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T18:15:26.635465Z",
     "start_time": "2025-10-19T18:15:13.704763Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SupervisorState(TypedDict):\n",
    "    \"\"\"State for supervisor pattern with multiple agents.\"\"\"\n",
    "    topic: str\n",
    "    messages: Annotated[List[str], operator.add]\n",
    "    next_agent: str\n",
    "    final_answer: str\n",
    "\n",
    "\n",
    "def researcher_agent(state: SupervisorState) -> dict:\n",
    "    \"\"\"Researcher agent gathers information about the topic.\"\"\"\n",
    "    sys = (\n",
    "        \"You are a researcher. Your job is to gather key facts and information \"\n",
    "        \"about the given topic. Provide 2-3 key points. Be concise.\"\n",
    "    )\n",
    "    messages_for_llm = [\n",
    "        (\"system\", sys),\n",
    "        (\"user\", f\"Research this topic: {state['topic']}\")\n",
    "    ]\n",
    "    resp = llm.invoke(messages_for_llm)\n",
    "    research_msg = f\"RESEARCHER: {resp.content}\"\n",
    "    return {\"messages\": [research_msg]}\n",
    "\n",
    "\n",
    "def expert_agent(state: SupervisorState) -> dict:\n",
    "    \"\"\"Expert agent analyzes and provides insights based on research.\"\"\"\n",
    "    sys = (\n",
    "        \"You are an expert analyst. Review the research provided and give \"\n",
    "        \"your expert analysis and conclusions. Be specific and insightful.\"\n",
    "    )\n",
    "    # Get context from previous messages\n",
    "    context = \"\\n\".join(state[\"messages\"])\n",
    "    messages_for_llm = [\n",
    "        (\"system\", sys),\n",
    "        (\"user\", f\"Topic: {state['topic']}\\n\\nPrevious research:\\n{context}\\n\\nProvide your expert analysis.\")\n",
    "    ]\n",
    "    resp = llm.invoke(messages_for_llm)\n",
    "    expert_msg = f\"EXPERT: {resp.content}\"\n",
    "    return {\"messages\": [expert_msg]}\n",
    "\n",
    "\n",
    "def supervisor_agent(state: SupervisorState) -> dict:\n",
    "    \"\"\"Supervisor decides which agent should act next or if discussion should end.\"\"\"\n",
    "    sys = (\n",
    "        \"You are a supervisor managing a research discussion between a RESEARCHER and an EXPERT. \"\n",
    "        \"Based on the conversation so far, decide what should happen next:\\n\"\n",
    "        \"- Return 'researcher' if we need initial research or more information\\n\"\n",
    "        \"- Return 'expert' if research is done and we need expert analysis\\n\"\n",
    "        \"- Return 'end' if both research and expert analysis are complete\\n\\n\"\n",
    "        \"Respond with ONLY one word: researcher, expert, or end\"\n",
    "    )\n",
    "\n",
    "    context = \"\\n\".join(state[\"messages\"]) if state[\"messages\"] else \"No discussion yet\"\n",
    "    messages_for_llm = [\n",
    "        (\"system\", sys),\n",
    "        (\"user\", f\"Topic: {state['topic']}\\n\\nConversation:\\n{context}\\n\\nWhat's next?\")\n",
    "    ]\n",
    "    resp = llm.invoke(messages_for_llm)\n",
    "    next_step = resp.content.strip().lower()\n",
    "\n",
    "    # Ensure valid response\n",
    "    if next_step not in [\"researcher\", \"expert\", \"end\"]:\n",
    "        next_step = \"end\"\n",
    "\n",
    "    return {\"next_agent\": next_step}\n",
    "\n",
    "\n",
    "def finalize_answer(state: SupervisorState) -> dict:\n",
    "    \"\"\"Compile final answer from the discussion.\"\"\"\n",
    "    sys = (\n",
    "        \"Summarize the research discussion into a clear, concise final answer. \"\n",
    "        \"Include key findings and expert insights.\"\n",
    "    )\n",
    "    context = \"\\n\".join(state[\"messages\"])\n",
    "    messages_for_llm = [\n",
    "        (\"system\", sys),\n",
    "        (\"user\", f\"Topic: {state['topic']}\\n\\nDiscussion:\\n{context}\\n\\nProvide final summary:\")\n",
    "    ]\n",
    "    resp = llm.invoke(messages_for_llm)\n",
    "    return {\"final_answer\": resp.content}\n",
    "\n",
    "\n",
    "def route_supervisor(state: SupervisorState) -> str:\n",
    "    \"\"\"Route based on supervisor's decision.\"\"\"\n",
    "    next_agent = state.get(\"next_agent\", \"researcher\")\n",
    "    if next_agent == \"end\":\n",
    "        return \"finalize\"\n",
    "    return next_agent\n",
    "\n",
    "supervisor_graph = StateGraph(SupervisorState)\n",
    "\n",
    "supervisor_graph.add_node(\"supervisor\", supervisor_agent)\n",
    "supervisor_graph.add_node(\"researcher\", researcher_agent)\n",
    "supervisor_graph.add_node(\"expert\", expert_agent)\n",
    "supervisor_graph.add_node(\"finalize\", finalize_answer)\n",
    "\n",
    "supervisor_graph.add_edge(START, \"supervisor\")\n",
    "\n",
    "supervisor_graph.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    route_supervisor,\n",
    "    {\n",
    "        \"researcher\": \"researcher\",\n",
    "        \"expert\": \"expert\",\n",
    "        \"finalize\": \"finalize\"\n",
    "    }\n",
    ")\n",
    "\n",
    "supervisor_graph.add_edge(\"researcher\", \"supervisor\")\n",
    "supervisor_graph.add_edge(\"expert\", \"supervisor\")\n",
    "\n",
    "supervisor_graph.add_edge(\"finalize\", END)\n",
    "\n",
    "supervisor_agent_graph = supervisor_graph.compile()\n",
    "\n",
    "topic = \"What are the main benefits of using LangGraph for building AI agents?\"\n",
    "\n",
    "initial_state = {\n",
    "    \"topic\": topic,\n",
    "    \"messages\": [],\n",
    "    \"next_agent\": \"\",\n",
    "    \"final_answer\": \"\"\n",
    "}\n",
    "\n",
    "result = supervisor_agent_graph.invoke(initial_state)\n",
    "\n",
    "print(f\"TOPIC: {topic}\\n\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nDISCUSSION:\")\n",
    "print(\"-\" * 80)\n",
    "for msg in result[\"messages\"]:\n",
    "    print(f\"\\n{msg}\\n\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nFINAL ANSWER:\\n{result['final_answer']}\")\n"
   ],
   "id": "68458fef5529f946",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOPIC: What are the main benefits of using LangGraph for building AI agents?\n",
      "\n",
      "================================================================================\n",
      "\n",
      "DISCUSSION:\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "RESEARCHER: 1. **Modular Design**: LangGraph offers a modular architecture that allows developers to easily integrate various components and functionalities, facilitating the rapid development and customization of AI agents.\n",
      "\n",
      "2. **Enhanced Natural Language Processing**: It leverages advanced natural language processing capabilities, enabling AI agents to understand and generate human-like responses, improving user interaction and engagement.\n",
      "\n",
      "3. **Scalability and Flexibility**: LangGraph is designed to be scalable, allowing developers to build AI agents that can handle varying workloads and adapt to different use cases, making it suitable for both small projects and large-scale applications.\n",
      "\n",
      "\n",
      "EXPERT: The research highlights several key benefits of using LangGraph for building AI agents, each of which plays a crucial role in the development and deployment of effective AI solutions. Here’s a detailed analysis of the points raised:\n",
      "\n",
      "1. **Modular Design**: The modular architecture of LangGraph is a significant advantage for developers. This design allows for the easy integration of various components, which can lead to faster development cycles. By enabling developers to customize AI agents according to specific needs, LangGraph promotes innovation and experimentation. This flexibility is particularly beneficial in a rapidly evolving field like AI, where requirements can change quickly. Furthermore, a modular approach can facilitate collaboration among teams, as different components can be developed and tested independently before being integrated into a cohesive system.\n",
      "\n",
      "2. **Enhanced Natural Language Processing**: The emphasis on advanced natural language processing (NLP) capabilities is critical for the success of AI agents, especially in applications that require human-like interaction. The ability to understand and generate natural language responses not only enhances user experience but also increases the effectiveness of the AI agent in performing its tasks. This capability can lead to higher user satisfaction and engagement, as users are more likely to interact with an AI that communicates in a relatable and intuitive manner. Moreover, improved NLP can reduce misunderstandings and errors in communication, which is vital for applications in customer service, education, and healthcare.\n",
      "\n",
      "3. **Scalability and Flexibility**: The scalability of LangGraph is another essential benefit, as it allows developers to create AI agents that can grow with their user base or adapt to varying workloads. This is particularly important for businesses that may start with a small project but anticipate growth or increased demand over time. The ability to scale effectively means that organizations can invest in LangGraph with confidence, knowing that their AI solutions can evolve without requiring a complete overhaul. Additionally, the flexibility to adapt to different use cases ensures that LangGraph can cater to a wide range of industries and applications, from simple chatbots to complex decision-making systems.\n",
      "\n",
      "**Conclusions**: \n",
      "\n",
      "LangGraph presents a compelling option for developers looking to build AI agents due to its modular design, advanced NLP capabilities, and scalability. These features not only streamline the development process but also enhance the functionality and user experience of the resulting AI agents. As the demand for sophisticated AI solutions continues to grow across various sectors, LangGraph's ability to adapt and scale will likely position it as a valuable tool in the AI development landscape. \n",
      "\n",
      "In summary, organizations considering LangGraph for their AI projects can expect a robust framework that supports rapid development, effective communication, and the ability to scale, making it a strategic choice for both current and future AI initiatives.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "FINAL ANSWER:\n",
      "LangGraph offers several key benefits for building AI agents, making it an attractive choice for developers. Its **modular design** allows for easy integration and customization of components, facilitating rapid development and innovation. The platform's **enhanced natural language processing (NLP)** capabilities enable AI agents to understand and generate human-like responses, improving user interaction and satisfaction. Additionally, LangGraph's **scalability and flexibility** ensure that AI solutions can grow with user demands and adapt to various applications, from simple chatbots to complex systems. Overall, LangGraph provides a robust framework that streamlines development, enhances functionality, and positions organizations for success in the evolving AI landscape.\n"
     ]
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
