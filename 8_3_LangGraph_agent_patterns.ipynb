{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02846c5e",
   "metadata": {},
   "source": "## Architektury agentów"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Instalacja bibliotek",
   "id": "971acb42af2cb236"
  },
  {
   "cell_type": "code",
   "id": "77f9b81c",
   "metadata": {},
   "source": "%pip install -U langgraph langchain langchain-openai",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Import bibliotek i konfiguracja",
   "id": "6cffa241fe838685"
  },
  {
   "cell_type": "code",
   "id": "4f251900",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T09:23:42.544748Z",
     "start_time": "2025-10-19T09:23:42.540235Z"
    }
   },
   "source": [
    "import operator\n",
    "from typing import Annotated, List, TypedDict, Literal\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "8b1b1578",
   "metadata": {},
   "source": [
    "### Sequential Agent\n",
    "Sequential Agent prowadzi wewnętrzne rozumowanie w kilku krokach (tzw. scratchpad), ale nie używa narzędzi; stosowany tam, gdzie wystarczy czysta analiza i dedukcja."
   ]
  },
  {
   "cell_type": "code",
   "id": "b5bfcd8c",
   "metadata": {},
   "source": [
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    steps: Annotated[List[str], operator.add]\n",
    "    answer: str\n",
    "\n",
    "def plan_node(state: State) -> dict:\n",
    "    sys = (\n",
    "        \"You are a careful planner. Break the user's question into 2-4 concise steps. \"\n",
    "        \"Do not solve. Return only a numbered list of steps; no extra text.\"\n",
    "    )\n",
    "    messages = [(\"system\", sys), (\"user\", state[\"question\"])]\n",
    "    resp = llm.invoke(messages)\n",
    "    raw = resp.content\n",
    "    steps = []\n",
    "    for line in str(raw).splitlines():\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        line = line.lstrip(\"-• \").split(\". \", 1)[-1] if \". \" in line[:4] else line.lstrip(\"-• \")\n",
    "        steps.append(line)\n",
    "    return {\"steps\": steps}\n",
    "\n",
    "def solve_node(state: State) -> dict:\n",
    "    \"\"\"Use the planned steps to derive the final answer only.\"\"\"\n",
    "    sys = (\n",
    "        \"Use the provided steps to solve the problem. \"\n",
    "        \"Return only the final answer, no reasoning.\"\n",
    "    )\n",
    "    messages = [\n",
    "        (\"system\", sys),\n",
    "        (\"user\", f\"Question: {state['question']}\\nSteps: {state['steps']}\"),\n",
    "    ]\n",
    "    resp = llm.invoke(messages)\n",
    "    return {\"answer\": str(resp.content).strip()}\n",
    "\n",
    "# Wire up the graph\n",
    "graph = StateGraph(State)\n",
    "graph.add_node(\"plan\", plan_node)\n",
    "graph.add_node(\"solve\", solve_node)\n",
    "graph.add_edge(START, \"plan\")\n",
    "graph.add_edge(\"plan\", \"solve\")\n",
    "graph.add_edge(\"solve\", END)\n",
    "cot_graph = graph.compile()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "90243e2d",
   "metadata": {},
   "source": [
    "state = {\n",
    "    \"question\": \"If a book has 350 pages and I read 14 pages per day, how many days to finish?\",\n",
    "    \"steps\": [],\n",
    "    \"answer\": \"\"\n",
    "}\n",
    "out = cot_graph.invoke(state)\n",
    "print(\"Final answer:\", out[\"answer\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bec1a754",
   "metadata": {},
   "source": [
    "### Custom Agent\n",
    "Custom Agent daje pełną elstyczność, można samemu zdefiniować logikę, routing i węzły."
   ]
  },
  {
   "cell_type": "code",
   "id": "c7cbc302",
   "metadata": {},
   "source": [
    "class CustomState(TypedDict):\n",
    "    input: str\n",
    "    task: Literal[\"math\", \"capitalize\", \"count\"]\n",
    "    result: str\n",
    "\n",
    "def route(state: CustomState) -> str:\n",
    "    \"\"\"Deterministic router based on a simple protocol in the input.\"\"\"\n",
    "    text = state[\"input\"].strip().lower()\n",
    "    if text.startswith(\"math:\"):\n",
    "        return \"math\"\n",
    "    if text.startswith(\"capitalize:\"):\n",
    "        return \"capitalize\"\n",
    "    if text.startswith(\"count:\"):\n",
    "        return \"count\"\n",
    "    return \"count\"\n",
    "\n",
    "def do_math(state: CustomState) -> dict:\n",
    "    expr = state[\"input\"].split(\":\", 1)[-1].strip()\n",
    "    allowed = set(\"0123456789+-*/(). \")\n",
    "    if any(c not in allowed for c in expr):\n",
    "        return {\"result\": \"Error: unsupported characters in math expression.\"}\n",
    "    try:\n",
    "        res = eval(expr, {\"__builtins__\": {}})\n",
    "    except Exception as e:\n",
    "        res = f\"Error: {e}\"\n",
    "    return {\"result\": str(res)}\n",
    "\n",
    "def do_capitalize(state: CustomState) -> dict:\n",
    "    text = state[\"input\"].split(\":\", 1)[-1].strip()\n",
    "    return {\"result\": text.upper()}\n",
    "\n",
    "def do_count(state: CustomState) -> dict:\n",
    "    text = state[\"input\"].split(\":\", 1)[-1].strip()\n",
    "    tokens = [t for t in text.split() if t]\n",
    "    return {\"result\": f\"words={len(tokens)} chars={len(text)}\"}\n",
    "\n",
    "g = StateGraph(CustomState)\n",
    "g.add_node(\"math\", do_math)\n",
    "g.add_node(\"capitalize\", do_capitalize)\n",
    "g.add_node(\"count\", do_count)\n",
    "\n",
    "# Conditional edges from router\n",
    "g.add_conditional_edges(\n",
    "    START,\n",
    "    route,\n",
    "    {\n",
    "        \"math\": \"math\",\n",
    "        \"capitalize\": \"capitalize\",\n",
    "        \"count\": \"count\",\n",
    "    },\n",
    ")\n",
    "g.add_edge(\"math\", END)\n",
    "g.add_edge(\"capitalize\", END)\n",
    "g.add_edge(\"count\", END)\n",
    "\n",
    "custom_agent = g.compile()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "279f8804",
   "metadata": {},
   "source": [
    "# Wypróbuj różne wejścia\n",
    "for user_input in [\n",
    "    \"math: (12 + 8) * 3\",\n",
    "    \"capitalize: langgraph is great!\",\n",
    "    \"count: How many words are here?\",\n",
    "]:\n",
    "    out = custom_agent.invoke({\"input\": user_input, \"task\": \"count\", \"result\": \"\"})\n",
    "    print(f\"Input: {user_input}\\nResult: {out['result']}\\n---\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Supervisor",
   "id": "83e0ed41aeb9d07e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T09:51:46.762933Z",
     "start_time": "2025-10-19T09:51:32.321828Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Annotated\n",
    "\n",
    "class SupervisorState(TypedDict):\n",
    "    \"\"\"State for supervisor pattern with multiple agents.\"\"\"\n",
    "    topic: str\n",
    "    messages: Annotated[List[str], operator.add]\n",
    "    next_agent: str\n",
    "    final_answer: str\n",
    "\n",
    "\n",
    "def researcher_agent(state: SupervisorState) -> dict:\n",
    "    \"\"\"Researcher agent gathers information about the topic.\"\"\"\n",
    "    sys = (\n",
    "        \"You are a researcher. Your job is to gather key facts and information \"\n",
    "        \"about the given topic. Provide 2-3 key points. Be concise.\"\n",
    "    )\n",
    "    messages_for_llm = [\n",
    "        (\"system\", sys),\n",
    "        (\"user\", f\"Research this topic: {state['topic']}\")\n",
    "    ]\n",
    "    resp = llm.invoke(messages_for_llm)\n",
    "    research_msg = f\"RESEARCHER: {resp.content}\"\n",
    "    return {\"messages\": [research_msg]}\n",
    "\n",
    "\n",
    "def expert_agent(state: SupervisorState) -> dict:\n",
    "    \"\"\"Expert agent analyzes and provides insights based on research.\"\"\"\n",
    "    sys = (\n",
    "        \"You are an expert analyst. Review the research provided and give \"\n",
    "        \"your expert analysis and conclusions. Be specific and insightful.\"\n",
    "    )\n",
    "    # Get context from previous messages\n",
    "    context = \"\\n\".join(state[\"messages\"])\n",
    "    messages_for_llm = [\n",
    "        (\"system\", sys),\n",
    "        (\"user\", f\"Topic: {state['topic']}\\n\\nPrevious research:\\n{context}\\n\\nProvide your expert analysis.\")\n",
    "    ]\n",
    "    resp = llm.invoke(messages_for_llm)\n",
    "    expert_msg = f\"EXPERT: {resp.content}\"\n",
    "    return {\"messages\": [expert_msg]}\n",
    "\n",
    "\n",
    "def supervisor_agent(state: SupervisorState) -> dict:\n",
    "    \"\"\"Supervisor decides which agent should act next or if discussion should end.\"\"\"\n",
    "    sys = (\n",
    "        \"You are a supervisor managing a research discussion between a RESEARCHER and an EXPERT. \"\n",
    "        \"Based on the conversation so far, decide what should happen next:\\n\"\n",
    "        \"- Return 'researcher' if we need initial research or more information\\n\"\n",
    "        \"- Return 'expert' if research is done and we need expert analysis\\n\"\n",
    "        \"- Return 'end' if both research and expert analysis are complete\\n\\n\"\n",
    "        \"Respond with ONLY one word: researcher, expert, or end\"\n",
    "    )\n",
    "\n",
    "    context = \"\\n\".join(state[\"messages\"]) if state[\"messages\"] else \"No discussion yet\"\n",
    "    messages_for_llm = [\n",
    "        (\"system\", sys),\n",
    "        (\"user\", f\"Topic: {state['topic']}\\n\\nConversation:\\n{context}\\n\\nWhat's next?\")\n",
    "    ]\n",
    "    resp = llm.invoke(messages_for_llm)\n",
    "    next_step = resp.content.strip().lower()\n",
    "\n",
    "    # Ensure valid response\n",
    "    if next_step not in [\"researcher\", \"expert\", \"end\"]:\n",
    "        next_step = \"end\"\n",
    "\n",
    "    return {\"next_agent\": next_step}\n",
    "\n",
    "\n",
    "def finalize_answer(state: SupervisorState) -> dict:\n",
    "    \"\"\"Compile final answer from the discussion.\"\"\"\n",
    "    sys = (\n",
    "        \"Summarize the research discussion into a clear, concise final answer. \"\n",
    "        \"Include key findings and expert insights.\"\n",
    "    )\n",
    "    context = \"\\n\".join(state[\"messages\"])\n",
    "    messages_for_llm = [\n",
    "        (\"system\", sys),\n",
    "        (\"user\", f\"Topic: {state['topic']}\\n\\nDiscussion:\\n{context}\\n\\nProvide final summary:\")\n",
    "    ]\n",
    "    resp = llm.invoke(messages_for_llm)\n",
    "    return {\"final_answer\": resp.content}\n",
    "\n",
    "\n",
    "def route_supervisor(state: SupervisorState) -> str:\n",
    "    \"\"\"Route based on supervisor's decision.\"\"\"\n",
    "    next_agent = state.get(\"next_agent\", \"researcher\")\n",
    "    if next_agent == \"end\":\n",
    "        return \"finalize\"\n",
    "    return next_agent\n",
    "\n",
    "supervisor_graph = StateGraph(SupervisorState)\n",
    "\n",
    "supervisor_graph.add_node(\"supervisor\", supervisor_agent)\n",
    "supervisor_graph.add_node(\"researcher\", researcher_agent)\n",
    "supervisor_graph.add_node(\"expert\", expert_agent)\n",
    "supervisor_graph.add_node(\"finalize\", finalize_answer)\n",
    "\n",
    "supervisor_graph.add_edge(START, \"supervisor\")\n",
    "\n",
    "supervisor_graph.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    route_supervisor,\n",
    "    {\n",
    "        \"researcher\": \"researcher\",\n",
    "        \"expert\": \"expert\",\n",
    "        \"finalize\": \"finalize\"\n",
    "    }\n",
    ")\n",
    "\n",
    "supervisor_graph.add_edge(\"researcher\", \"supervisor\")\n",
    "supervisor_graph.add_edge(\"expert\", \"supervisor\")\n",
    "\n",
    "supervisor_graph.add_edge(\"finalize\", END)\n",
    "\n",
    "supervisor_agent_graph = supervisor_graph.compile()\n",
    "\n",
    "topic = \"What are the main benefits of using LangGraph for building AI agents?\"\n",
    "\n",
    "initial_state = {\n",
    "    \"topic\": topic,\n",
    "    \"messages\": [],\n",
    "    \"next_agent\": \"\",\n",
    "    \"final_answer\": \"\"\n",
    "}\n",
    "\n",
    "result = supervisor_agent_graph.invoke(initial_state)\n",
    "\n",
    "print(f\"TOPIC: {topic}\\n\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nDISCUSSION:\")\n",
    "print(\"-\" * 80)\n",
    "for msg in result[\"messages\"]:\n",
    "    print(f\"\\n{msg}\\n\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nFINAL ANSWER:\\n{result['final_answer']}\")\n"
   ],
   "id": "68458fef5529f946",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOPIC: What are the main benefits of using LangGraph for building AI agents?\n",
      "\n",
      "================================================================================\n",
      "\n",
      "DISCUSSION:\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "RESEARCHER: 1. **Modular Design**: LangGraph offers a modular architecture that allows developers to easily integrate various components and functionalities, facilitating the rapid development and customization of AI agents.\n",
      "\n",
      "2. **Enhanced Natural Language Processing**: It leverages advanced natural language processing capabilities, enabling AI agents to understand and generate human-like responses, improving user interaction and engagement.\n",
      "\n",
      "3. **Scalability and Flexibility**: LangGraph is designed to be scalable, allowing developers to build AI agents that can handle varying workloads and adapt to different use cases, from simple tasks to complex applications.\n",
      "\n",
      "\n",
      "EXPERT: The research highlights several key benefits of using LangGraph for building AI agents, each of which plays a crucial role in the development and deployment of effective AI solutions. Here’s a detailed analysis of these benefits:\n",
      "\n",
      "1. **Modular Design**:\n",
      "   - **Analysis**: The modular architecture of LangGraph is a significant advantage for developers. It allows for the separation of concerns, meaning that different functionalities can be developed, tested, and deployed independently. This modularity not only accelerates the development process but also enhances maintainability. Developers can easily swap out components or add new features without overhauling the entire system, which is particularly beneficial in agile development environments where requirements may evolve rapidly.\n",
      "   - **Conclusion**: The modular design fosters innovation and experimentation, enabling teams to iterate quickly and respond to user feedback effectively. This flexibility is essential in the fast-paced AI landscape, where new technologies and methodologies emerge frequently.\n",
      "\n",
      "2. **Enhanced Natural Language Processing**:\n",
      "   - **Analysis**: The emphasis on advanced natural language processing (NLP) capabilities is critical for the success of AI agents, as user interaction is often centered around natural language. By enabling AI agents to understand and generate human-like responses, LangGraph significantly improves user experience. This capability not only enhances engagement but also broadens the potential applications of AI agents, making them suitable for customer service, virtual assistants, and more complex conversational interfaces.\n",
      "   - **Conclusion**: The enhanced NLP capabilities position LangGraph as a competitive tool in the AI development space, as effective communication is a cornerstone of user satisfaction and retention. This focus on human-like interaction can lead to higher adoption rates and more effective AI solutions.\n",
      "\n",
      "3. **Scalability and Flexibility**:\n",
      "   - **Analysis**: Scalability is a critical factor for any technology that aims to serve a wide range of applications. LangGraph’s design allows developers to create AI agents that can efficiently manage varying workloads, which is essential for businesses that may experience fluctuating demand. The ability to adapt to different use cases—from simple tasks to complex applications—ensures that LangGraph can cater to a diverse clientele, from startups to large enterprises.\n",
      "   - **Conclusion**: The scalability and flexibility of LangGraph not only enhance its utility across different sectors but also future-proof the development of AI agents. As businesses grow and their needs evolve, having a platform that can scale accordingly is invaluable.\n",
      "\n",
      "**Overall Conclusion**:\n",
      "LangGraph presents a robust framework for building AI agents, characterized by its modular design, advanced NLP capabilities, and scalability. These benefits collectively empower developers to create highly effective, user-friendly, and adaptable AI solutions. As the demand for AI-driven applications continues to rise, LangGraph's strengths position it as a leading choice for developers looking to innovate and enhance user engagement in their AI projects. The combination of these features not only streamlines the development process but also ensures that the resulting AI agents are capable of meeting the diverse and evolving needs of users.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "FINAL ANSWER:\n",
      "LangGraph offers several key benefits for building AI agents, making it a compelling choice for developers. \n",
      "\n",
      "1. **Modular Design**: Its modular architecture allows for easy integration and customization of components, facilitating rapid development and maintenance. This flexibility supports agile methodologies, enabling teams to quickly adapt to changing requirements.\n",
      "\n",
      "2. **Enhanced Natural Language Processing**: LangGraph's advanced NLP capabilities enable AI agents to understand and generate human-like responses, significantly improving user interaction and engagement. This positions LangGraph as a competitive tool in the AI space, enhancing user satisfaction and adoption rates.\n",
      "\n",
      "3. **Scalability and Flexibility**: The platform is designed to handle varying workloads and adapt to diverse use cases, making it suitable for a wide range of applications from simple tasks to complex systems. This scalability ensures that LangGraph can meet the evolving needs of businesses, from startups to large enterprises.\n",
      "\n",
      "Overall, LangGraph's strengths in modularity, NLP, and scalability empower developers to create effective, user-friendly, and adaptable AI solutions, positioning it as a leading framework in the growing demand for AI-driven applications.\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
